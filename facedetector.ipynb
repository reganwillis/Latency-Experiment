{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d7c93c7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-13T14:29:25.818513Z",
     "iopub.status.busy": "2025-04-13T14:29:25.818199Z",
     "iopub.status.idle": "2025-04-13T14:29:37.157317Z",
     "shell.execute_reply": "2025-04-13T14:29:37.156384Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 11.34692,
     "end_time": "2025-04-13T14:29:37.159019",
     "exception": false,
     "start_time": "2025-04-13T14:29:25.812099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from torchmetrics.detection import IntersectionOverUnion\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import shutil\n",
    "from torchsummary import summary\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00ae137b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T14:29:37.169184Z",
     "iopub.status.busy": "2025-04-13T14:29:37.168821Z",
     "iopub.status.idle": "2025-04-13T14:29:37.221321Z",
     "shell.execute_reply": "2025-04-13T14:29:37.220604Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.058658,
     "end_time": "2025-04-13T14:29:37.222535",
     "exception": false,
     "start_time": "2025-04-13T14:29:37.163877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27a6ff96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T14:29:37.232170Z",
     "iopub.status.busy": "2025-04-13T14:29:37.231958Z",
     "iopub.status.idle": "2025-04-13T14:29:37.599088Z",
     "shell.execute_reply": "2025-04-13T14:29:37.598300Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.373268,
     "end_time": "2025-04-13T14:29:37.600315",
     "exception": false,
     "start_time": "2025-04-13T14:29:37.227047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /kaggle/input/dataset-face-detection-for-edge-computing-class\n",
      "Path to dataset files: /kaggle/input/testset\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"icaslab/dataset-face-detection-for-edge-computing-class\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"reganwillis/testset\")\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "935b46d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T14:29:37.610181Z",
     "iopub.status.busy": "2025-04-13T14:29:37.609975Z",
     "iopub.status.idle": "2025-04-13T14:29:37.613009Z",
     "shell.execute_reply": "2025-04-13T14:29:37.612311Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.00904,
     "end_time": "2025-04-13T14:29:37.614055",
     "exception": false,
     "start_time": "2025-04-13T14:29:37.605015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Data base addresses\n",
    "base_adress = '/kaggle/input/dataset-face-detection-for-edge-computing-class/Dataset_FDDB/Dataset_FDDB/images'\n",
    "labels_adr = '/kaggle/input/dataset-face-detection-for-edge-computing-class/Dataset_FDDB/Dataset_FDDB/label.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cde2c687",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T14:29:37.623433Z",
     "iopub.status.busy": "2025-04-13T14:29:37.623231Z",
     "iopub.status.idle": "2025-04-13T14:29:37.651421Z",
     "shell.execute_reply": "2025-04-13T14:29:37.650853Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.034189,
     "end_time": "2025-04-13T14:29:37.652635",
     "exception": false,
     "start_time": "2025-04-13T14:29:37.618446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make the labels ready\n",
    "\n",
    "with open(labels_adr, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "annotations = []\n",
    "bboxes = []\n",
    "flag = False\n",
    "for line in lines:\n",
    "    if line.startswith('#'):\n",
    "      if flag:\n",
    "        annotations.append({'image':img_name, 'bboxes': bboxes})\n",
    "        bboxes = []\n",
    "      flag = True\n",
    "      img_name = line[2:]\n",
    "    else:\n",
    "      x_min, y_min, x_max, y_max = line.split()\n",
    "      bboxes.append([int(x_min), int(y_min), int(x_max), int(y_max)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cc67d6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T14:29:37.662096Z",
     "iopub.status.busy": "2025-04-13T14:29:37.661904Z",
     "iopub.status.idle": "2025-04-13T14:29:37.668830Z",
     "shell.execute_reply": "2025-04-13T14:29:37.668161Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.012953,
     "end_time": "2025-04-13T14:29:37.669948",
     "exception": false,
     "start_time": "2025-04-13T14:29:37.656995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom Dataset Class for FDDB\n",
    "class FDDBDataset(Dataset):\n",
    "    def __init__(self, img_dir, annot_file, target_size=(224, 224), transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.target_size = target_size\n",
    "        self.transform = transform\n",
    "        self.data = self._parse_annotations(annot_file)\n",
    "\n",
    "    def _parse_annotations(self, annot_file):\n",
    "        \n",
    "        data = []\n",
    "        for el in annot_file:\n",
    "          img_path = os.path.join(self.img_dir, el['image'][:-1])\n",
    "          boxes = el['bboxes']\n",
    "          data.append((img_path, boxes))\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, boxes = self.data[idx]\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
    "\n",
    "        # Original dimensions\n",
    "        h, w, _ = image.shape\n",
    "\n",
    "        # Resize image\n",
    "        image_resized = cv2.resize(image, self.target_size)\n",
    "        target_h, target_w = self.target_size\n",
    "\n",
    "        # Scale bounding boxes\n",
    "        scale_x = target_w / w\n",
    "        scale_y = target_h / h\n",
    "        boxes_resized = []\n",
    "        for box in boxes:\n",
    "            x_min = int(box[0] * scale_x)\n",
    "            y_min = int(box[1] * scale_y)\n",
    "            x_max = int(box[2] * scale_x)\n",
    "            y_max = int(box[3] * scale_y)\n",
    "            boxes_resized.append([x_min, y_min, x_max, y_max])\n",
    "\n",
    "        # Convert to tensor\n",
    "        if self.transform:\n",
    "            image_resized = self.transform(image_resized)\n",
    "        else:\n",
    "            image_resized = transforms.ToTensor()(image_resized)\n",
    "\n",
    "        return image_resized, torch.tensor(boxes_resized, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffa91e23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T14:29:37.679261Z",
     "iopub.status.busy": "2025-04-13T14:29:37.679060Z",
     "iopub.status.idle": "2025-04-13T14:29:37.684203Z",
     "shell.execute_reply": "2025-04-13T14:29:37.683562Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.010922,
     "end_time": "2025-04-13T14:29:37.685252",
     "exception": false,
     "start_time": "2025-04-13T14:29:37.674330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DataLoader preparation\n",
    "def get_dataloaders(img_dir, annot_file, batch_size=16, target_size=(224, 224), validation_split=0.2):\n",
    "\n",
    "    # Transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # Dataset\n",
    "    dataset = FDDBDataset(img_dir, annot_file, target_size, transform)\n",
    "\n",
    "    # Split dataset\n",
    "    val_size = int(len(dataset) * validation_split)\n",
    "    train_size = len(dataset) - val_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    # DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function to handle variable-length bounding box arrays.\n",
    "\n",
    "    :param batch: List of tuples (image, boxes).\n",
    "    :return: Tuple of images and targets.\n",
    "    \"\"\"\n",
    "    images = torch.stack([item[0] for item in batch])\n",
    "    targets = [item[1] for item in batch]\n",
    "    return images, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "459d3301",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T14:29:37.694824Z",
     "iopub.status.busy": "2025-04-13T14:29:37.694585Z",
     "iopub.status.idle": "2025-04-13T14:29:38.810632Z",
     "shell.execute_reply": "2025-04-13T14:29:38.809753Z"
    },
    "papermill": {
     "duration": 1.123098,
     "end_time": "2025-04-13T14:29:38.812740",
     "exception": false,
     "start_time": "2025-04-13T14:29:37.689642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 112, 112]             896\n",
      "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
      "             ReLU6-3         [-1, 32, 112, 112]               0\n",
      "            Conv2d-4         [-1, 32, 112, 112]             288\n",
      "       BatchNorm2d-5         [-1, 32, 112, 112]              64\n",
      "             ReLU6-6         [-1, 32, 112, 112]               0\n",
      "            Conv2d-7         [-1, 16, 112, 112]             512\n",
      "       BatchNorm2d-8         [-1, 16, 112, 112]              32\n",
      "            Conv2d-9         [-1, 96, 112, 112]           1,536\n",
      "      BatchNorm2d-10         [-1, 96, 112, 112]             192\n",
      "            ReLU6-11         [-1, 96, 112, 112]               0\n",
      "           Conv2d-12           [-1, 96, 56, 56]             864\n",
      "      BatchNorm2d-13           [-1, 96, 56, 56]             192\n",
      "            ReLU6-14           [-1, 96, 56, 56]               0\n",
      "           Conv2d-15           [-1, 24, 56, 56]           2,304\n",
      "      BatchNorm2d-16           [-1, 24, 56, 56]              48\n",
      "           Conv2d-17          [-1, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-18          [-1, 144, 56, 56]             288\n",
      "            ReLU6-19          [-1, 144, 56, 56]               0\n",
      "           Conv2d-20          [-1, 144, 56, 56]           1,296\n",
      "      BatchNorm2d-21          [-1, 144, 56, 56]             288\n",
      "            ReLU6-22          [-1, 144, 56, 56]               0\n",
      "           Conv2d-23           [-1, 24, 56, 56]           3,456\n",
      "      BatchNorm2d-24           [-1, 24, 56, 56]              48\n",
      "           Conv2d-25          [-1, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-26          [-1, 144, 56, 56]             288\n",
      "            ReLU6-27          [-1, 144, 56, 56]               0\n",
      "           Conv2d-28          [-1, 144, 28, 28]           1,296\n",
      "      BatchNorm2d-29          [-1, 144, 28, 28]             288\n",
      "            ReLU6-30          [-1, 144, 28, 28]               0\n",
      "           Conv2d-31           [-1, 32, 28, 28]           4,608\n",
      "      BatchNorm2d-32           [-1, 32, 28, 28]              64\n",
      "           Conv2d-33          [-1, 192, 28, 28]           6,144\n",
      "      BatchNorm2d-34          [-1, 192, 28, 28]             384\n",
      "            ReLU6-35          [-1, 192, 28, 28]               0\n",
      "           Conv2d-36          [-1, 192, 28, 28]           1,728\n",
      "      BatchNorm2d-37          [-1, 192, 28, 28]             384\n",
      "            ReLU6-38          [-1, 192, 28, 28]               0\n",
      "           Conv2d-39           [-1, 32, 28, 28]           6,144\n",
      "      BatchNorm2d-40           [-1, 32, 28, 28]              64\n",
      "           Conv2d-41          [-1, 192, 28, 28]           6,144\n",
      "      BatchNorm2d-42          [-1, 192, 28, 28]             384\n",
      "            ReLU6-43          [-1, 192, 28, 28]               0\n",
      "           Conv2d-44          [-1, 192, 28, 28]           1,728\n",
      "      BatchNorm2d-45          [-1, 192, 28, 28]             384\n",
      "            ReLU6-46          [-1, 192, 28, 28]               0\n",
      "           Conv2d-47           [-1, 32, 28, 28]           6,144\n",
      "      BatchNorm2d-48           [-1, 32, 28, 28]              64\n",
      "           Conv2d-49          [-1, 192, 28, 28]           6,144\n",
      "      BatchNorm2d-50          [-1, 192, 28, 28]             384\n",
      "            ReLU6-51          [-1, 192, 28, 28]               0\n",
      "           Conv2d-52          [-1, 192, 14, 14]           1,728\n",
      "      BatchNorm2d-53          [-1, 192, 14, 14]             384\n",
      "            ReLU6-54          [-1, 192, 14, 14]               0\n",
      "           Conv2d-55           [-1, 64, 14, 14]          12,288\n",
      "      BatchNorm2d-56           [-1, 64, 14, 14]             128\n",
      "           Conv2d-57          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-58          [-1, 384, 14, 14]             768\n",
      "            ReLU6-59          [-1, 384, 14, 14]               0\n",
      "           Conv2d-60          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-61          [-1, 384, 14, 14]             768\n",
      "            ReLU6-62          [-1, 384, 14, 14]               0\n",
      "           Conv2d-63           [-1, 64, 14, 14]          24,576\n",
      "      BatchNorm2d-64           [-1, 64, 14, 14]             128\n",
      "           Conv2d-65          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-66          [-1, 384, 14, 14]             768\n",
      "            ReLU6-67          [-1, 384, 14, 14]               0\n",
      "           Conv2d-68          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-69          [-1, 384, 14, 14]             768\n",
      "            ReLU6-70          [-1, 384, 14, 14]               0\n",
      "           Conv2d-71           [-1, 64, 14, 14]          24,576\n",
      "      BatchNorm2d-72           [-1, 64, 14, 14]             128\n",
      "           Conv2d-73          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-74          [-1, 384, 14, 14]             768\n",
      "            ReLU6-75          [-1, 384, 14, 14]               0\n",
      "           Conv2d-76          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-77          [-1, 384, 14, 14]             768\n",
      "            ReLU6-78          [-1, 384, 14, 14]               0\n",
      "           Conv2d-79           [-1, 64, 14, 14]          24,576\n",
      "      BatchNorm2d-80           [-1, 64, 14, 14]             128\n",
      "           Conv2d-81          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-82          [-1, 384, 14, 14]             768\n",
      "            ReLU6-83          [-1, 384, 14, 14]               0\n",
      "           Conv2d-84          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-85          [-1, 384, 14, 14]             768\n",
      "            ReLU6-86          [-1, 384, 14, 14]               0\n",
      "           Conv2d-87           [-1, 96, 14, 14]          36,864\n",
      "      BatchNorm2d-88           [-1, 96, 14, 14]             192\n",
      "           Conv2d-89          [-1, 576, 14, 14]          55,296\n",
      "      BatchNorm2d-90          [-1, 576, 14, 14]           1,152\n",
      "            ReLU6-91          [-1, 576, 14, 14]               0\n",
      "           Conv2d-92          [-1, 576, 14, 14]           5,184\n",
      "      BatchNorm2d-93          [-1, 576, 14, 14]           1,152\n",
      "            ReLU6-94          [-1, 576, 14, 14]               0\n",
      "           Conv2d-95           [-1, 96, 14, 14]          55,296\n",
      "      BatchNorm2d-96           [-1, 96, 14, 14]             192\n",
      "           Conv2d-97          [-1, 576, 14, 14]          55,296\n",
      "      BatchNorm2d-98          [-1, 576, 14, 14]           1,152\n",
      "            ReLU6-99          [-1, 576, 14, 14]               0\n",
      "          Conv2d-100          [-1, 576, 14, 14]           5,184\n",
      "     BatchNorm2d-101          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-102          [-1, 576, 14, 14]               0\n",
      "          Conv2d-103           [-1, 96, 14, 14]          55,296\n",
      "     BatchNorm2d-104           [-1, 96, 14, 14]             192\n",
      "          Conv2d-105          [-1, 576, 14, 14]          55,296\n",
      "     BatchNorm2d-106          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-107          [-1, 576, 14, 14]               0\n",
      "          Conv2d-108            [-1, 576, 7, 7]           5,184\n",
      "     BatchNorm2d-109            [-1, 576, 7, 7]           1,152\n",
      "           ReLU6-110            [-1, 576, 7, 7]               0\n",
      "          Conv2d-111            [-1, 160, 7, 7]          92,160\n",
      "     BatchNorm2d-112            [-1, 160, 7, 7]             320\n",
      "          Conv2d-113            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-114            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-115            [-1, 960, 7, 7]               0\n",
      "          Conv2d-116            [-1, 960, 7, 7]           8,640\n",
      "     BatchNorm2d-117            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-118            [-1, 960, 7, 7]               0\n",
      "          Conv2d-119            [-1, 160, 7, 7]         153,600\n",
      "     BatchNorm2d-120            [-1, 160, 7, 7]             320\n",
      "          Conv2d-121            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-122            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-123            [-1, 960, 7, 7]               0\n",
      "          Conv2d-124            [-1, 960, 7, 7]           8,640\n",
      "     BatchNorm2d-125            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-126            [-1, 960, 7, 7]               0\n",
      "          Conv2d-127            [-1, 160, 7, 7]         153,600\n",
      "     BatchNorm2d-128            [-1, 160, 7, 7]             320\n",
      "          Conv2d-129            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-130            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-131            [-1, 960, 7, 7]               0\n",
      "          Conv2d-132            [-1, 960, 7, 7]           8,640\n",
      "     BatchNorm2d-133            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-134            [-1, 960, 7, 7]               0\n",
      "          Conv2d-135            [-1, 320, 7, 7]         307,200\n",
      "     BatchNorm2d-136            [-1, 320, 7, 7]             640\n",
      "          Conv2d-137           [-1, 1280, 7, 7]         409,600\n",
      "     BatchNorm2d-138           [-1, 1280, 7, 7]           2,560\n",
      "           ReLU6-139           [-1, 1280, 7, 7]               0\n",
      "AdaptiveAvgPool2d-140           [-1, 1280, 1, 1]               0\n",
      "          Linear-141                  [-1, 512]         655,872\n",
      "            ReLU-142                  [-1, 512]               0\n",
      "         Dropout-143                  [-1, 512]               0\n",
      "          Linear-144                    [-1, 4]           2,052\n",
      "          Linear-145                  [-1, 512]         655,872\n",
      "            ReLU-146                  [-1, 512]               0\n",
      "          Linear-147                    [-1, 1]             513\n",
      "         Sigmoid-148                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 3,538,213\n",
      "Trainable params: 3,538,213\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 148.51\n",
      "Params size (MB): 13.50\n",
      "Estimated Total Size (MB): 162.58\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class MobileNetFaceDetector(nn.Module):\n",
    "    def __init__(self, pretrained=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3,\n",
    "            out_channels=32,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            padding=1\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu1 = nn.ReLU6()\n",
    "\n",
    "        # bottleneck\n",
    "        #hidden_dim = 32\n",
    "        self.bottleneck1 = nn.Sequential(\n",
    "            #nn.Conv2d(in_channels=32, out_channels=32, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            #nn.BatchNorm2d(32),\n",
    "            #nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1, groups=32, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=32, out_channels=16, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "        )\n",
    "        #hidden_dim = 16*6\n",
    "        self.bottleneck2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=16*6, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(16*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=16*6, out_channels=16*6, kernel_size=3, stride=2, padding=1, groups=16*6, bias=False),\n",
    "            nn.BatchNorm2d(16*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=16*6, out_channels=24, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(24),\n",
    "        )\n",
    "        self.bottleneck21 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=24, out_channels=24*6, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(24*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=24*6, out_channels=24*6, kernel_size=3, stride=1, padding=1, groups=24*6, bias=False),\n",
    "            nn.BatchNorm2d(24*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=24*6, out_channels=24, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(24),\n",
    "        )\n",
    "        #hidden_dim = 24*6\n",
    "        self.bottleneck3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=24, out_channels=24*6, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(24*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=24*6, out_channels=24*6, kernel_size=3, stride=2, padding=1, groups=24*6, bias=False),\n",
    "            nn.BatchNorm2d(24*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=24*6, out_channels=32, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        self.bottleneck31 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32*6, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(32*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=32*6, out_channels=32*6, kernel_size=3, stride=1, padding=1, groups=32*6, bias=False),\n",
    "            nn.BatchNorm2d(32*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=32*6, out_channels=32, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        self.bottleneck32 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32*6, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(32*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=32*6, out_channels=32*6, kernel_size=3, stride=1, padding=1, groups=32*6, bias=False),\n",
    "            nn.BatchNorm2d(32*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=32*6, out_channels=32, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        #hidden_dim=32*6\n",
    "        self.bottleneck4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32*6, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(32*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=32*6, out_channels=32*6, kernel_size=3, stride=2, padding=1, groups=32*6, bias=False),\n",
    "            nn.BatchNorm2d(32*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=32*6, out_channels=64, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        self.bottleneck41 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=64*6, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(64*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=64*6, out_channels=64*6, kernel_size=3, stride=1, padding=1, groups=64*6, bias=False),\n",
    "            nn.BatchNorm2d(64*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=64*6, out_channels=64, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        self.bottleneck42 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=64*6, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(64*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=64*6, out_channels=64*6, kernel_size=3, stride=1, padding=1, groups=64*6, bias=False),\n",
    "            nn.BatchNorm2d(64*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=64*6, out_channels=64, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        self.bottleneck43 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=64*6, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(64*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=64*6, out_channels=64*6, kernel_size=3, stride=1, padding=1, groups=64*6, bias=False),\n",
    "            nn.BatchNorm2d(64*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=64*6, out_channels=64, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        #hidden_dim=64*6\n",
    "        self.bottleneck5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=64*6, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(64*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=64*6, out_channels=64*6, kernel_size=3, stride=1, padding=1, groups=64*6, bias=False),\n",
    "            nn.BatchNorm2d(64*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=64*6, out_channels=96, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(96),\n",
    "        )\n",
    "        self.bottleneck51 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=96, out_channels=96*6, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(96*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=96*6, out_channels=96*6, kernel_size=3, stride=1, padding=1, groups=96*6, bias=False),\n",
    "            nn.BatchNorm2d(96*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=96*6, out_channels=96, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(96),\n",
    "        )\n",
    "        self.bottleneck52 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=96, out_channels=96*6, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(96*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=96*6, out_channels=96*6, kernel_size=3, stride=1, padding=1, groups=96*6, bias=False),\n",
    "            nn.BatchNorm2d(96*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=96*6, out_channels=96, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(96),\n",
    "        )\n",
    "        #hidden_dim=96*6\n",
    "        self.bottleneck6 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=96, out_channels=96*6, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(96*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=96*6, out_channels=96*6, kernel_size=3, stride=2, padding=1, groups=96*6, bias=False),\n",
    "            nn.BatchNorm2d(96*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=96*6, out_channels=160, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(160),\n",
    "        )\n",
    "        self.bottleneck61 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=160, out_channels=160*6, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(160*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=160*6, out_channels=160*6, kernel_size=3, stride=1, padding=1, groups=160*6, bias=False),\n",
    "            nn.BatchNorm2d(160*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=160*6, out_channels=160, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(160),\n",
    "        )\n",
    "        self.bottleneck62 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=160, out_channels=160*6, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(160*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=160*6, out_channels=160*6, kernel_size=3, stride=1, padding=1, groups=160*6, bias=False),\n",
    "            nn.BatchNorm2d(160*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=160*6, out_channels=160, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(160),\n",
    "        )\n",
    "        #hidden_dim=160*6\n",
    "        self.bottleneck7 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=160, out_channels=160*6, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(160*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=160*6, out_channels=160*6, kernel_size=3, stride=1, padding=1, groups=160*6, bias=False),\n",
    "            nn.BatchNorm2d(160*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=160*6, out_channels=320, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(320),\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=320,\n",
    "            out_channels=1280,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(1280)\n",
    "        self.relu2 = nn.ReLU6()\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        # Custom head for bounding box and classification\n",
    "        self.fc_bbox = nn.Sequential(\n",
    "            nn.Linear(1280, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(512, 4),  # Bounding box: [x_min, y_min, x_max, y_max]\n",
    "        )\n",
    "        self.fc_label = nn.Sequential(\n",
    "            nn.Linear(1280, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1),  # Binary classification: face/no face\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        x = self.bottleneck1(x)\n",
    "        x = self.bottleneck2(x)\n",
    "        x = self.bottleneck21(x)\n",
    "        x = self.bottleneck3(x)\n",
    "        x = self.bottleneck31(x)\n",
    "        x = self.bottleneck32(x)\n",
    "        x = self.bottleneck4(x)\n",
    "        x = self.bottleneck41(x)\n",
    "        x = self.bottleneck42(x)\n",
    "        x = self.bottleneck43(x)\n",
    "        x = self.bottleneck5(x)\n",
    "        x = self.bottleneck51(x)\n",
    "        x = self.bottleneck52(x)\n",
    "        x = self.bottleneck6(x)\n",
    "        x = self.bottleneck61(x)\n",
    "        x = self.bottleneck62(x)\n",
    "        x = self.bottleneck7(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        x = self.pool(x).view(x.size(0), -1)\n",
    "        bbox = self.fc_bbox(x)\n",
    "        label = self.fc_label(x)\n",
    "        return bbox, label\n",
    "mobilenetfacedetector = MobileNetFaceDetector().to(device)\n",
    "summary(mobilenetfacedetector, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a270ae6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T14:29:38.823246Z",
     "iopub.status.busy": "2025-04-13T14:29:38.823012Z",
     "iopub.status.idle": "2025-04-13T14:29:38.826257Z",
     "shell.execute_reply": "2025-04-13T14:29:38.825637Z"
    },
    "papermill": {
     "duration": 0.009733,
     "end_time": "2025-04-13T14:29:38.827429",
     "exception": false,
     "start_time": "2025-04-13T14:29:38.817696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "bbox_loss_fn = nn.SmoothL1Loss()  # For bounding box regression\n",
    "label_loss_fn = nn.BCELoss()      # For binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c5f492e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T14:29:38.837372Z",
     "iopub.status.busy": "2025-04-13T14:29:38.837148Z",
     "iopub.status.idle": "2025-04-13T14:29:38.843898Z",
     "shell.execute_reply": "2025-04-13T14:29:38.843272Z"
    },
    "papermill": {
     "duration": 0.012953,
     "end_time": "2025-04-13T14:29:38.844973",
     "exception": false,
     "start_time": "2025-04-13T14:29:38.832020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train_model(train_loader, val_loader, num_epochs, model, arch, learning_rate, batch_size):\n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    best_val_loss = float('inf')  # Initialize best validation loss\n",
    "    best_model_path = f\"{arch}_{learning_rate}_{batch_size}.pth\"  # Path to save the best model\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for images, targets in train_loader:\n",
    "            images = images.to(device)\n",
    "            bboxes = [torch.tensor(t, dtype=torch.float32).to(device) for t in targets]  # List of bounding boxes\n",
    "            labels = [int(1) for t in targets]  # List of labels\n",
    "            labels = torch.tensor(labels, dtype=torch.float32).to(device)\n",
    "            preds_bbox, preds_label = model(images)\n",
    "            # Compute losses\n",
    "            bbox_losses = []\n",
    "            label_losses = []\n",
    "            for i in range(len(bboxes)):\n",
    "              bbox_losses.append(bbox_loss_fn(preds_bbox[i], bboxes[i]))\n",
    "              label_losses.append(label_loss_fn(preds_label[i], labels[i].unsqueeze(-1)))\n",
    "\n",
    "            bbox_loss = torch.mean(torch.stack(bbox_losses))\n",
    "            label_loss = torch.mean(torch.stack(label_losses))\n",
    "            loss = bbox_loss + label_loss\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "        # Validate and save the best model\n",
    "        val_loss = validate_model(model, val_loader)\n",
    "        if val_loss < best_val_loss:\n",
    "            print(f\"Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. Saving model...\")\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "    print(\"Training complete. Best model saved as:\", best_model_path)\n",
    "    return best_val_loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6775b357",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T14:29:38.854524Z",
     "iopub.status.busy": "2025-04-13T14:29:38.854318Z",
     "iopub.status.idle": "2025-04-13T14:29:38.857697Z",
     "shell.execute_reply": "2025-04-13T14:29:38.857055Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.009471,
     "end_time": "2025-04-13T14:29:38.858883",
     "exception": false,
     "start_time": "2025-04-13T14:29:38.849412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_boxes(preds):\n",
    "    \"\"\"\n",
    "    Normalize the 'boxes' in the predictions to ensure they are all tensors of shape [N, 4].\n",
    "    Args:\n",
    "        preds: List of dictionaries with 'boxes' and 'labels'.\n",
    "    Returns:\n",
    "        Normalized predictions with 'boxes' as tensors of shape [N, 4].\n",
    "    \"\"\"\n",
    "    for pred in preds:\n",
    "        # If boxes is a list of tensors, stack them into a single tensor\n",
    "        if isinstance(pred['boxes'], list):\n",
    "            pred['boxes'] = torch.stack(pred['boxes'])  # Stack into [N, 4]\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b749fb2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T14:29:38.868600Z",
     "iopub.status.busy": "2025-04-13T14:29:38.868383Z",
     "iopub.status.idle": "2025-04-13T14:29:38.872949Z",
     "shell.execute_reply": "2025-04-13T14:29:38.872290Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.010608,
     "end_time": "2025-04-13T14:29:38.874117",
     "exception": false,
     "start_time": "2025-04-13T14:29:38.863509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_iou(pred_box, gt_box):\n",
    "    \"\"\"\n",
    "    Calculate IoU (Intersection over Union) for a single pair of boxes.\n",
    "    Args:\n",
    "        pred_box: Tensor of shape (4,), [x_min, y_min, x_max, y_max].\n",
    "        gt_box: Tensor of shape (4,), [x_min, y_min, x_max, y_max].\n",
    "    Returns:\n",
    "        IoU value (float).\n",
    "    \"\"\"\n",
    "    # Determine the (x, y)-coordinates of the intersection rectangle\n",
    "    x1 = max(pred_box[0], gt_box[0])\n",
    "    y1 = max(pred_box[1], gt_box[1])\n",
    "    x2 = min(pred_box[2], gt_box[2])\n",
    "    y2 = min(pred_box[3], gt_box[3])\n",
    "\n",
    "    # Compute the area of intersection rectangle\n",
    "    inter_width = max(0, x2 - x1)\n",
    "    inter_height = max(0, y2 - y1)\n",
    "    inter_area = inter_width * inter_height\n",
    "\n",
    "    # Compute the area of both the predicted and ground-truth rectangles\n",
    "    pred_area = (pred_box[2] - pred_box[0]) * (pred_box[3] - pred_box[1])\n",
    "    gt_area = (gt_box[2] - gt_box[0]) * (gt_box[3] - gt_box[1])\n",
    "\n",
    "    # Compute the area of union\n",
    "    union_area = pred_area + gt_area - inter_area\n",
    "\n",
    "    # Compute IoU\n",
    "    iou = inter_area / union_area if union_area > 0 else 0.0\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5806d6c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T14:29:38.884058Z",
     "iopub.status.busy": "2025-04-13T14:29:38.883864Z",
     "iopub.status.idle": "2025-04-13T14:29:38.888185Z",
     "shell.execute_reply": "2025-04-13T14:29:38.887526Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.010599,
     "end_time": "2025-04-13T14:29:38.889375",
     "exception": false,
     "start_time": "2025-04-13T14:29:38.878776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_map(pred_boxes, gt_boxes, threshold=0.5):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "\n",
    "    # format\n",
    "    pred_boxes = pred_boxes[0][\"boxes\"].cpu().detach().numpy().tolist()\n",
    "    gt_boxes = gt_boxes[0][\"boxes\"].cpu().detach().numpy().tolist()\n",
    "\n",
    "    # if there is more than one ground truth box\n",
    "    # loop over ious for all boxes and pick the\n",
    "    # closest one to measure mAP\n",
    "    closest_iou = 0.0\n",
    "    for i in range(len(gt_boxes)):\n",
    "        iou = calculate_iou(pred_boxes[0], gt_boxes[i])\n",
    "        if iou > closest_iou:\n",
    "            closest_iou = iou\n",
    "    if closest_iou >= threshold:\n",
    "        tp += 1\n",
    "    else:\n",
    "        fp += 1\n",
    "    precision = tp / (tp + fp + 1e-6)\n",
    "\n",
    "    return precision * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a3990c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T14:29:38.899130Z",
     "iopub.status.busy": "2025-04-13T14:29:38.898939Z",
     "iopub.status.idle": "2025-04-13T14:29:38.905904Z",
     "shell.execute_reply": "2025-04-13T14:29:38.905254Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.013212,
     "end_time": "2025-04-13T14:29:38.907071",
     "exception": false,
     "start_time": "2025-04-13T14:29:38.893859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate_model(model, val_loader):\n",
    "    metric = IntersectionOverUnion().to(device)\n",
    "    model.eval()\n",
    "    total_bbox_loss = 0\n",
    "    total_label_loss = 0\n",
    "    total_iou = []\n",
    "    total_map = []\n",
    "    with torch.no_grad():\n",
    "        for images, targets in val_loader:\n",
    "            images = images.to(device)\n",
    "            bboxes = [torch.tensor(t, dtype=torch.float32).to(device) for t in targets]  # List of bounding boxes\n",
    "            labels = [int(1) for t in targets]  # List of labels\n",
    "            labels = torch.tensor(labels, dtype=torch.float32).to(device)\n",
    "            preds_bbox, preds_label = model(images)\n",
    "\n",
    "            bbox_losses = []\n",
    "            label_losses = []\n",
    "\n",
    "            for i in range(len(bboxes)):\n",
    "                bbox_losses.append(bbox_loss_fn(preds_bbox[i], bboxes[i]))\n",
    "                label_losses.append(label_loss_fn(preds_label[i], labels[i].unsqueeze(-1)))\n",
    "                \n",
    "                preds = [{\"boxes\": [preds_bbox[i]], \"labels\": preds_label[i]}]\n",
    "                preds = normalize_boxes(preds)\n",
    "                \n",
    "                targets_combined = torch.cat([bboxes[i]], dim=0)\n",
    "                targets = [{\"boxes\": targets_combined, \"labels\": torch.ones(len(targets_combined)).to(device)}]\n",
    "\n",
    "                iou_value = metric(preds, targets)\n",
    "                total_iou.append(iou_value['iou'].item())\n",
    "                map_value = compute_map(preds, targets)\n",
    "                total_map.append(map_value)\n",
    "            total_bbox_loss += torch.mean(torch.stack(bbox_losses))\n",
    "            total_label_loss += torch.mean(torch.stack(label_losses))\n",
    "\n",
    "    # Calculate average validation loss\n",
    "    avg_bbox_loss = total_bbox_loss / len(val_loader)\n",
    "    avg_label_loss = total_label_loss / len(val_loader)\n",
    "    val_loss = avg_bbox_loss + avg_label_loss\n",
    "    print('IoU = ', sum(total_iou)/len(total_iou))\n",
    "    print('mAP@50 = ', sum(total_map)/len(total_map))\n",
    "    print(f\"Validation - BBox Loss: {avg_bbox_loss:.4f}, Label Loss: {avg_label_loss:.4f}, Total Loss: {val_loss:.4f}\")\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a4d2bcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T14:29:38.916564Z",
     "iopub.status.busy": "2025-04-13T14:29:38.916339Z",
     "iopub.status.idle": "2025-04-13T14:29:44.588361Z",
     "shell.execute_reply": "2025-04-13T14:29:44.587637Z"
    },
    "papermill": {
     "duration": 5.678517,
     "end_time": "2025-04-13T14:29:44.589993",
     "exception": false,
     "start_time": "2025-04-13T14:29:38.911476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hyperopt in /usr/local/lib/python3.10/dist-packages (0.2.7)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.26.4)\r\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.13.1)\r\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.17.0)\r\n",
      "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from hyperopt) (3.4.2)\r\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.0.0)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from hyperopt) (4.67.1)\r\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt) (3.1.0)\r\n",
      "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt) (0.10.9.7)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->hyperopt) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->hyperopt) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->hyperopt) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->hyperopt) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->hyperopt) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->hyperopt) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->hyperopt) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->hyperopt) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->hyperopt) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->hyperopt) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->hyperopt) (2024.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install hyperopt\n",
    "from hyperopt import fmin, tpe, hp, anneal, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8c2e3a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T14:29:44.601071Z",
     "iopub.status.busy": "2025-04-13T14:29:44.600602Z",
     "iopub.status.idle": "2025-04-13T15:08:55.321807Z",
     "shell.execute_reply": "2025-04-13T15:08:55.321070Z"
    },
    "papermill": {
     "duration": 2350.72794,
     "end_time": "2025-04-13T15:08:55.323063",
     "exception": false,
     "start_time": "2025-04-13T14:29:44.595123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-592d80072b0a>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  bboxes = [torch.tensor(t, dtype=torch.float32).to(device) for t in targets]  # List of bounding boxes\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:1040: UserWarning: Using a target size (torch.Size([1, 4])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:1040: UserWarning: Using a target size (torch.Size([3, 4])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:1040: UserWarning: Using a target size (torch.Size([2, 4])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:1040: UserWarning: Using a target size (torch.Size([4, 4])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:1040: UserWarning: Using a target size (torch.Size([7, 4])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:1040: UserWarning: Using a target size (torch.Size([5, 4])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:1040: UserWarning: Using a target size (torch.Size([9, 4])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:1040: UserWarning: Using a target size (torch.Size([15, 4])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:1040: UserWarning: Using a target size (torch.Size([8, 4])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:1040: UserWarning: Using a target size (torch.Size([6, 4])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:1040: UserWarning: Using a target size (torch.Size([10, 4])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:1040: UserWarning: Using a target size (torch.Size([11, 4])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:1040: UserWarning: Using a target size (torch.Size([22, 4])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:1040: UserWarning: Using a target size (torch.Size([13, 4])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:1040: UserWarning: Using a target size (torch.Size([27, 4])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:1040: UserWarning: Using a target size (torch.Size([12, 4])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40, Loss: 43.1630\n",
      "  0%|          | 0/3 [00:24<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-3e8f1a4f874e>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  bboxes = [torch.tensor(t, dtype=torch.float32).to(device) for t in targets]  # List of bounding boxes\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IoU = \n",
      "0.24438445957667768\n",
      "mAP@50 = \n",
      "17.13779204948711\n",
      "Validation - BBox Loss: 34.9344, Label Loss: 0.0000, Total Loss: 34.9344\n",
      "Validation loss improved from inf to 34.9344. Saving model...\n",
      "Epoch 2/40, Loss: 27.4809\n",
      "IoU = \n",
      "0.29983391446495833\n",
      "mAP@50 = \n",
      "24.204922791543698\n",
      "Validation - BBox Loss: 32.7128, Label Loss: 0.0000, Total Loss: 32.7128\n",
      "Validation loss improved from 34.9344 to 32.7128. Saving model...\n",
      "Epoch 3/40, Loss: 25.2306\n",
      "IoU = \n",
      "0.36569963863231375\n",
      "mAP@50 = \n",
      "39.929288692619615\n",
      "Validation - BBox Loss: 26.6573, Label Loss: 0.0000, Total Loss: 26.6573\n",
      "Validation loss improved from 32.7128 to 26.6573. Saving model...\n",
      "Epoch 4/40, Loss: 24.1844\n",
      "IoU = \n",
      "0.35334895800489785\n",
      "mAP@50 = \n",
      "35.86568851593707\n",
      "Validation - BBox Loss: 27.5797, Label Loss: 0.0000, Total Loss: 27.5797\n",
      "Epoch 5/40, Loss: 23.1848\n",
      "IoU = \n",
      "0.3919967374297076\n",
      "mAP@50 = \n",
      "47.34977597177903\n",
      "Validation - BBox Loss: 24.2118, Label Loss: 0.0000, Total Loss: 24.2118\n",
      "Validation loss improved from 26.6573 to 24.2118. Saving model...\n",
      "Epoch 6/40, Loss: 22.8109\n",
      "IoU = \n",
      "0.4140654844205165\n",
      "mAP@50 = \n",
      "55.65365459369553\n",
      "Validation - BBox Loss: 22.5865, Label Loss: 0.0000, Total Loss: 22.5865\n",
      "Validation loss improved from 24.2118 to 22.5865. Saving model...\n",
      "Epoch 7/40, Loss: 22.2021\n",
      "IoU = \n",
      "0.4128284878821471\n",
      "mAP@50 = \n",
      "57.067080742106846\n",
      "Validation - BBox Loss: 22.2697, Label Loss: 0.0000, Total Loss: 22.2697\n",
      "Validation loss improved from 22.5865 to 22.2697. Saving model...\n",
      "Epoch 8/40, Loss: 21.2697\n",
      "IoU = \n",
      "0.3822638021465601\n",
      "mAP@50 = \n",
      "51.06001961135874\n",
      "Validation - BBox Loss: 22.4054, Label Loss: 0.0000, Total Loss: 22.4054\n",
      "Epoch 9/40, Loss: 21.0321\n",
      "IoU = \n",
      "0.44545098251166226\n",
      "mAP@50 = \n",
      "61.660715724443484\n",
      "Validation - BBox Loss: 20.8503, Label Loss: 0.0000, Total Loss: 20.8503\n",
      "Validation loss improved from 22.2697 to 20.8503. Saving model...\n",
      "Epoch 10/40, Loss: 20.6193\n",
      "IoU = \n",
      "0.44798993521457203\n",
      "mAP@50 = \n",
      "61.30735918734067\n",
      "Validation - BBox Loss: 20.2460, Label Loss: 0.0000, Total Loss: 20.2460\n",
      "Validation loss improved from 20.8503 to 20.2460. Saving model...\n",
      "Epoch 11/40, Loss: 20.2927\n",
      "IoU = \n",
      "0.39707207181384\n",
      "mAP@50 = \n",
      "53.71019363962996\n",
      "Validation - BBox Loss: 21.0674, Label Loss: 0.0000, Total Loss: 21.0674\n",
      "Epoch 12/40, Loss: 20.0328\n",
      "IoU = \n",
      "0.42860853719601555\n",
      "mAP@50 = \n",
      "60.77732438168645\n",
      "Validation - BBox Loss: 20.7638, Label Loss: 0.0000, Total Loss: 20.7638\n",
      "Epoch 13/40, Loss: 19.6125\n",
      "IoU = \n",
      "0.4703030083846801\n",
      "mAP@50 = \n",
      "66.43102897533151\n",
      "Validation - BBox Loss: 19.5760, Label Loss: 0.0000, Total Loss: 19.5760\n",
      "Validation loss improved from 20.2460 to 19.5760. Saving model...\n",
      "Epoch 14/40, Loss: 19.6683\n",
      "IoU = \n",
      "0.45572486104317794\n",
      "mAP@50 = \n",
      "63.9575332156118\n",
      "Validation - BBox Loss: 19.6259, Label Loss: 0.0000, Total Loss: 19.6259\n",
      "Epoch 15/40, Loss: 19.4980\n",
      "IoU = \n",
      "0.46910279823217027\n",
      "mAP@50 = \n",
      "63.9575332156118\n",
      "Validation - BBox Loss: 19.2338, Label Loss: 0.0000, Total Loss: 19.2338\n",
      "Validation loss improved from 19.5760 to 19.2338. Saving model...\n",
      "Epoch 16/40, Loss: 19.1762\n",
      "IoU = \n",
      "0.4510399793359441\n",
      "mAP@50 = \n",
      "62.89746360430335\n",
      "Validation - BBox Loss: 20.1598, Label Loss: 0.0000, Total Loss: 20.1598\n",
      "Epoch 17/40, Loss: 19.1992\n",
      "IoU = \n",
      "0.4607166922521652\n",
      "mAP@50 = \n",
      "66.07767243822869\n",
      "Validation - BBox Loss: 19.4027, Label Loss: 0.0000, Total Loss: 19.4027\n",
      "Epoch 18/40, Loss: 19.1066\n",
      "IoU = \n",
      "0.4698068632986133\n",
      "mAP@50 = \n",
      "65.54763763257446\n",
      "Validation - BBox Loss: 19.3351, Label Loss: 0.0000, Total Loss: 19.3351\n",
      "Epoch 19/40, Loss: 18.9465\n",
      "IoU = \n",
      "0.48217758714160125\n",
      "mAP@50 = \n",
      "68.19781166084559\n",
      "Validation - BBox Loss: 18.7592, Label Loss: 0.0000, Total Loss: 18.7592\n",
      "Validation loss improved from 19.2338 to 18.7592. Saving model...\n",
      "Epoch 20/40, Loss: 18.8415\n",
      "IoU = \n",
      "0.42486792355490965\n",
      "mAP@50 = \n",
      "59.18721996472377\n",
      "Validation - BBox Loss: 20.0076, Label Loss: 0.0000, Total Loss: 20.0076\n",
      "Epoch 21/40, Loss: 18.6315\n",
      "IoU = \n",
      "0.46062422833848576\n",
      "mAP@50 = \n",
      "65.01760282692024\n",
      "Validation - BBox Loss: 19.0806, Label Loss: 0.0000, Total Loss: 19.0806\n",
      "Epoch 22/40, Loss: 18.7595\n",
      "IoU = \n",
      "0.4831060516022108\n",
      "mAP@50 = \n",
      "68.19781166084559\n",
      "Validation - BBox Loss: 18.5083, Label Loss: 0.0000, Total Loss: 18.5083\n",
      "Validation loss improved from 18.7592 to 18.5083. Saving model...\n",
      "Epoch 23/40, Loss: 18.4648\n",
      "IoU = \n",
      "0.4829223161306588\n",
      "mAP@50 = \n",
      "67.66777685519136\n",
      "Validation - BBox Loss: 18.7316, Label Loss: 0.0000, Total Loss: 18.7316\n",
      "Epoch 24/40, Loss: 18.6353\n",
      "IoU = \n",
      "0.4833140645242813\n",
      "mAP@50 = \n",
      "66.60770724388291\n",
      "Validation - BBox Loss: 18.5772, Label Loss: 0.0000, Total Loss: 18.5772\n",
      "Epoch 25/40, Loss: 18.6960\n",
      "IoU = \n",
      "0.41693675940010577\n",
      "mAP@50 = \n",
      "56.5370459364526\n",
      "Validation - BBox Loss: 20.2976, Label Loss: 0.0000, Total Loss: 20.2976\n",
      "Epoch 26/40, Loss: 18.5422\n",
      "IoU = \n",
      "0.4758215188188643\n",
      "mAP@50 = \n",
      "68.19781166084559\n",
      "Validation - BBox Loss: 18.5214, Label Loss: 0.0000, Total Loss: 18.5214\n",
      "Epoch 27/40, Loss: 18.1730\n",
      "IoU = \n",
      "0.4731446905972254\n",
      "mAP@50 = \n",
      "65.90099416967729\n",
      "Validation - BBox Loss: 19.5273, Label Loss: 0.0000, Total Loss: 19.5273\n",
      "Epoch 28/40, Loss: 18.3965\n",
      "IoU = \n",
      "0.45430056782983996\n",
      "mAP@50 = \n",
      "62.89746360430335\n",
      "Validation - BBox Loss: 19.1603, Label Loss: 0.0000, Total Loss: 19.1603\n",
      "Epoch 29/40, Loss: 18.0780\n",
      "IoU = \n",
      "0.492833540155577\n",
      "mAP@50 = \n",
      "68.72784646649981\n",
      "Validation - BBox Loss: 18.7956, Label Loss: 0.0000, Total Loss: 18.7956\n",
      "Epoch 30/40, Loss: 18.2130\n",
      "IoU = \n",
      "0.4926299305213173\n",
      "mAP@50 = \n",
      "66.2543507067801\n",
      "Validation - BBox Loss: 18.3480, Label Loss: 0.0000, Total Loss: 18.3480\n",
      "Validation loss improved from 18.5083 to 18.3480. Saving model...\n",
      "Epoch 31/40, Loss: 18.2179\n",
      "IoU = \n",
      "0.4820464197694334\n",
      "mAP@50 = \n",
      "68.55116819794841\n",
      "Validation - BBox Loss: 18.8046, Label Loss: 0.0000, Total Loss: 18.8046\n",
      "Epoch 32/40, Loss: 18.0487\n",
      "IoU = \n",
      "0.49001189464597894\n",
      "mAP@50 = \n",
      "68.55116819794841\n",
      "Validation - BBox Loss: 18.2441, Label Loss: 0.0000, Total Loss: 18.2441\n",
      "Validation loss improved from 18.3480 to 18.2441. Saving model...\n",
      "Epoch 33/40, Loss: 17.9789\n",
      "IoU = \n",
      "0.46675568334544376\n",
      "mAP@50 = \n",
      "65.54763763257446\n",
      "Validation - BBox Loss: 18.8432, Label Loss: 0.0000, Total Loss: 18.8432\n",
      "Epoch 34/40, Loss: 18.0423\n",
      "IoU = \n",
      "0.4867971166668052\n",
      "mAP@50 = \n",
      "67.31442031808855\n",
      "Validation - BBox Loss: 18.6302, Label Loss: 0.0000, Total Loss: 18.6302\n",
      "Epoch 35/40, Loss: 17.7939\n",
      "IoU = \n",
      "0.4669072768902291\n",
      "mAP@50 = \n",
      "65.54763763257446\n",
      "Validation - BBox Loss: 19.4369, Label Loss: 0.0000, Total Loss: 19.4369\n",
      "Epoch 36/40, Loss: 18.2364\n",
      "IoU = \n",
      "0.4765922028347998\n",
      "mAP@50 = \n",
      "69.08120300360264\n",
      "Validation - BBox Loss: 19.2903, Label Loss: 0.0000, Total Loss: 19.2903\n",
      "Epoch 37/40, Loss: 18.0962\n",
      "IoU = \n",
      "0.4971833806641255\n",
      "mAP@50 = \n",
      "70.84798568911673\n",
      "Validation - BBox Loss: 18.1581, Label Loss: 0.0000, Total Loss: 18.1581\n",
      "Validation loss improved from 18.2441 to 18.1581. Saving model...\n",
      "Epoch 38/40, Loss: 17.8412\n",
      "IoU = \n",
      "0.4920725426455637\n",
      "mAP@50 = \n",
      "68.02113339229419\n",
      "Validation - BBox Loss: 18.7977, Label Loss: 0.0000, Total Loss: 18.7977\n",
      "Epoch 39/40, Loss: 17.9825\n",
      "IoU = \n",
      "0.5131614116039424\n",
      "mAP@50 = \n",
      "70.4946291520139\n",
      "Validation - BBox Loss: 17.7415, Label Loss: 0.0000, Total Loss: 17.7415\n",
      "Validation loss improved from 18.1581 to 17.7415. Saving model...\n",
      "Epoch 40/40, Loss: 17.9179\n",
      "IoU = \n",
      "0.5136733189685511\n",
      "mAP@50 = \n",
      "70.67130742056531\n",
      "Validation - BBox Loss: 17.6385, Label Loss: 0.0000, Total Loss: 17.6385\n",
      "Validation loss improved from 17.7415 to 17.6385. Saving model...\n",
      "Training complete. Best model saved as:\n",
      "mobilenetv2_0.001_32.pth\n",
      "Epoch 1/40, Loss: 19.3704\n",
      "IoU = \n",
      "0.4975990464074978\n",
      "mAP@50 = \n",
      "69.96459434635968\n",
      "Validation - BBox Loss: 18.4224, Label Loss: 0.0000, Total Loss: 18.4224\n",
      "Validation loss improved from inf to 18.4224. Saving model...\n",
      "Epoch 2/40, Loss: 19.3890\n",
      "IoU = \n",
      "0.4839182699933424\n",
      "mAP@50 = \n",
      "70.3179508834625\n",
      "Validation - BBox Loss: 19.2295, Label Loss: 0.0000, Total Loss: 19.2295\n",
      "Epoch 3/40, Loss: 18.8161\n",
      "IoU = \n",
      "0.46349738219789105\n",
      "mAP@50 = \n",
      "65.01760282692024\n",
      "Validation - BBox Loss: 19.6078, Label Loss: 0.0000, Total Loss: 19.6078\n",
      "Epoch 4/40, Loss: 18.8393\n",
      "IoU = \n",
      "0.45049006703997513\n",
      "mAP@50 = \n",
      "63.42749840995757\n",
      "Validation - BBox Loss: 19.7024, Label Loss: 0.0000, Total Loss: 19.7024\n",
      "Epoch 5/40, Loss: 18.5338\n",
      "IoU = \n",
      "0.49418834320601907\n",
      "mAP@50 = \n",
      "69.61123780925686\n",
      "Validation - BBox Loss: 19.2899, Label Loss: 0.0000, Total Loss: 19.2899\n",
      "Epoch 6/40, Loss: 18.4804\n",
      "IoU = \n",
      "0.4973529085896205\n",
      "mAP@50 = \n",
      "67.84445512374278\n",
      "Validation - BBox Loss: 18.2512, Label Loss: 0.0000, Total Loss: 18.2512\n",
      "Validation loss improved from 18.4224 to 18.2512. Saving model...\n",
      "Epoch 7/40, Loss: 18.3553\n",
      "IoU = \n",
      "0.5087059541998674\n",
      "mAP@50 = \n",
      "71.90805530042518\n",
      "Validation - BBox Loss: 18.3550, Label Loss: 0.0000, Total Loss: 18.3550\n",
      "Epoch 8/40, Loss: 18.1738\n",
      "IoU = \n",
      "0.5268907753784413\n",
      "mAP@50 = \n",
      "73.85151625449066\n",
      "Validation - BBox Loss: 17.2534, Label Loss: 0.0000, Total Loss: 17.2534\n",
      "Validation loss improved from 18.2512 to 17.2534. Saving model...\n",
      "Epoch 9/40, Loss: 18.0371\n",
      "IoU = \n",
      "0.5009692393720698\n",
      "mAP@50 = \n",
      "67.84445512374278\n",
      "Validation - BBox Loss: 17.9590, Label Loss: 0.0000, Total Loss: 17.9590\n",
      "Epoch 10/40, Loss: 17.8689\n",
      "IoU = \n",
      "0.5076876912552324\n",
      "mAP@50 = \n",
      "74.91158586579911\n",
      "Validation - BBox Loss: 18.4406, Label Loss: 0.0000, Total Loss: 18.4406\n",
      "Epoch 11/40, Loss: 17.7038\n",
      "IoU = \n",
      "0.5193208685904156\n",
      "mAP@50 = \n",
      "72.79144664318221\n",
      "Validation - BBox Loss: 17.5958, Label Loss: 0.0000, Total Loss: 17.5958\n",
      "Epoch 12/40, Loss: 17.6946\n",
      "IoU = \n",
      "0.5005669863373181\n",
      "mAP@50 = \n",
      "70.3179508834625\n",
      "Validation - BBox Loss: 17.8876, Label Loss: 0.0000, Total Loss: 17.8876\n",
      "Epoch 13/40, Loss: 17.4716\n",
      "IoU = \n",
      "0.5127492952982232\n",
      "mAP@50 = \n",
      "72.26141183752799\n",
      "Validation - BBox Loss: 17.9191, Label Loss: 0.0000, Total Loss: 17.9191\n",
      "Epoch 14/40, Loss: 17.4925\n",
      "IoU = \n",
      "0.5278556254592004\n",
      "mAP@50 = \n",
      "73.67483798593925\n",
      "Validation - BBox Loss: 17.4415, Label Loss: 0.0000, Total Loss: 17.4415\n",
      "Epoch 15/40, Loss: 17.8205\n",
      "IoU = \n",
      "0.5340846354329413\n",
      "mAP@50 = \n",
      "73.67483798593925\n",
      "Validation - BBox Loss: 17.4640, Label Loss: 0.0000, Total Loss: 17.4640\n",
      "Epoch 16/40, Loss: 17.5767\n",
      "IoU = \n",
      "0.5259301126038848\n",
      "mAP@50 = \n",
      "74.38155106014489\n",
      "Validation - BBox Loss: 17.2739, Label Loss: 0.0000, Total Loss: 17.2739\n",
      "Epoch 17/40, Loss: 17.3809\n",
      "IoU = \n",
      "0.5155023908186638\n",
      "mAP@50 = \n",
      "72.26141183752799\n",
      "Validation - BBox Loss: 17.7175, Label Loss: 0.0000, Total Loss: 17.7175\n",
      "Epoch 18/40, Loss: 17.6244\n",
      "IoU = \n",
      "0.5156934238672454\n",
      "mAP@50 = \n",
      "74.02819452304207\n",
      "Validation - BBox Loss: 17.8540, Label Loss: 0.0000, Total Loss: 17.8540\n",
      "Epoch 19/40, Loss: 17.4274\n",
      "IoU = \n",
      "0.5362827963238522\n",
      "mAP@50 = \n",
      "73.85151625449066\n",
      "Validation - BBox Loss: 17.2156, Label Loss: 0.0000, Total Loss: 17.2156\n",
      "Validation loss improved from 17.2534 to 17.2156. Saving model...\n",
      "Epoch 20/40, Loss: 17.1454\n",
      "IoU = \n",
      "0.5095681694843033\n",
      "mAP@50 = \n",
      "71.55469876332235\n",
      "Validation - BBox Loss: 17.9179, Label Loss: 0.0000, Total Loss: 17.9179\n",
      "Epoch 21/40, Loss: 17.2035\n",
      "IoU = \n",
      "0.48883864615278527\n",
      "mAP@50 = \n",
      "72.4380901060794\n",
      "Validation - BBox Loss: 18.4069, Label Loss: 0.0000, Total Loss: 18.4069\n",
      "Epoch 22/40, Loss: 17.2448\n",
      "IoU = \n",
      "0.5349506651044761\n",
      "mAP@50 = \n",
      "75.79497720855615\n",
      "Validation - BBox Loss: 17.1185, Label Loss: 0.0000, Total Loss: 17.1185\n",
      "Validation loss improved from 17.2156 to 17.1185. Saving model...\n",
      "Epoch 23/40, Loss: 17.3479\n",
      "IoU = \n",
      "0.5372758367589954\n",
      "mAP@50 = \n",
      "73.14480318028502\n",
      "Validation - BBox Loss: 17.3257, Label Loss: 0.0000, Total Loss: 17.3257\n",
      "Epoch 24/40, Loss: 17.1583\n",
      "IoU = \n",
      "0.5309261625359911\n",
      "mAP@50 = \n",
      "76.50169028276179\n",
      "Validation - BBox Loss: 17.3371, Label Loss: 0.0000, Total Loss: 17.3371\n",
      "Epoch 25/40, Loss: 17.1278\n",
      "IoU = \n",
      "0.5056346267403775\n",
      "mAP@50 = \n",
      "73.67483798593925\n",
      "Validation - BBox Loss: 17.5918, Label Loss: 0.0000, Total Loss: 17.5918\n",
      "Epoch 26/40, Loss: 16.9957\n",
      "IoU = \n",
      "0.47068904067349354\n",
      "mAP@50 = \n",
      "69.08120300360264\n",
      "Validation - BBox Loss: 18.4672, Label Loss: 0.0000, Total Loss: 18.4672\n",
      "Epoch 27/40, Loss: 17.1083\n",
      "IoU = \n",
      "0.517674970880312\n",
      "mAP@50 = \n",
      "72.6147683746308\n",
      "Validation - BBox Loss: 17.8765, Label Loss: 0.0000, Total Loss: 17.8765\n",
      "Epoch 28/40, Loss: 16.8981\n",
      "IoU = \n",
      "0.5191059633793289\n",
      "mAP@50 = \n",
      "71.90805530042518\n",
      "Validation - BBox Loss: 17.3654, Label Loss: 0.0000, Total Loss: 17.3654\n",
      "Epoch 29/40, Loss: 16.9641\n",
      "IoU = \n",
      "0.5283024103920446\n",
      "mAP@50 = \n",
      "71.73137703187376\n",
      "Validation - BBox Loss: 17.3561, Label Loss: 0.0000, Total Loss: 17.3561\n",
      "Epoch 30/40, Loss: 16.8489\n",
      "IoU = \n",
      "0.527299800246597\n",
      "mAP@50 = \n",
      "73.85151625449066\n",
      "Validation - BBox Loss: 17.5074, Label Loss: 0.0000, Total Loss: 17.5074\n",
      "Epoch 31/40, Loss: 16.6990\n",
      "IoU = \n",
      "0.5200493868564621\n",
      "mAP@50 = \n",
      "72.6147683746308\n",
      "Validation - BBox Loss: 17.3481, Label Loss: 0.0000, Total Loss: 17.3481\n",
      "Epoch 32/40, Loss: 16.8492\n",
      "IoU = \n",
      "0.5485528424791926\n",
      "mAP@50 = \n",
      "74.02819452304207\n",
      "Validation - BBox Loss: 16.6989, Label Loss: 0.0000, Total Loss: 16.6989\n",
      "Validation loss improved from 17.1185 to 16.6989. Saving model...\n",
      "Epoch 33/40, Loss: 16.7002\n",
      "IoU = \n",
      "0.5452871421375065\n",
      "mAP@50 = \n",
      "74.91158586579911\n",
      "Validation - BBox Loss: 16.9701, Label Loss: 0.0000, Total Loss: 16.9701\n",
      "Epoch 34/40, Loss: 16.6355\n",
      "IoU = \n",
      "0.5455162081622285\n",
      "mAP@50 = \n",
      "72.08473356897657\n",
      "Validation - BBox Loss: 16.6999, Label Loss: 0.0000, Total Loss: 16.6999\n",
      "Epoch 35/40, Loss: 16.7829\n",
      "IoU = \n",
      "0.5152821197487536\n",
      "mAP@50 = \n",
      "70.84798568911673\n",
      "Validation - BBox Loss: 17.5969, Label Loss: 0.0000, Total Loss: 17.5969\n",
      "Epoch 36/40, Loss: 16.8339\n",
      "IoU = \n",
      "0.4456713592373213\n",
      "mAP@50 = \n",
      "66.60770724388291\n",
      "Validation - BBox Loss: 18.9681, Label Loss: 0.0000, Total Loss: 18.9681\n",
      "Epoch 37/40, Loss: 16.9008\n",
      "IoU = \n",
      "0.541278344722452\n",
      "mAP@50 = \n",
      "72.6147683746308\n",
      "Validation - BBox Loss: 16.8602, Label Loss: 0.0000, Total Loss: 16.8602\n",
      "Epoch 38/40, Loss: 16.6352\n",
      "IoU = \n",
      "0.521903763554806\n",
      "mAP@50 = \n",
      "69.96459434635968\n",
      "Validation - BBox Loss: 18.2102, Label Loss: 0.0000, Total Loss: 18.2102\n",
      "Epoch 39/40, Loss: 16.6763\n",
      "IoU = \n",
      "0.5388695215081855\n",
      "mAP@50 = \n",
      "73.85151625449066\n",
      "Validation - BBox Loss: 16.8336, Label Loss: 0.0000, Total Loss: 16.8336\n",
      "Epoch 40/40, Loss: 16.6431\n",
      "IoU = \n",
      "0.5252297798747751\n",
      "mAP@50 = \n",
      "73.85151625449066\n",
      "Validation - BBox Loss: 17.3419, Label Loss: 0.0000, Total Loss: 17.3419\n",
      "Training complete. Best model saved as:\n",
      "mobilenetv2_0.001_16.pth\n",
      "Epoch 1/40, Loss: 16.5687\n",
      "IoU = \n",
      "0.560178915837929\n",
      "mAP@50 = \n",
      "73.49815971738785\n",
      "Validation - BBox Loss: 15.4766, Label Loss: 0.0000, Total Loss: 15.4766\n",
      "Validation loss improved from inf to 15.4766. Saving model...\n",
      "Epoch 2/40, Loss: 16.3380\n",
      "IoU = \n",
      "0.5648569628940204\n",
      "mAP@50 = \n",
      "71.90805530042518\n",
      "Validation - BBox Loss: 15.3641, Label Loss: 0.0000, Total Loss: 15.3641\n",
      "Validation loss improved from 15.4766 to 15.3641. Saving model...\n",
      "Epoch 3/40, Loss: 16.3198\n",
      "IoU = \n",
      "0.5664170841326898\n",
      "mAP@50 = \n",
      "73.14480318028502\n",
      "Validation - BBox Loss: 15.4401, Label Loss: 0.0000, Total Loss: 15.4401\n",
      "Epoch 4/40, Loss: 16.2466\n",
      "IoU = \n",
      "0.5538106384852082\n",
      "mAP@50 = \n",
      "72.96812491173363\n",
      "Validation - BBox Loss: 15.5669, Label Loss: 0.0000, Total Loss: 15.5669\n",
      "Epoch 5/40, Loss: 16.2698\n",
      "IoU = \n",
      "0.5591696197327058\n",
      "mAP@50 = \n",
      "73.67483798593925\n",
      "Validation - BBox Loss: 15.6727, Label Loss: 0.0000, Total Loss: 15.6727\n",
      "Epoch 6/40, Loss: 16.1425\n",
      "IoU = \n",
      "0.5686332618751047\n",
      "mAP@50 = \n",
      "71.90805530042518\n",
      "Validation - BBox Loss: 15.2852, Label Loss: 0.0000, Total Loss: 15.2852\n",
      "Validation loss improved from 15.3641 to 15.2852. Saving model...\n",
      "Epoch 7/40, Loss: 16.1965\n",
      "IoU = \n",
      "0.5244038498921562\n",
      "mAP@50 = \n",
      "72.79144664318221\n",
      "Validation - BBox Loss: 16.3538, Label Loss: 0.0000, Total Loss: 16.3538\n",
      "Epoch 8/40, Loss: 16.1690\n",
      "IoU = \n",
      "0.5393998529959483\n",
      "mAP@50 = \n",
      "70.84798568911673\n",
      "Validation - BBox Loss: 15.8694, Label Loss: 0.0000, Total Loss: 15.8694\n",
      "Epoch 9/40, Loss: 16.1390\n",
      "IoU = \n",
      "0.5714733323498625\n",
      "mAP@50 = \n",
      "73.67483798593925\n",
      "Validation - BBox Loss: 15.3751, Label Loss: 0.0000, Total Loss: 15.3751\n",
      "Epoch 10/40, Loss: 16.3288\n",
      "IoU = \n",
      "0.5562103095212655\n",
      "mAP@50 = \n",
      "73.49815971738785\n",
      "Validation - BBox Loss: 15.8816, Label Loss: 0.0000, Total Loss: 15.8816\n",
      "Epoch 11/40, Loss: 16.2132\n",
      "IoU = \n",
      "0.5187179799884386\n",
      "mAP@50 = \n",
      "69.78791607780828\n",
      "Validation - BBox Loss: 16.8134, Label Loss: 0.0000, Total Loss: 16.8134\n",
      "Epoch 12/40, Loss: 16.2718\n",
      "IoU = \n",
      "0.5649879704992198\n",
      "mAP@50 = \n",
      "72.96812491173363\n",
      "Validation - BBox Loss: 15.7085, Label Loss: 0.0000, Total Loss: 15.7085\n",
      "Epoch 13/40, Loss: 15.8651\n",
      "IoU = \n",
      "0.5648094575647298\n",
      "mAP@50 = \n",
      "73.32148144883644\n",
      "Validation - BBox Loss: 15.5113, Label Loss: 0.0000, Total Loss: 15.5113\n",
      "Epoch 14/40, Loss: 15.9271\n",
      "IoU = \n",
      "0.5672069628212466\n",
      "mAP@50 = \n",
      "72.08473356897657\n",
      "Validation - BBox Loss: 15.4251, Label Loss: 0.0000, Total Loss: 15.4251\n",
      "Epoch 15/40, Loss: 15.9983\n",
      "IoU = \n",
      "0.5305611530341275\n",
      "mAP@50 = \n",
      "71.90805530042518\n",
      "Validation - BBox Loss: 15.7913, Label Loss: 0.0000, Total Loss: 15.7913\n",
      "Epoch 16/40, Loss: 15.8608\n",
      "IoU = \n",
      "0.5439858504627788\n",
      "mAP@50 = \n",
      "72.08473356897657\n",
      "Validation - BBox Loss: 15.8154, Label Loss: 0.0000, Total Loss: 15.8154\n",
      "Epoch 17/40, Loss: 15.8949\n",
      "IoU = \n",
      "0.5544941802003154\n",
      "mAP@50 = \n",
      "75.44162067145334\n",
      "Validation - BBox Loss: 15.6935, Label Loss: 0.0000, Total Loss: 15.6935\n",
      "Epoch 18/40, Loss: 15.8464\n",
      "IoU = \n",
      "0.572677166071184\n",
      "mAP@50 = \n",
      "74.38155106014489\n",
      "Validation - BBox Loss: 15.2609, Label Loss: 0.0000, Total Loss: 15.2609\n",
      "Validation loss improved from 15.2852 to 15.2609. Saving model...\n",
      "Epoch 19/40, Loss: 15.8156\n",
      "IoU = \n",
      "0.5580023147746618\n",
      "mAP@50 = \n",
      "72.96812491173363\n",
      "Validation - BBox Loss: 15.6359, Label Loss: 0.0000, Total Loss: 15.6359\n",
      "Epoch 20/40, Loss: 15.8874\n",
      "IoU = \n",
      "0.5588593889176335\n",
      "mAP@50 = \n",
      "72.96812491173363\n",
      "Validation - BBox Loss: 15.4796, Label Loss: 0.0000, Total Loss: 15.4796\n",
      "Epoch 21/40, Loss: 15.8089\n",
      "IoU = \n",
      "0.5555706101810303\n",
      "mAP@50 = \n",
      "73.49815971738785\n",
      "Validation - BBox Loss: 15.7300, Label Loss: 0.0000, Total Loss: 15.7300\n",
      "Epoch 22/40, Loss: 15.8639\n",
      "IoU = \n",
      "0.5466321985563921\n",
      "mAP@50 = \n",
      "74.02819452304207\n",
      "Validation - BBox Loss: 15.9457, Label Loss: 0.0000, Total Loss: 15.9457\n",
      "Epoch 23/40, Loss: 15.7898\n",
      "IoU = \n",
      "0.5622781854708656\n",
      "mAP@50 = \n",
      "72.08473356897657\n",
      "Validation - BBox Loss: 15.4690, Label Loss: 0.0000, Total Loss: 15.4690\n",
      "Epoch 24/40, Loss: 15.8626\n",
      "IoU = \n",
      "0.5718753636599101\n",
      "mAP@50 = \n",
      "74.91158586579911\n",
      "Validation - BBox Loss: 15.4110, Label Loss: 0.0000, Total Loss: 15.4110\n",
      "Epoch 25/40, Loss: 15.9806\n",
      "IoU = \n",
      "0.5646168922103757\n",
      "mAP@50 = \n",
      "72.96812491173363\n",
      "Validation - BBox Loss: 15.3747, Label Loss: 0.0000, Total Loss: 15.3747\n",
      "Epoch 26/40, Loss: 15.8029\n",
      "IoU = \n",
      "0.56761761840191\n",
      "mAP@50 = \n",
      "72.4380901060794\n",
      "Validation - BBox Loss: 15.3377, Label Loss: 0.0000, Total Loss: 15.3377\n",
      "Epoch 27/40, Loss: 15.7591\n",
      "IoU = \n",
      "0.5650115049914737\n",
      "mAP@50 = \n",
      "73.14480318028502\n",
      "Validation - BBox Loss: 15.6776, Label Loss: 0.0000, Total Loss: 15.6776\n",
      "Epoch 28/40, Loss: 15.8004\n",
      "IoU = \n",
      "0.564257545056901\n",
      "mAP@50 = \n",
      "71.55469876332235\n",
      "Validation - BBox Loss: 15.5132, Label Loss: 0.0000, Total Loss: 15.5132\n",
      "Epoch 29/40, Loss: 15.8288\n",
      "IoU = \n",
      "0.5660524611328828\n",
      "mAP@50 = \n",
      "74.5582293286963\n",
      "Validation - BBox Loss: 15.4403, Label Loss: 0.0000, Total Loss: 15.4403\n",
      "Epoch 30/40, Loss: 15.7733\n",
      "IoU = \n",
      "0.5645518793462029\n",
      "mAP@50 = \n",
      "73.32148144883644\n",
      "Validation - BBox Loss: 15.5451, Label Loss: 0.0000, Total Loss: 15.5451\n",
      "Epoch 31/40, Loss: 15.7605\n",
      "IoU = \n",
      "0.5608998591032178\n",
      "mAP@50 = \n",
      "74.02819452304207\n",
      "Validation - BBox Loss: 15.7746, Label Loss: 0.0000, Total Loss: 15.7746\n",
      "Epoch 32/40, Loss: 15.9035\n",
      "IoU = \n",
      "0.520510432047131\n",
      "mAP@50 = \n",
      "72.08473356897657\n",
      "Validation - BBox Loss: 16.8103, Label Loss: 0.0000, Total Loss: 16.8103\n",
      "Epoch 33/40, Loss: 15.7430\n",
      "IoU = \n",
      "0.5631854878557524\n",
      "mAP@50 = \n",
      "72.96812491173363\n",
      "Validation - BBox Loss: 15.6003, Label Loss: 0.0000, Total Loss: 15.6003\n",
      "Epoch 34/40, Loss: 15.7140\n",
      "IoU = \n",
      "0.5640373445252144\n",
      "mAP@50 = \n",
      "73.85151625449066\n",
      "Validation - BBox Loss: 15.7079, Label Loss: 0.0000, Total Loss: 15.7079\n",
      "Epoch 35/40, Loss: 15.6762\n",
      "IoU = \n",
      "0.559952993113128\n",
      "mAP@50 = \n",
      "74.02819452304207\n",
      "Validation - BBox Loss: 15.5690, Label Loss: 0.0000, Total Loss: 15.5690\n",
      "Epoch 36/40, Loss: 15.6679\n",
      "IoU = \n",
      "0.5457501929136513\n",
      "mAP@50 = \n",
      "72.08473356897657\n",
      "Validation - BBox Loss: 16.3522, Label Loss: 0.0000, Total Loss: 16.3522\n",
      "Epoch 37/40, Loss: 15.7050\n",
      "IoU = \n",
      "0.5526465631156745\n",
      "mAP@50 = \n",
      "74.20487279159347\n",
      "Validation - BBox Loss: 15.8103, Label Loss: 0.0000, Total Loss: 15.8103\n",
      "Epoch 38/40, Loss: 15.8280\n",
      "IoU = \n",
      "0.5573141143559363\n",
      "mAP@50 = \n",
      "72.08473356897657\n",
      "Validation - BBox Loss: 15.8035, Label Loss: 0.0000, Total Loss: 15.8035\n",
      "Epoch 39/40, Loss: 15.7211\n",
      "IoU = \n",
      "0.5613372374339154\n",
      "mAP@50 = \n",
      "73.67483798593925\n",
      "Validation - BBox Loss: 15.6221, Label Loss: 0.0000, Total Loss: 15.6221\n",
      "Epoch 40/40, Loss: 15.6968\n",
      "IoU = \n",
      "0.5528967139803124\n",
      "mAP@50 = \n",
      "72.08473356897657\n",
      "Validation - BBox Loss: 15.9868, Label Loss: 0.0000, Total Loss: 15.9868\n",
      "Training complete. Best model saved as:\n",
      "mobilenetv2_0.001_32.pth\n",
      "100%|██████████| 3/3 [39:10<00:00, 783.55s/trial, best loss: 15.26085376739502]\n"
     ]
    }
   ],
   "source": [
    "#batch_size = 16\n",
    "#target_size = (224, 224)\n",
    "#train_loader, val_loader = get_dataloaders(base_adress, annotations, batch_size, target_size)\n",
    "#train_model(mobilenetfacedetector, train_loader, val_loader, num_epochs=2)\n",
    "\n",
    "hyperopt_out = [['score', 'arch', 'learning_rate', 'batch_size']]\n",
    "\n",
    "def min_func(params):\n",
    "    params = {'model': params['model'], 'arch': params['arch'],\n",
    "              'learning_rate': float(params['learning_rate']),\n",
    "              'batch_size': int(params['batch_size'])}\n",
    "              #'dropout': float(params['dropout'])}\n",
    "    target_size = (224, 224)\n",
    "    train_loader, val_loader = get_dataloaders(base_adress, annotations, params['batch_size'], target_size)\n",
    "    score = train_model(train_loader, val_loader, num_epochs=40, **params)\n",
    "    hyperopt_out.append([score, params['arch'],\n",
    "                         params['learning_rate'], params['batch_size']])\n",
    "\n",
    "    return score\n",
    "\n",
    "curr_model = MobileNetFaceDetector().to(device)\n",
    "mobilenetv2space={'model': curr_model,\n",
    "                  'arch': 'mobilenetv2',\n",
    "                  #'learning_rate': hp.loguniform('learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "                  'learning_rate': hp.choice('learning_rate', [1e-3]),\n",
    "                  'batch_size': hp.choice('batch_size', [16, 32, 64])}\n",
    "                  #'dropout' hp.loguniform('dropout', np.log(0.3), np.log(0.5))}\n",
    "\n",
    "best_params = fmin(fn=min_func, space=mobilenetv2space, algo=tpe.suggest, max_evals=3)\n",
    "\n",
    "with open('hyperopt_out.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(hyperopt_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c09b85d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T15:08:55.527772Z",
     "iopub.status.busy": "2025-04-13T15:08:55.527459Z",
     "iopub.status.idle": "2025-04-13T15:08:55.533779Z",
     "shell.execute_reply": "2025-04-13T15:08:55.533101Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.109627,
     "end_time": "2025-04-13T15:08:55.534998",
     "exception": false,
     "start_time": "2025-04-13T15:08:55.425371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FDDBTestDataset(Dataset):\n",
    "    def __init__(self, img_dir, target_size=(224, 224)):\n",
    "        self.img_dir = img_dir\n",
    "        self.target_size = target_size\n",
    "        self.transform = transforms.Compose([\n",
    "                                            transforms.ToTensor(),\n",
    "                                            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                                            ])\n",
    "        self.image_files = []\n",
    "\n",
    "        for img in os.listdir(img_dir):\n",
    "            self.image_files.append(img)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_dir + '/' + self.image_files[idx]\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
    "        image_resized = cv2.resize(image, self.target_size)\n",
    "        image_resized = self.transform(image_resized)\n",
    "\n",
    "        return image_resized, self.image_files[idx]\n",
    "\n",
    "# DataLoader preparation\n",
    "def get_test_dataloader(img_dir, batch_size=1, target_size=(224, 224)):\n",
    "    dataset = FDDBTestDataset(img_dir, target_size)\n",
    "    test_loader = DataLoader(dataset, batch_size=batch_size)#, collate_fn=collate_fn)\n",
    "\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7796c46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T15:08:55.738743Z",
     "iopub.status.busy": "2025-04-13T15:08:55.738422Z",
     "iopub.status.idle": "2025-04-13T15:08:55.742738Z",
     "shell.execute_reply": "2025-04-13T15:08:55.742054Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.106031,
     "end_time": "2025-04-13T15:08:55.743930",
     "exception": false,
     "start_time": "2025-04-13T15:08:55.637899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    predictions = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (image, image_name) in enumerate(test_loader):\n",
    "            image = image.to(device)\n",
    "\n",
    "            # get prediction\n",
    "            pbbox, plabel = model(image)\n",
    "            \n",
    "            # format prediction\n",
    "            preds = [{\"id\": image_name, \"boxes\": [pbbox], \"labels\": plabel}]\n",
    "            preds = normalize_boxes(preds)\n",
    "            predictions.append(preds)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b9865b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T15:08:55.947249Z",
     "iopub.status.busy": "2025-04-13T15:08:55.946955Z",
     "iopub.status.idle": "2025-04-13T15:10:16.156854Z",
     "shell.execute_reply": "2025-04-13T15:10:16.156131Z"
    },
    "papermill": {
     "duration": 80.312186,
     "end_time": "2025-04-13T15:10:16.158428",
     "exception": false,
     "start_time": "2025-04-13T15:08:55.846242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferencing on model: mobilenetv2_0001_16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-d503d9a2e139>:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  inf_model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferencing on model: mobilenetv2_0001_32\n"
     ]
    }
   ],
   "source": [
    "# evaluate - submission\n",
    "\n",
    "# test dataloader\n",
    "testset_file_path = '/kaggle/input/testset/testset'\n",
    "test_dataloader = get_test_dataloader(testset_file_path)\n",
    "\n",
    "# model inference\n",
    "for model_path in os.listdir('/kaggle/working'):\n",
    "    full_path = model_path.split('.')\n",
    "    model_id = ''.join(full_path[0:len(full_path)-1])\n",
    "    if full_path[-1] == 'pth':\n",
    "        print('inferencing on model:', model_id)\n",
    "        inf_model = MobileNetFaceDetector()\n",
    "        inf_model.load_state_dict(torch.load(model_path))\n",
    "        inf_model.to(device)\n",
    "        predictions = inference(inf_model, test_dataloader, device)\n",
    "        \n",
    "        # create submission\n",
    "        data = [['image_id', 'x1', 'y1', 'x2', 'y2']]\n",
    "        \n",
    "        for i in range(len(predictions)):\n",
    "            img_id = predictions[i][0]['id'][0]\n",
    "            image = cv2.imread(testset_file_path + '/' + img_id)\n",
    "            pbbox = predictions[i][0]['boxes'].cpu().tolist()[0][0]\n",
    "        \n",
    "            # scale predictions\n",
    "            h, w = (224, 224)\n",
    "            target_h, target_w, _ = image.shape\n",
    "            scale_x = target_w / w\n",
    "            scale_y = target_h / h\n",
    "            x_min = int(pbbox[0] * scale_x)\n",
    "            y_min = int(pbbox[1] * scale_y)\n",
    "            x_max = int(pbbox[2] * scale_x)\n",
    "            y_max = int(pbbox[3] * scale_y)\n",
    "            pbbox = [x_min, y_min, x_max, y_max]\n",
    "            formatted_img_id = \"\\'\" + img_id + \"\\'\"\n",
    "            data.append([formatted_img_id, pbbox[0], pbbox[1], pbbox[2], pbbox[3]])\n",
    "        with open(f'od_out_{model_id}.csv', 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ae17c4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T15:10:16.362824Z",
     "iopub.status.busy": "2025-04-13T15:10:16.362506Z",
     "iopub.status.idle": "2025-04-13T15:10:23.972908Z",
     "shell.execute_reply": "2025-04-13T15:10:23.971972Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 7.714007,
     "end_time": "2025-04-13T15:10:23.974424",
     "exception": false,
     "start_time": "2025-04-13T15:10:16.260417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (1.17.0)\r\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.26.4)\r\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->onnx) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->onnx) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->onnx) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->onnx) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->onnx) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->onnx) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.20->onnx) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.20->onnx) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.20->onnx) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.20->onnx) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.20->onnx) (2024.2.0)\r\n",
      "Collecting onnxscript\r\n",
      "  Downloading onnxscript-0.2.4-py3-none-any.whl.metadata (15 kB)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnxscript) (1.26.4)\r\n",
      "Requirement already satisfied: onnx>=1.16 in /usr/local/lib/python3.10/dist-packages (from onnxscript) (1.17.0)\r\n",
      "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.10/dist-packages (from onnxscript) (4.12.2)\r\n",
      "Requirement already satisfied: ml_dtypes in /usr/local/lib/python3.10/dist-packages (from onnxscript) (0.4.1)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxscript) (24.2)\r\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.16->onnxscript) (3.20.3)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->onnxscript) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->onnxscript) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->onnxscript) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->onnxscript) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->onnxscript) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->onnxscript) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->onnxscript) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->onnxscript) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->onnxscript) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->onnxscript) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->onnxscript) (2024.2.0)\r\n",
      "Downloading onnxscript-0.2.4-py3-none-any.whl (705 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m705.4/705.4 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: onnxscript\r\n",
      "Successfully installed onnxscript-0.2.4\r\n"
     ]
    }
   ],
   "source": [
    "!pip install onnx\n",
    "!pip install onnxscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d37beb9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T15:10:24.179795Z",
     "iopub.status.busy": "2025-04-13T15:10:24.179466Z",
     "iopub.status.idle": "2025-04-13T15:10:26.124727Z",
     "shell.execute_reply": "2025-04-13T15:10:26.123725Z"
    },
    "papermill": {
     "duration": 2.048238,
     "end_time": "2025-04-13T15:10:26.126011",
     "exception": false,
     "start_time": "2025-04-13T15:10:24.077773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deploying to onnx: mobilenetv2_0001_16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-d3eba58bdb50>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(PATH))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Model successfully exported to ONNX!\n",
      "deploying to onnx: mobilenetv2_0001_32\n",
      "...Model successfully exported to ONNX!\n"
     ]
    }
   ],
   "source": [
    "# Model class must be defined somewhere\n",
    "for PATH in os.listdir('/kaggle/working'):\n",
    "    full_path = PATH.split('.')\n",
    "    model_id = ''.join(full_path[0:len(full_path)-1])\n",
    "    if full_path[-1] == 'pth':\n",
    "        print('deploying to onnx:', model_id)\n",
    "        model = MobileNetFaceDetector().to(device)\n",
    "        model.load_state_dict(torch.load(PATH))\n",
    "        model.eval()\n",
    "        dummy_input = torch.randn(1, 3, 224, 224).to(device)  # Adjust shape based on your model's input size\n",
    "        \n",
    "        # Export the model to ONNX\n",
    "        torch.onnx.export(\n",
    "            model,  # The loaded PyTorch model\n",
    "            dummy_input,  # Example input tensor\n",
    "            \"model.onnx\",  # Output ONNX file name\n",
    "            export_params=True,  # Store trained parameters\n",
    "            opset_version=13,  # ONNX version (adjust as needed)\n",
    "            do_constant_folding=True,  # Optimize by folding constants\n",
    "            input_names=[\"input\"],  # Naming input tensor\n",
    "            output_names=[\"output\"],  # Naming output tensor\n",
    "            dynamic_axes=None \n",
    "        )\n",
    "        \n",
    "        print(\"...Model successfully exported to ONNX!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11362930,
     "datasetId": 6836738,
     "sourceId": 10984842,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 11759492,
     "datasetId": 7089690,
     "sourceId": 11333711,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2465.871723,
   "end_time": "2025-04-13T15:10:29.152046",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-13T14:29:23.280323",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

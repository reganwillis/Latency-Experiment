{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03739957",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-14T00:07:16.557717Z",
     "iopub.status.busy": "2025-04-14T00:07:16.557421Z",
     "iopub.status.idle": "2025-04-14T00:07:28.882726Z",
     "shell.execute_reply": "2025-04-14T00:07:28.881477Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 12.333621,
     "end_time": "2025-04-14T00:07:28.884646",
     "exception": false,
     "start_time": "2025-04-14T00:07:16.551025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from torchmetrics.detection import IntersectionOverUnion\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import shutil\n",
    "from torchsummary import summary\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e0b2cdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T00:07:28.898020Z",
     "iopub.status.busy": "2025-04-14T00:07:28.897644Z",
     "iopub.status.idle": "2025-04-14T00:07:28.951085Z",
     "shell.execute_reply": "2025-04-14T00:07:28.950186Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.061198,
     "end_time": "2025-04-14T00:07:28.952574",
     "exception": false,
     "start_time": "2025-04-14T00:07:28.891376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8ae350c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T00:07:28.963155Z",
     "iopub.status.busy": "2025-04-14T00:07:28.962937Z",
     "iopub.status.idle": "2025-04-14T00:07:29.698350Z",
     "shell.execute_reply": "2025-04-14T00:07:29.697471Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.74201,
     "end_time": "2025-04-14T00:07:29.699621",
     "exception": false,
     "start_time": "2025-04-14T00:07:28.957611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /kaggle/input/dataset-face-detection-for-edge-computing-class\n",
      "Path to dataset files: /kaggle/input/testset\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"icaslab/dataset-face-detection-for-edge-computing-class\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"reganwillis/testset\")\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48d03ed6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T00:07:29.710774Z",
     "iopub.status.busy": "2025-04-14T00:07:29.710556Z",
     "iopub.status.idle": "2025-04-14T00:07:29.713676Z",
     "shell.execute_reply": "2025-04-14T00:07:29.713029Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.009943,
     "end_time": "2025-04-14T00:07:29.714845",
     "exception": false,
     "start_time": "2025-04-14T00:07:29.704902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Data base addresses\n",
    "base_adress = '/kaggle/input/dataset-face-detection-for-edge-computing-class/Dataset_FDDB/Dataset_FDDB/images'\n",
    "labels_adr = '/kaggle/input/dataset-face-detection-for-edge-computing-class/Dataset_FDDB/Dataset_FDDB/label.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "027ecad8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T00:07:29.725167Z",
     "iopub.status.busy": "2025-04-14T00:07:29.724964Z",
     "iopub.status.idle": "2025-04-14T00:07:29.756342Z",
     "shell.execute_reply": "2025-04-14T00:07:29.755732Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.037892,
     "end_time": "2025-04-14T00:07:29.757616",
     "exception": false,
     "start_time": "2025-04-14T00:07:29.719724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make the labels ready\n",
    "\n",
    "with open(labels_adr, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "annotations = []\n",
    "bboxes = []\n",
    "flag = False\n",
    "for line in lines:\n",
    "    if line.startswith('#'):\n",
    "      if flag:\n",
    "        annotations.append({'image':img_name, 'bboxes': bboxes})\n",
    "        bboxes = []\n",
    "      flag = True\n",
    "      img_name = line[2:]\n",
    "    else:\n",
    "      x_min, y_min, x_max, y_max = line.split()\n",
    "      bboxes.append([int(x_min), int(y_min), int(x_max), int(y_max)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2683911e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T00:07:29.767809Z",
     "iopub.status.busy": "2025-04-14T00:07:29.767600Z",
     "iopub.status.idle": "2025-04-14T00:07:29.774219Z",
     "shell.execute_reply": "2025-04-14T00:07:29.773640Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.013078,
     "end_time": "2025-04-14T00:07:29.775533",
     "exception": false,
     "start_time": "2025-04-14T00:07:29.762455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom Dataset Class for FDDB\n",
    "class FDDBDataset(Dataset):\n",
    "    def __init__(self, img_dir, annot_file, target_size=(224, 224), transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.target_size = target_size\n",
    "        self.transform = transform\n",
    "        self.data = self._parse_annotations(annot_file)\n",
    "\n",
    "    def _parse_annotations(self, annot_file):\n",
    "        \n",
    "        data = []\n",
    "        for el in annot_file:\n",
    "          img_path = os.path.join(self.img_dir, el['image'][:-1])\n",
    "          boxes = el['bboxes']\n",
    "          data.append((img_path, boxes))\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, boxes = self.data[idx]\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
    "\n",
    "        # Original dimensions\n",
    "        h, w, _ = image.shape\n",
    "\n",
    "        # Resize image\n",
    "        image_resized = cv2.resize(image, self.target_size)\n",
    "        target_h, target_w = self.target_size\n",
    "\n",
    "        # Scale bounding boxes\n",
    "        scale_x = target_w / w\n",
    "        scale_y = target_h / h\n",
    "        boxes_resized = []\n",
    "        for box in boxes:\n",
    "            x_min = int(box[0] * scale_x)\n",
    "            y_min = int(box[1] * scale_y)\n",
    "            x_max = int(box[2] * scale_x)\n",
    "            y_max = int(box[3] * scale_y)\n",
    "            boxes_resized.append([x_min, y_min, x_max, y_max])\n",
    "\n",
    "        # Convert to tensor\n",
    "        if self.transform:\n",
    "            image_resized = self.transform(image_resized)\n",
    "        else:\n",
    "            image_resized = transforms.ToTensor()(image_resized)\n",
    "\n",
    "        return image_resized, torch.tensor(boxes_resized, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1617519",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T00:07:29.786084Z",
     "iopub.status.busy": "2025-04-14T00:07:29.785890Z",
     "iopub.status.idle": "2025-04-14T00:07:29.790934Z",
     "shell.execute_reply": "2025-04-14T00:07:29.790344Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.011617,
     "end_time": "2025-04-14T00:07:29.792132",
     "exception": false,
     "start_time": "2025-04-14T00:07:29.780515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DataLoader preparation\n",
    "def get_dataloaders(img_dir, annot_file, batch_size=16, target_size=(224, 224), validation_split=0.2):\n",
    "\n",
    "    # Transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # Dataset\n",
    "    dataset = FDDBDataset(img_dir, annot_file, target_size, transform)\n",
    "\n",
    "    # Split dataset\n",
    "    val_size = int(len(dataset) * validation_split)\n",
    "    train_size = len(dataset) - val_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    # DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function to handle variable-length bounding box arrays.\n",
    "\n",
    "    :param batch: List of tuples (image, boxes).\n",
    "    :return: Tuple of images and targets.\n",
    "    \"\"\"\n",
    "    images = torch.stack([item[0] for item in batch])\n",
    "    targets = [item[1] for item in batch]\n",
    "    return images, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "553ea508",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-04-14T00:07:29.802708Z",
     "iopub.status.busy": "2025-04-14T00:07:29.802507Z",
     "iopub.status.idle": "2025-04-14T00:07:31.101055Z",
     "shell.execute_reply": "2025-04-14T00:07:31.100150Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 1.306038,
     "end_time": "2025-04-14T00:07:31.102984",
     "exception": false,
     "start_time": "2025-04-14T00:07:29.796946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 112, 112]             896\n",
      "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
      "             ReLU6-3         [-1, 32, 112, 112]               0\n",
      "            Conv2d-4         [-1, 32, 112, 112]             288\n",
      "       BatchNorm2d-5         [-1, 32, 112, 112]              64\n",
      "             ReLU6-6         [-1, 32, 112, 112]               0\n",
      "            Conv2d-7         [-1, 16, 112, 112]             512\n",
      "       BatchNorm2d-8         [-1, 16, 112, 112]              32\n",
      "            Conv2d-9         [-1, 96, 112, 112]           1,536\n",
      "      BatchNorm2d-10         [-1, 96, 112, 112]             192\n",
      "            ReLU6-11         [-1, 96, 112, 112]               0\n",
      "           Conv2d-12           [-1, 96, 56, 56]             864\n",
      "      BatchNorm2d-13           [-1, 96, 56, 56]             192\n",
      "            ReLU6-14           [-1, 96, 56, 56]               0\n",
      "           Conv2d-15           [-1, 24, 56, 56]           2,304\n",
      "      BatchNorm2d-16           [-1, 24, 56, 56]              48\n",
      "           Conv2d-17          [-1, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-18          [-1, 144, 56, 56]             288\n",
      "            ReLU6-19          [-1, 144, 56, 56]               0\n",
      "           Conv2d-20          [-1, 144, 56, 56]           1,296\n",
      "      BatchNorm2d-21          [-1, 144, 56, 56]             288\n",
      "            ReLU6-22          [-1, 144, 56, 56]               0\n",
      "           Conv2d-23           [-1, 24, 56, 56]           3,456\n",
      "      BatchNorm2d-24           [-1, 24, 56, 56]              48\n",
      "           Conv2d-25          [-1, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-26          [-1, 144, 56, 56]             288\n",
      "            ReLU6-27          [-1, 144, 56, 56]               0\n",
      "           Conv2d-28          [-1, 144, 28, 28]           1,296\n",
      "      BatchNorm2d-29          [-1, 144, 28, 28]             288\n",
      "            ReLU6-30          [-1, 144, 28, 28]               0\n",
      "           Conv2d-31           [-1, 32, 28, 28]           4,608\n",
      "      BatchNorm2d-32           [-1, 32, 28, 28]              64\n",
      "           Conv2d-33          [-1, 192, 28, 28]           6,144\n",
      "      BatchNorm2d-34          [-1, 192, 28, 28]             384\n",
      "            ReLU6-35          [-1, 192, 28, 28]               0\n",
      "           Conv2d-36          [-1, 192, 28, 28]           1,728\n",
      "      BatchNorm2d-37          [-1, 192, 28, 28]             384\n",
      "            ReLU6-38          [-1, 192, 28, 28]               0\n",
      "           Conv2d-39           [-1, 32, 28, 28]           6,144\n",
      "      BatchNorm2d-40           [-1, 32, 28, 28]              64\n",
      "           Conv2d-41          [-1, 192, 28, 28]           6,144\n",
      "      BatchNorm2d-42          [-1, 192, 28, 28]             384\n",
      "            ReLU6-43          [-1, 192, 28, 28]               0\n",
      "           Conv2d-44          [-1, 192, 28, 28]           1,728\n",
      "      BatchNorm2d-45          [-1, 192, 28, 28]             384\n",
      "            ReLU6-46          [-1, 192, 28, 28]               0\n",
      "           Conv2d-47           [-1, 32, 28, 28]           6,144\n",
      "      BatchNorm2d-48           [-1, 32, 28, 28]              64\n",
      "           Conv2d-49          [-1, 192, 28, 28]           6,144\n",
      "      BatchNorm2d-50          [-1, 192, 28, 28]             384\n",
      "            ReLU6-51          [-1, 192, 28, 28]               0\n",
      "           Conv2d-52          [-1, 192, 14, 14]           1,728\n",
      "      BatchNorm2d-53          [-1, 192, 14, 14]             384\n",
      "            ReLU6-54          [-1, 192, 14, 14]               0\n",
      "           Conv2d-55           [-1, 64, 14, 14]          12,288\n",
      "      BatchNorm2d-56           [-1, 64, 14, 14]             128\n",
      "           Conv2d-57          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-58          [-1, 384, 14, 14]             768\n",
      "            ReLU6-59          [-1, 384, 14, 14]               0\n",
      "           Conv2d-60          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-61          [-1, 384, 14, 14]             768\n",
      "            ReLU6-62          [-1, 384, 14, 14]               0\n",
      "           Conv2d-63           [-1, 64, 14, 14]          24,576\n",
      "      BatchNorm2d-64           [-1, 64, 14, 14]             128\n",
      "           Conv2d-65          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-66          [-1, 384, 14, 14]             768\n",
      "            ReLU6-67          [-1, 384, 14, 14]               0\n",
      "           Conv2d-68          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-69          [-1, 384, 14, 14]             768\n",
      "            ReLU6-70          [-1, 384, 14, 14]               0\n",
      "           Conv2d-71           [-1, 64, 14, 14]          24,576\n",
      "      BatchNorm2d-72           [-1, 64, 14, 14]             128\n",
      "           Conv2d-73          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-74          [-1, 384, 14, 14]             768\n",
      "            ReLU6-75          [-1, 384, 14, 14]               0\n",
      "           Conv2d-76          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-77          [-1, 384, 14, 14]             768\n",
      "            ReLU6-78          [-1, 384, 14, 14]               0\n",
      "           Conv2d-79           [-1, 64, 14, 14]          24,576\n",
      "      BatchNorm2d-80           [-1, 64, 14, 14]             128\n",
      "           Conv2d-81          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-82          [-1, 384, 14, 14]             768\n",
      "            ReLU6-83          [-1, 384, 14, 14]               0\n",
      "           Conv2d-84          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-85          [-1, 384, 14, 14]             768\n",
      "            ReLU6-86          [-1, 384, 14, 14]               0\n",
      "           Conv2d-87           [-1, 96, 14, 14]          36,864\n",
      "      BatchNorm2d-88           [-1, 96, 14, 14]             192\n",
      "           Conv2d-89          [-1, 576, 14, 14]          55,296\n",
      "      BatchNorm2d-90          [-1, 576, 14, 14]           1,152\n",
      "            ReLU6-91          [-1, 576, 14, 14]               0\n",
      "           Conv2d-92          [-1, 576, 14, 14]           5,184\n",
      "      BatchNorm2d-93          [-1, 576, 14, 14]           1,152\n",
      "            ReLU6-94          [-1, 576, 14, 14]               0\n",
      "           Conv2d-95           [-1, 96, 14, 14]          55,296\n",
      "      BatchNorm2d-96           [-1, 96, 14, 14]             192\n",
      "           Conv2d-97          [-1, 576, 14, 14]          55,296\n",
      "      BatchNorm2d-98          [-1, 576, 14, 14]           1,152\n",
      "            ReLU6-99          [-1, 576, 14, 14]               0\n",
      "          Conv2d-100          [-1, 576, 14, 14]           5,184\n",
      "     BatchNorm2d-101          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-102          [-1, 576, 14, 14]               0\n",
      "          Conv2d-103           [-1, 96, 14, 14]          55,296\n",
      "     BatchNorm2d-104           [-1, 96, 14, 14]             192\n",
      "          Conv2d-105          [-1, 576, 14, 14]          55,296\n",
      "     BatchNorm2d-106          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-107          [-1, 576, 14, 14]               0\n",
      "          Conv2d-108            [-1, 576, 7, 7]           5,184\n",
      "     BatchNorm2d-109            [-1, 576, 7, 7]           1,152\n",
      "           ReLU6-110            [-1, 576, 7, 7]               0\n",
      "          Conv2d-111            [-1, 160, 7, 7]          92,160\n",
      "     BatchNorm2d-112            [-1, 160, 7, 7]             320\n",
      "          Conv2d-113            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-114            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-115            [-1, 960, 7, 7]               0\n",
      "          Conv2d-116            [-1, 960, 7, 7]           8,640\n",
      "     BatchNorm2d-117            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-118            [-1, 960, 7, 7]               0\n",
      "          Conv2d-119            [-1, 160, 7, 7]         153,600\n",
      "     BatchNorm2d-120            [-1, 160, 7, 7]             320\n",
      "          Conv2d-121            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-122            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-123            [-1, 960, 7, 7]               0\n",
      "          Conv2d-124            [-1, 960, 7, 7]           8,640\n",
      "     BatchNorm2d-125            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-126            [-1, 960, 7, 7]               0\n",
      "          Conv2d-127            [-1, 160, 7, 7]         153,600\n",
      "     BatchNorm2d-128            [-1, 160, 7, 7]             320\n",
      "          Conv2d-129            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-130            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-131            [-1, 960, 7, 7]               0\n",
      "          Conv2d-132            [-1, 960, 7, 7]           8,640\n",
      "     BatchNorm2d-133            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-134            [-1, 960, 7, 7]               0\n",
      "          Conv2d-135            [-1, 320, 7, 7]         307,200\n",
      "     BatchNorm2d-136            [-1, 320, 7, 7]             640\n",
      "          Conv2d-137           [-1, 1280, 7, 7]         409,600\n",
      "     BatchNorm2d-138           [-1, 1280, 7, 7]           2,560\n",
      "           ReLU6-139           [-1, 1280, 7, 7]               0\n",
      "AdaptiveAvgPool2d-140           [-1, 1280, 1, 1]               0\n",
      "          Linear-141                  [-1, 512]         655,872\n",
      "            ReLU-142                  [-1, 512]               0\n",
      "         Dropout-143                  [-1, 512]               0\n",
      "          Linear-144                    [-1, 4]           2,052\n",
      "          Linear-145                  [-1, 512]         655,872\n",
      "            ReLU-146                  [-1, 512]               0\n",
      "          Linear-147                    [-1, 1]             513\n",
      "         Sigmoid-148                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 3,538,213\n",
      "Trainable params: 3,538,213\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 148.51\n",
      "Params size (MB): 13.50\n",
      "Estimated Total Size (MB): 162.58\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class MobileNetFaceDetector(nn.Module):\n",
    "    def __init__(self, pretrained=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3,\n",
    "            out_channels=32,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            padding=1\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu1 = nn.ReLU6()\n",
    "\n",
    "        # bottleneck\n",
    "        #hidden_dim = 32\n",
    "        self.bottleneck1 = nn.Sequential(\n",
    "            #nn.Conv2d(in_channels=32, out_channels=32, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            #nn.BatchNorm2d(32),\n",
    "            #nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1, groups=32, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=32, out_channels=16, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "        )\n",
    "        #hidden_dim = 16*6\n",
    "        self.bottleneck2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=16*6, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(16*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=16*6, out_channels=16*6, kernel_size=3, stride=2, padding=1, groups=16*6, bias=False),\n",
    "            nn.BatchNorm2d(16*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=16*6, out_channels=24, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(24),\n",
    "        )\n",
    "        self.bottleneck21 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=24, out_channels=24*6, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(24*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=24*6, out_channels=24*6, kernel_size=3, stride=1, padding=1, groups=24*6, bias=False),\n",
    "            nn.BatchNorm2d(24*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=24*6, out_channels=24, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(24),\n",
    "        )\n",
    "        #hidden_dim = 24*6\n",
    "        self.bottleneck3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=24, out_channels=24*6, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(24*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=24*6, out_channels=24*6, kernel_size=3, stride=2, padding=1, groups=24*6, bias=False),\n",
    "            nn.BatchNorm2d(24*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=24*6, out_channels=32, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        self.bottleneck31 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32*6, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(32*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=32*6, out_channels=32*6, kernel_size=3, stride=1, padding=1, groups=32*6, bias=False),\n",
    "            nn.BatchNorm2d(32*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=32*6, out_channels=32, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        self.bottleneck32 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32*6, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(32*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=32*6, out_channels=32*6, kernel_size=3, stride=1, padding=1, groups=32*6, bias=False),\n",
    "            nn.BatchNorm2d(32*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=32*6, out_channels=32, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        #hidden_dim=32*6\n",
    "        self.bottleneck4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32*6, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(32*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=32*6, out_channels=32*6, kernel_size=3, stride=2, padding=1, groups=32*6, bias=False),\n",
    "            nn.BatchNorm2d(32*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=32*6, out_channels=64, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        self.bottleneck41 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=64*6, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(64*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=64*6, out_channels=64*6, kernel_size=3, stride=1, padding=1, groups=64*6, bias=False),\n",
    "            nn.BatchNorm2d(64*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=64*6, out_channels=64, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        self.bottleneck42 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=64*6, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(64*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=64*6, out_channels=64*6, kernel_size=3, stride=1, padding=1, groups=64*6, bias=False),\n",
    "            nn.BatchNorm2d(64*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=64*6, out_channels=64, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        self.bottleneck43 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=64*6, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(64*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=64*6, out_channels=64*6, kernel_size=3, stride=1, padding=1, groups=64*6, bias=False),\n",
    "            nn.BatchNorm2d(64*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=64*6, out_channels=64, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        #hidden_dim=64*6\n",
    "        self.bottleneck5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=64*6, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(64*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=64*6, out_channels=64*6, kernel_size=3, stride=1, padding=1, groups=64*6, bias=False),\n",
    "            nn.BatchNorm2d(64*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=64*6, out_channels=96, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(96),\n",
    "        )\n",
    "        self.bottleneck51 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=96, out_channels=96*6, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(96*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=96*6, out_channels=96*6, kernel_size=3, stride=1, padding=1, groups=96*6, bias=False),\n",
    "            nn.BatchNorm2d(96*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=96*6, out_channels=96, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(96),\n",
    "        )\n",
    "        self.bottleneck52 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=96, out_channels=96*6, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(96*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=96*6, out_channels=96*6, kernel_size=3, stride=1, padding=1, groups=96*6, bias=False),\n",
    "            nn.BatchNorm2d(96*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=96*6, out_channels=96, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(96),\n",
    "        )\n",
    "        #hidden_dim=96*6\n",
    "        self.bottleneck6 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=96, out_channels=96*6, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(96*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=96*6, out_channels=96*6, kernel_size=3, stride=2, padding=1, groups=96*6, bias=False),\n",
    "            nn.BatchNorm2d(96*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=96*6, out_channels=160, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(160),\n",
    "        )\n",
    "        self.bottleneck61 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=160, out_channels=160*6, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(160*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=160*6, out_channels=160*6, kernel_size=3, stride=1, padding=1, groups=160*6, bias=False),\n",
    "            nn.BatchNorm2d(160*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=160*6, out_channels=160, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(160),\n",
    "        )\n",
    "        self.bottleneck62 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=160, out_channels=160*6, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(160*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=160*6, out_channels=160*6, kernel_size=3, stride=1, padding=1, groups=160*6, bias=False),\n",
    "            nn.BatchNorm2d(160*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=160*6, out_channels=160, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(160),\n",
    "        )\n",
    "        #hidden_dim=160*6\n",
    "        self.bottleneck7 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=160, out_channels=160*6, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(160*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=160*6, out_channels=160*6, kernel_size=3, stride=1, padding=1, groups=160*6, bias=False),\n",
    "            nn.BatchNorm2d(160*6),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels=160*6, out_channels=320, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(320),\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=320,\n",
    "            out_channels=1280,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(1280)\n",
    "        self.relu2 = nn.ReLU6()\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        # Custom head for bounding box and classification\n",
    "        self.fc_bbox = nn.Sequential(\n",
    "            nn.Linear(1280, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(512, 4),  # Bounding box: [x_min, y_min, x_max, y_max]\n",
    "        )\n",
    "        self.fc_label = nn.Sequential(\n",
    "            nn.Linear(1280, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1),  # Binary classification: face/no face\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        x = self.bottleneck1(x)\n",
    "        x = self.bottleneck2(x)\n",
    "        x = self.bottleneck21(x)\n",
    "        x = self.bottleneck3(x)\n",
    "        x = self.bottleneck31(x)\n",
    "        x = self.bottleneck32(x)\n",
    "        x = self.bottleneck4(x)\n",
    "        x = self.bottleneck41(x)\n",
    "        x = self.bottleneck42(x)\n",
    "        x = self.bottleneck43(x)\n",
    "        x = self.bottleneck5(x)\n",
    "        x = self.bottleneck51(x)\n",
    "        x = self.bottleneck52(x)\n",
    "        x = self.bottleneck6(x)\n",
    "        x = self.bottleneck61(x)\n",
    "        x = self.bottleneck62(x)\n",
    "        x = self.bottleneck7(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        x = self.pool(x).view(x.size(0), -1)\n",
    "        bbox = self.fc_bbox(x)\n",
    "        label = self.fc_label(x)\n",
    "        return bbox, label\n",
    "mobilenetfacedetector = MobileNetFaceDetector().to(device)\n",
    "summary(mobilenetfacedetector, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1065c72b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T00:07:31.114949Z",
     "iopub.status.busy": "2025-04-14T00:07:31.114715Z",
     "iopub.status.idle": "2025-04-14T00:07:33.183252Z",
     "shell.execute_reply": "2025-04-14T00:07:33.182360Z"
    },
    "papermill": {
     "duration": 2.076259,
     "end_time": "2025-04-14T00:07:33.184976",
     "exception": false,
     "start_time": "2025-04-14T00:07:31.108717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 110, 110]           4,736\n",
      "       BatchNorm2d-2         [-1, 32, 110, 110]              64\n",
      "         LeakyReLU-3         [-1, 32, 110, 110]               0\n",
      "         MaxPool2d-4           [-1, 32, 55, 55]               0\n",
      "            Conv2d-5           [-1, 96, 55, 55]          27,744\n",
      "       BatchNorm2d-6           [-1, 96, 55, 55]             192\n",
      "         LeakyReLU-7           [-1, 96, 55, 55]               0\n",
      "         MaxPool2d-8           [-1, 96, 27, 27]               0\n",
      "            Conv2d-9           [-1, 64, 29, 29]           6,208\n",
      "      BatchNorm2d-10           [-1, 64, 29, 29]             128\n",
      "        LeakyReLU-11           [-1, 64, 29, 29]               0\n",
      "           Conv2d-12          [-1, 128, 29, 29]          73,856\n",
      "      BatchNorm2d-13          [-1, 128, 29, 29]             256\n",
      "        LeakyReLU-14          [-1, 128, 29, 29]               0\n",
      "        MaxPool2d-15          [-1, 128, 14, 14]               0\n",
      "           Conv2d-16          [-1, 128, 16, 16]          16,512\n",
      "      BatchNorm2d-17          [-1, 128, 16, 16]             256\n",
      "        LeakyReLU-18          [-1, 128, 16, 16]               0\n",
      "           Conv2d-19          [-1, 256, 16, 16]         295,168\n",
      "      BatchNorm2d-20          [-1, 256, 16, 16]             512\n",
      "        LeakyReLU-21          [-1, 256, 16, 16]               0\n",
      "        MaxPool2d-22            [-1, 256, 8, 8]               0\n",
      "           Conv2d-23          [-1, 256, 10, 10]          65,792\n",
      "      BatchNorm2d-24          [-1, 256, 10, 10]             512\n",
      "        LeakyReLU-25          [-1, 256, 10, 10]               0\n",
      "           Conv2d-26          [-1, 512, 10, 10]       1,180,160\n",
      "      BatchNorm2d-27          [-1, 512, 10, 10]           1,024\n",
      "        LeakyReLU-28          [-1, 512, 10, 10]               0\n",
      "           Conv2d-29          [-1, 512, 10, 10]       2,359,808\n",
      "      BatchNorm2d-30          [-1, 512, 10, 10]           1,024\n",
      "        LeakyReLU-31          [-1, 512, 10, 10]               0\n",
      "          Flatten-32                [-1, 51200]               0\n",
      "           Linear-33                 [-1, 2048]     104,859,648\n",
      "        LeakyReLU-34                 [-1, 2048]               0\n",
      "          Dropout-35                 [-1, 2048]               0\n",
      "           Linear-36                    [-1, 4]           8,196\n",
      "           Linear-37                 [-1, 2048]     104,859,648\n",
      "        LeakyReLU-38                 [-1, 2048]               0\n",
      "          Dropout-39                 [-1, 2048]               0\n",
      "           Linear-40                    [-1, 1]           2,049\n",
      "          Sigmoid-41                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 213,763,493\n",
      "Trainable params: 213,763,493\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 26.46\n",
      "Params size (MB): 815.44\n",
      "Estimated Total Size (MB): 842.48\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class YOLOFaceDetector(nn.Module):\n",
    "    def __init__(self, pretrained=False):\n",
    "        super().__init__()\n",
    "        # architecture from original YOLO paper - Fast YOLO\n",
    "        # architecture improved according to YOLOv2 paper\n",
    "\n",
    "        # conv layer 1\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3,\n",
    "            out_channels=int(64/2),\n",
    "            kernel_size=7,\n",
    "            stride=2,\n",
    "            padding=1\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(int(64/2))\n",
    "        self.relu1 = nn.LeakyReLU(negative_slope=0.1)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=int(64/2),\n",
    "            out_channels=int(192/2),\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(int(192/2))\n",
    "        self.relu2 = nn.LeakyReLU(negative_slope=0.1)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=int(192/2),\n",
    "            out_channels=int(128/2),\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm2d(int(128/2))\n",
    "        self.relu3 = nn.LeakyReLU(negative_slope=0.1)\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=int(128/2),\n",
    "            out_channels=int(256/2),\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        )\n",
    "        self.bn4 = nn.BatchNorm2d(int(256/2))\n",
    "        self.relu4 = nn.LeakyReLU(negative_slope=0.1)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv7 = nn.Conv2d(\n",
    "            in_channels=int(256/2),\n",
    "            out_channels=int(256/2),\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        )\n",
    "        self.bn7 = nn.BatchNorm2d(int(256/2))\n",
    "        self.relu7 = nn.LeakyReLU(negative_slope=0.1)\n",
    "        self.conv8 = nn.Conv2d(\n",
    "            in_channels=int(256/2),\n",
    "            out_channels=int(512/2),\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        )\n",
    "        self.bn8 = nn.BatchNorm2d(int(512/2))\n",
    "        self.relu8 = nn.LeakyReLU(negative_slope=0.1)\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv17 = nn.Conv2d(\n",
    "            in_channels=int(512/2),\n",
    "            out_channels=int(512/2),\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        )\n",
    "        self.bn17 = nn.BatchNorm2d(int(512/2))\n",
    "        self.relu17 = nn.LeakyReLU(negative_slope=0.1)\n",
    "        self.conv18 = nn.Conv2d(\n",
    "            in_channels=int(512/2),\n",
    "            out_channels=int(1024/2),\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        )\n",
    "        self.bn18 = nn.BatchNorm2d(int(1024/2))\n",
    "        self.relu18 = nn.LeakyReLU(negative_slope=0.1)\n",
    "\n",
    "        self.conv24 = nn.Conv2d(\n",
    "            in_channels=int(1024/2),\n",
    "            out_channels=int(1024/2),\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        )\n",
    "        self.bn24 = nn.BatchNorm2d(int(1024/2))\n",
    "        self.relu24 = nn.LeakyReLU(negative_slope=0.1)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # regression head\n",
    "        self.bbox = nn.Sequential(\n",
    "            nn.Linear(int(1024/2)*10*10, int(4096/2)),\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(int(4096/2), 4)\n",
    "        )\n",
    "        \n",
    "        # classification head\n",
    "        self.classify = nn.Sequential(\n",
    "            nn.Linear(int(1024/2)*10*10, int(4096/2)),\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(int(4096/2), 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # pass through feature extractor backbone\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.maxpool3(x)\n",
    "\n",
    "        x = self.conv7(x)\n",
    "        x = self.bn7(x)\n",
    "        x = self.relu7(x)\n",
    "        x = self.conv8(x)\n",
    "        x = self.bn8(x)\n",
    "        x = self.relu8(x)\n",
    "        x = self.maxpool4(x)\n",
    "\n",
    "        x = self.conv17(x)\n",
    "        x = self.bn17(x)\n",
    "        x = self.relu17(x)\n",
    "        x = self.conv18(x)\n",
    "        x = self.bn18(x)\n",
    "        x = self.relu18(x)\n",
    "        x = self.conv24(x)\n",
    "        x = self.bn24(x)\n",
    "        x = self.relu24(x)\n",
    "\n",
    "        #_, c, h, w = x.shape\n",
    "        #print(c, h, w)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        bbox = self.bbox(x)\n",
    "        label = self.classify(x)\n",
    "\n",
    "        return bbox, label\n",
    "yolofacedetector = YOLOFaceDetector().to(device)\n",
    "summary(yolofacedetector, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61901a81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T00:07:33.196421Z",
     "iopub.status.busy": "2025-04-14T00:07:33.196150Z",
     "iopub.status.idle": "2025-04-14T00:07:33.200337Z",
     "shell.execute_reply": "2025-04-14T00:07:33.199508Z"
    },
    "papermill": {
     "duration": 0.011232,
     "end_time": "2025-04-14T00:07:33.201752",
     "exception": false,
     "start_time": "2025-04-14T00:07:33.190520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "def step_lr(epoch):\n",
    "    if epoch < 5:\n",
    "        return (epoch+1)/5\n",
    "    elif epoch >= 5 and epoch < 30:\n",
    "        return 1.0\n",
    "    elif epoch >= 30 and epoch < 40:\n",
    "        return 0.1\n",
    "    else:\n",
    "        return 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93b7679a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T00:07:33.212883Z",
     "iopub.status.busy": "2025-04-14T00:07:33.212660Z",
     "iopub.status.idle": "2025-04-14T00:07:33.216022Z",
     "shell.execute_reply": "2025-04-14T00:07:33.215193Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.010356,
     "end_time": "2025-04-14T00:07:33.217310",
     "exception": false,
     "start_time": "2025-04-14T00:07:33.206954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "bbox_loss_fn = nn.SmoothL1Loss()  # For bounding box regression\n",
    "label_loss_fn = nn.BCELoss()      # For binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43c4fc6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T00:07:33.228238Z",
     "iopub.status.busy": "2025-04-14T00:07:33.228010Z",
     "iopub.status.idle": "2025-04-14T00:07:33.235039Z",
     "shell.execute_reply": "2025-04-14T00:07:33.234203Z"
    },
    "papermill": {
     "duration": 0.013825,
     "end_time": "2025-04-14T00:07:33.236307",
     "exception": false,
     "start_time": "2025-04-14T00:07:33.222482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train_model(train_loader, val_loader, num_epochs, scheduler, model_id, model, arch, learning_rate, batch_size):\n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    if scheduler:\n",
    "        scheduler_fn = LambdaLR(optimizer, step_lr)\n",
    "\n",
    "    best_val_loss = float('inf')  # Initialize best validation loss\n",
    "    best_model_path = f\"{arch}_{model_id}.pth\"  # Path to save the best model\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for images, targets in train_loader:\n",
    "            images = images.to(device)\n",
    "            bboxes = [torch.tensor(t, dtype=torch.float32).to(device) for t in targets]  # List of bounding boxes\n",
    "            labels = [int(1) for t in targets]  # List of labels\n",
    "            labels = torch.tensor(labels, dtype=torch.float32).to(device)\n",
    "            preds_bbox, preds_label = model(images)\n",
    "            # Compute losses\n",
    "            bbox_losses = []\n",
    "            label_losses = []\n",
    "            for i in range(len(bboxes)):\n",
    "              bbox_losses.append(bbox_loss_fn(preds_bbox[i], bboxes[i]))\n",
    "              label_losses.append(label_loss_fn(preds_label[i], labels[i].unsqueeze(-1)))\n",
    "\n",
    "            bbox_loss = torch.mean(torch.stack(bbox_losses))\n",
    "            label_loss = torch.mean(torch.stack(label_losses))\n",
    "            loss = bbox_loss + label_loss\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        if scheduler:\n",
    "            scheduler_fn.step()\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "        # Validate and save the best model\n",
    "        val_loss = validate_model(model, val_loader)\n",
    "        if val_loss < best_val_loss:\n",
    "            print(f\"Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. Saving model...\")\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "    print(\"Training complete. Best model saved as:\", best_model_path)\n",
    "    return best_val_loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30a08df1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T00:07:33.247048Z",
     "iopub.status.busy": "2025-04-14T00:07:33.246811Z",
     "iopub.status.idle": "2025-04-14T00:07:33.250472Z",
     "shell.execute_reply": "2025-04-14T00:07:33.249638Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.01038,
     "end_time": "2025-04-14T00:07:33.251734",
     "exception": false,
     "start_time": "2025-04-14T00:07:33.241354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_boxes(preds):\n",
    "    \"\"\"\n",
    "    Normalize the 'boxes' in the predictions to ensure they are all tensors of shape [N, 4].\n",
    "    Args:\n",
    "        preds: List of dictionaries with 'boxes' and 'labels'.\n",
    "    Returns:\n",
    "        Normalized predictions with 'boxes' as tensors of shape [N, 4].\n",
    "    \"\"\"\n",
    "    for pred in preds:\n",
    "        # If boxes is a list of tensors, stack them into a single tensor\n",
    "        if isinstance(pred['boxes'], list):\n",
    "            pred['boxes'] = torch.stack(pred['boxes'])  # Stack into [N, 4]\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5715289",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T00:07:33.262576Z",
     "iopub.status.busy": "2025-04-14T00:07:33.262340Z",
     "iopub.status.idle": "2025-04-14T00:07:33.267225Z",
     "shell.execute_reply": "2025-04-14T00:07:33.266436Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.011593,
     "end_time": "2025-04-14T00:07:33.268396",
     "exception": false,
     "start_time": "2025-04-14T00:07:33.256803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_iou(pred_box, gt_box):\n",
    "    \"\"\"\n",
    "    Calculate IoU (Intersection over Union) for a single pair of boxes.\n",
    "    Args:\n",
    "        pred_box: Tensor of shape (4,), [x_min, y_min, x_max, y_max].\n",
    "        gt_box: Tensor of shape (4,), [x_min, y_min, x_max, y_max].\n",
    "    Returns:\n",
    "        IoU value (float).\n",
    "    \"\"\"\n",
    "    # Determine the (x, y)-coordinates of the intersection rectangle\n",
    "    x1 = max(pred_box[0], gt_box[0])\n",
    "    y1 = max(pred_box[1], gt_box[1])\n",
    "    x2 = min(pred_box[2], gt_box[2])\n",
    "    y2 = min(pred_box[3], gt_box[3])\n",
    "\n",
    "    # Compute the area of intersection rectangle\n",
    "    inter_width = max(0, x2 - x1)\n",
    "    inter_height = max(0, y2 - y1)\n",
    "    inter_area = inter_width * inter_height\n",
    "\n",
    "    # Compute the area of both the predicted and ground-truth rectangles\n",
    "    pred_area = (pred_box[2] - pred_box[0]) * (pred_box[3] - pred_box[1])\n",
    "    gt_area = (gt_box[2] - gt_box[0]) * (gt_box[3] - gt_box[1])\n",
    "\n",
    "    # Compute the area of union\n",
    "    union_area = pred_area + gt_area - inter_area\n",
    "\n",
    "    # Compute IoU\n",
    "    iou = inter_area / union_area if union_area > 0 else 0.0\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cf9f69e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T00:07:33.279087Z",
     "iopub.status.busy": "2025-04-14T00:07:33.278859Z",
     "iopub.status.idle": "2025-04-14T00:07:33.283514Z",
     "shell.execute_reply": "2025-04-14T00:07:33.282684Z"
    },
    "papermill": {
     "duration": 0.011313,
     "end_time": "2025-04-14T00:07:33.284702",
     "exception": false,
     "start_time": "2025-04-14T00:07:33.273389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_map(pred_boxes, gt_boxes, threshold=0.5):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "\n",
    "    # format\n",
    "    pred_boxes = pred_boxes[0][\"boxes\"].cpu().detach().numpy().tolist()\n",
    "    gt_boxes = gt_boxes[0][\"boxes\"].cpu().detach().numpy().tolist()\n",
    "\n",
    "    # if there is more than one ground truth box\n",
    "    # loop over ious for all boxes and pick the\n",
    "    # closest one to measure mAP\n",
    "    closest_iou = 0.0\n",
    "    for i in range(len(gt_boxes)):\n",
    "        iou = calculate_iou(pred_boxes[0], gt_boxes[i])\n",
    "        if iou > closest_iou:\n",
    "            closest_iou = iou\n",
    "    if closest_iou >= threshold:\n",
    "        tp += 1\n",
    "    else:\n",
    "        fp += 1\n",
    "    precision = tp / (tp + fp + 1e-6)\n",
    "\n",
    "    return precision * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e91c977",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T00:07:33.295521Z",
     "iopub.status.busy": "2025-04-14T00:07:33.295260Z",
     "iopub.status.idle": "2025-04-14T00:07:33.302598Z",
     "shell.execute_reply": "2025-04-14T00:07:33.301794Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.014011,
     "end_time": "2025-04-14T00:07:33.303763",
     "exception": false,
     "start_time": "2025-04-14T00:07:33.289752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate_model(model, val_loader):\n",
    "    metric = IntersectionOverUnion().to(device)\n",
    "    model.eval()\n",
    "    total_bbox_loss = 0\n",
    "    total_label_loss = 0\n",
    "    total_iou = []\n",
    "    total_map = []\n",
    "    with torch.no_grad():\n",
    "        for images, targets in val_loader:\n",
    "            images = images.to(device)\n",
    "            bboxes = [torch.tensor(t, dtype=torch.float32).to(device) for t in targets]  # List of bounding boxes\n",
    "            labels = [int(1) for t in targets]  # List of labels\n",
    "            labels = torch.tensor(labels, dtype=torch.float32).to(device)\n",
    "            preds_bbox, preds_label = model(images)\n",
    "\n",
    "            bbox_losses = []\n",
    "            label_losses = []\n",
    "\n",
    "            for i in range(len(bboxes)):\n",
    "                bbox_losses.append(bbox_loss_fn(preds_bbox[i], bboxes[i]))\n",
    "                label_losses.append(label_loss_fn(preds_label[i], labels[i].unsqueeze(-1)))\n",
    "                \n",
    "                preds = [{\"boxes\": [preds_bbox[i]], \"labels\": preds_label[i]}]\n",
    "                preds = normalize_boxes(preds)\n",
    "                \n",
    "                targets_combined = torch.cat([bboxes[i]], dim=0)\n",
    "                targets = [{\"boxes\": targets_combined, \"labels\": torch.ones(len(targets_combined)).to(device)}]\n",
    "\n",
    "                iou_value = metric(preds, targets)\n",
    "                total_iou.append(iou_value['iou'].item())\n",
    "                map_value = compute_map(preds, targets)\n",
    "                total_map.append(map_value)\n",
    "            total_bbox_loss += torch.mean(torch.stack(bbox_losses))\n",
    "            total_label_loss += torch.mean(torch.stack(label_losses))\n",
    "\n",
    "    # Calculate average validation loss\n",
    "    avg_bbox_loss = total_bbox_loss / len(val_loader)\n",
    "    avg_label_loss = total_label_loss / len(val_loader)\n",
    "    val_loss = avg_bbox_loss + avg_label_loss\n",
    "    print('IoU = ', sum(total_iou)/len(total_iou))\n",
    "    print('mAP@50 = ', sum(total_map)/len(total_map))\n",
    "    print(f\"Validation - BBox Loss: {avg_bbox_loss:.4f}, Label Loss: {avg_label_loss:.4f}, Total Loss: {val_loss:.4f}\")\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "217e0628",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T00:07:33.314386Z",
     "iopub.status.busy": "2025-04-14T00:07:33.314143Z",
     "iopub.status.idle": "2025-04-14T00:07:39.314490Z",
     "shell.execute_reply": "2025-04-14T00:07:39.313702Z"
    },
    "papermill": {
     "duration": 6.007331,
     "end_time": "2025-04-14T00:07:39.316047",
     "exception": false,
     "start_time": "2025-04-14T00:07:33.308716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hyperopt in /usr/local/lib/python3.10/dist-packages (0.2.7)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.26.4)\r\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.13.1)\r\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.17.0)\r\n",
      "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from hyperopt) (3.4.2)\r\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.0.0)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from hyperopt) (4.67.1)\r\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt) (3.1.0)\r\n",
      "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt) (0.10.9.7)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->hyperopt) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->hyperopt) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->hyperopt) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->hyperopt) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->hyperopt) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->hyperopt) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->hyperopt) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->hyperopt) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->hyperopt) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->hyperopt) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->hyperopt) (2024.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install hyperopt\n",
    "from hyperopt import fmin, tpe, hp, anneal, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7492d125",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T00:07:39.329258Z",
     "iopub.status.busy": "2025-04-14T00:07:39.328814Z",
     "iopub.status.idle": "2025-04-14T01:15:41.749201Z",
     "shell.execute_reply": "2025-04-14T01:15:41.748355Z"
    },
    "papermill": {
     "duration": 4082.428597,
     "end_time": "2025-04-14T01:15:41.750643",
     "exception": false,
     "start_time": "2025-04-14T00:07:39.322046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-617baa71bbb5>:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  bboxes = [torch.tensor(t, dtype=torch.float32).to(device) for t in targets]  # List of bounding boxes\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:1040: UserWarning: Using a target size (torch.Size([2, 4])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:1040: UserWarning: Using a target size (torch.Size([1, 4])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:1040: UserWarning: Using a target size (torch.Size([3, 4])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:1040: UserWarning: Using a target size (torch.Size([5, 4])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:1040: UserWarning: Using a target size (torch.Size([4, 4])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:1040: UserWarning: Using a target size (torch.Size([8, 4])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:1040: UserWarning: Using a target size (torch.Size([11, 4])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:1040: UserWarning: Using a target size (torch.Size([10, 4])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:1040: UserWarning: Using a target size (torch.Size([15, 4])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:1040: UserWarning: Using a target size (torch.Size([6, 4])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:1040: UserWarning: Using a target size (torch.Size([7, 4])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:1040: UserWarning: Using a target size (torch.Size([9, 4])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:1040: UserWarning: Using a target size (torch.Size([13, 4])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:1040: UserWarning: Using a target size (torch.Size([27, 4])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 44.0500\n",
      "  0%|          | 0/1 [00:27<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-3e8f1a4f874e>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  bboxes = [torch.tensor(t, dtype=torch.float32).to(device) for t in targets]  # List of bounding boxes\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:1040: UserWarning: Using a target size (torch.Size([12, 4])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:1040: UserWarning: Using a target size (torch.Size([22, 4])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IoU = \n",
      "0.27780864579445114\n",
      "mAP@50 = \n",
      "18.021183392244183\n",
      "Validation - BBox Loss: 31.7657, Label Loss: 0.0000, Total Loss: 31.7657\n",
      "Validation loss improved from inf to 31.7657. Saving model...\n",
      "Epoch 2/100, Loss: 28.2317\n",
      "IoU = \n",
      "0.3092033474396769\n",
      "mAP@50 = \n",
      "30.388662190843217\n",
      "Validation - BBox Loss: 28.3772, Label Loss: 0.0000, Total Loss: 28.3772\n",
      "Validation loss improved from 31.7657 to 28.3772. Saving model...\n",
      "Epoch 3/100, Loss: 25.7754\n",
      "IoU = \n",
      "0.3708431369657118\n",
      "mAP@50 = \n",
      "45.229636749162054\n",
      "Validation - BBox Loss: 25.7047, Label Loss: 0.0000, Total Loss: 25.7047\n",
      "Validation loss improved from 28.3772 to 25.7047. Saving model...\n",
      "Epoch 4/100, Loss: 24.1969\n",
      "IoU = \n",
      "0.38174330295691294\n",
      "mAP@50 = \n",
      "47.703132508881865\n",
      "Validation - BBox Loss: 24.9613, Label Loss: 0.0000, Total Loss: 24.9613\n",
      "Validation loss improved from 25.7047 to 24.9613. Saving model...\n",
      "Epoch 5/100, Loss: 23.1924\n",
      "IoU = \n",
      "0.40848168681166713\n",
      "mAP@50 = \n",
      "53.53351537107855\n",
      "Validation - BBox Loss: 23.4952, Label Loss: 0.0000, Total Loss: 23.4952\n",
      "Validation loss improved from 24.9613 to 23.4952. Saving model...\n",
      "Epoch 6/100, Loss: 22.6539\n",
      "IoU = \n",
      "0.41664107813081924\n",
      "mAP@50 = \n",
      "52.296767491218645\n",
      "Validation - BBox Loss: 23.9127, Label Loss: 0.0000, Total Loss: 23.9127\n",
      "Epoch 7/100, Loss: 22.0801\n",
      "IoU = \n",
      "0.4411847870246723\n",
      "mAP@50 = \n",
      "62.0140722615463\n",
      "Validation - BBox Loss: 22.5818, Label Loss: 0.0000, Total Loss: 22.5818\n",
      "Validation loss improved from 23.4952 to 22.5818. Saving model...\n",
      "Epoch 8/100, Loss: 21.5153\n",
      "IoU = \n",
      "0.4465793266193067\n",
      "mAP@50 = \n",
      "62.19075053009771\n",
      "Validation - BBox Loss: 22.1512, Label Loss: 0.0000, Total Loss: 22.1512\n",
      "Validation loss improved from 22.5818 to 22.1512. Saving model...\n",
      "Epoch 9/100, Loss: 20.9400\n",
      "IoU = \n",
      "0.43721430547936085\n",
      "mAP@50 = \n",
      "62.36742879864912\n",
      "Validation - BBox Loss: 23.3098, Label Loss: 0.0000, Total Loss: 23.3098\n",
      "Epoch 10/100, Loss: 20.3938\n",
      "IoU = \n",
      "0.3816837294898473\n",
      "mAP@50 = \n",
      "54.0635501767328\n",
      "Validation - BBox Loss: 23.6892, Label Loss: 0.0000, Total Loss: 23.6892\n",
      "Epoch 11/100, Loss: 19.8225\n",
      "IoU = \n",
      "0.437197564031547\n",
      "mAP@50 = \n",
      "63.07414187285475\n",
      "Validation - BBox Loss: 21.9718, Label Loss: 0.0000, Total Loss: 21.9718\n",
      "Validation loss improved from 22.1512 to 21.9718. Saving model...\n",
      "Epoch 12/100, Loss: 19.8994\n",
      "IoU = \n",
      "0.45620856849314617\n",
      "mAP@50 = \n",
      "63.780854947060384\n",
      "Validation - BBox Loss: 20.8292, Label Loss: 0.0000, Total Loss: 20.8292\n",
      "Validation loss improved from 21.9718 to 20.8292. Saving model...\n",
      "Epoch 13/100, Loss: 19.7423\n",
      "IoU = \n",
      "0.45825435355710453\n",
      "mAP@50 = \n",
      "67.13774204953714\n",
      "Validation - BBox Loss: 20.8410, Label Loss: 0.0000, Total Loss: 20.8410\n",
      "Epoch 14/100, Loss: 19.4369\n",
      "IoU = \n",
      "0.41793462848262003\n",
      "mAP@50 = \n",
      "63.07414187285475\n",
      "Validation - BBox Loss: 21.9244, Label Loss: 0.0000, Total Loss: 21.9244\n",
      "Epoch 15/100, Loss: 19.2933\n",
      "IoU = \n",
      "0.4238122185303866\n",
      "mAP@50 = \n",
      "60.247289576032216\n",
      "Validation - BBox Loss: 21.2083, Label Loss: 0.0000, Total Loss: 21.2083\n",
      "Epoch 16/100, Loss: 19.2706\n",
      "IoU = \n",
      "0.4272537298690587\n",
      "mAP@50 = \n",
      "62.720785335751934\n",
      "Validation - BBox Loss: 21.0636, Label Loss: 0.0000, Total Loss: 21.0636\n",
      "Epoch 17/100, Loss: 19.0199\n",
      "IoU = \n",
      "0.5012585488502833\n",
      "mAP@50 = \n",
      "72.08473356897657\n",
      "Validation - BBox Loss: 19.7758, Label Loss: 0.0000, Total Loss: 19.7758\n",
      "Validation loss improved from 20.8292 to 19.7758. Saving model...\n",
      "Epoch 18/100, Loss: 19.0985\n",
      "IoU = \n",
      "0.4668907930698824\n",
      "mAP@50 = \n",
      "63.25082014140616\n",
      "Validation - BBox Loss: 20.2405, Label Loss: 0.0000, Total Loss: 20.2405\n",
      "Epoch 19/100, Loss: 18.7793\n",
      "IoU = \n",
      "0.46773453147682054\n",
      "mAP@50 = \n",
      "69.43455954070545\n",
      "Validation - BBox Loss: 20.7303, Label Loss: 0.0000, Total Loss: 20.7303\n",
      "Epoch 20/100, Loss: 18.7188\n",
      "IoU = \n",
      "0.4456733932336891\n",
      "mAP@50 = \n",
      "63.9575332156118\n",
      "Validation - BBox Loss: 20.6580, Label Loss: 0.0000, Total Loss: 20.6580\n",
      "Epoch 21/100, Loss: 18.5878\n",
      "IoU = \n",
      "0.47481118175719433\n",
      "mAP@50 = \n",
      "67.66777685519136\n",
      "Validation - BBox Loss: 19.7007, Label Loss: 0.0000, Total Loss: 19.7007\n",
      "Validation loss improved from 19.7758 to 19.7007. Saving model...\n",
      "Epoch 22/100, Loss: 18.5574\n",
      "IoU = \n",
      "0.48251196127277945\n",
      "mAP@50 = \n",
      "69.61123780925686\n",
      "Validation - BBox Loss: 20.1388, Label Loss: 0.0000, Total Loss: 20.1388\n",
      "Epoch 23/100, Loss: 18.1655\n",
      "IoU = \n",
      "0.4759393462601904\n",
      "mAP@50 = \n",
      "64.31088975271462\n",
      "Validation - BBox Loss: 20.6551, Label Loss: 0.0000, Total Loss: 20.6551\n",
      "Epoch 24/100, Loss: 18.0235\n",
      "IoU = \n",
      "0.4767698788721135\n",
      "mAP@50 = \n",
      "69.96459434635968\n",
      "Validation - BBox Loss: 20.8567, Label Loss: 0.0000, Total Loss: 20.8567\n",
      "Epoch 25/100, Loss: 18.2442\n",
      "IoU = \n",
      "0.4919381258583894\n",
      "mAP@50 = \n",
      "69.78791607780828\n",
      "Validation - BBox Loss: 20.0006, Label Loss: 0.0000, Total Loss: 20.0006\n",
      "Epoch 26/100, Loss: 18.3559\n",
      "IoU = \n",
      "0.4881358780034706\n",
      "mAP@50 = \n",
      "66.2543507067801\n",
      "Validation - BBox Loss: 19.9223, Label Loss: 0.0000, Total Loss: 19.9223\n",
      "Epoch 27/100, Loss: 18.0729\n",
      "IoU = \n",
      "0.46485512555680114\n",
      "mAP@50 = \n",
      "67.49109858663996\n",
      "Validation - BBox Loss: 20.3522, Label Loss: 0.0000, Total Loss: 20.3522\n",
      "Epoch 28/100, Loss: 17.9931\n",
      "IoU = \n",
      "0.44581341776532424\n",
      "mAP@50 = \n",
      "68.90452473505123\n",
      "Validation - BBox Loss: 20.9368, Label Loss: 0.0000, Total Loss: 20.9368\n",
      "Epoch 29/100, Loss: 18.1116\n",
      "IoU = \n",
      "0.4994395876355969\n",
      "mAP@50 = \n",
      "74.02819452304207\n",
      "Validation - BBox Loss: 19.1297, Label Loss: 0.0000, Total Loss: 19.1297\n",
      "Validation loss improved from 19.7007 to 19.1297. Saving model...\n",
      "Epoch 30/100, Loss: 17.8424\n",
      "IoU = \n",
      "0.5194181415621378\n",
      "mAP@50 = \n",
      "73.32148144883644\n",
      "Validation - BBox Loss: 18.8051, Label Loss: 0.0000, Total Loss: 18.8051\n",
      "Validation loss improved from 19.1297 to 18.8051. Saving model...\n",
      "Epoch 31/100, Loss: 17.8971\n",
      "IoU = \n",
      "0.49342062190716407\n",
      "mAP@50 = \n",
      "71.55469876332235\n",
      "Validation - BBox Loss: 19.5991, Label Loss: 0.0000, Total Loss: 19.5991\n",
      "Epoch 32/100, Loss: 17.8499\n",
      "IoU = \n",
      "0.5035949104254516\n",
      "mAP@50 = \n",
      "70.84798568911673\n",
      "Validation - BBox Loss: 19.1300, Label Loss: 0.0000, Total Loss: 19.1300\n",
      "Epoch 33/100, Loss: 17.6705\n",
      "IoU = \n",
      "0.4884427412513433\n",
      "mAP@50 = \n",
      "71.90805530042518\n",
      "Validation - BBox Loss: 19.2740, Label Loss: 0.0000, Total Loss: 19.2740\n",
      "Epoch 34/100, Loss: 17.7899\n",
      "IoU = \n",
      "0.5017449662748349\n",
      "mAP@50 = \n",
      "72.96812491173363\n",
      "Validation - BBox Loss: 19.2571, Label Loss: 0.0000, Total Loss: 19.2571\n",
      "Epoch 35/100, Loss: 17.8366\n",
      "IoU = \n",
      "0.508860381919884\n",
      "mAP@50 = \n",
      "71.73137703187376\n",
      "Validation - BBox Loss: 19.2022, Label Loss: 0.0000, Total Loss: 19.2022\n",
      "Epoch 36/100, Loss: 17.7343\n",
      "IoU = \n",
      "0.4921588118825899\n",
      "mAP@50 = \n",
      "70.84798568911673\n",
      "Validation - BBox Loss: 19.3589, Label Loss: 0.0000, Total Loss: 19.3589\n",
      "Epoch 37/100, Loss: 17.6294\n",
      "IoU = \n",
      "0.49570248814323564\n",
      "mAP@50 = \n",
      "71.90805530042518\n",
      "Validation - BBox Loss: 19.3403, Label Loss: 0.0000, Total Loss: 19.3403\n",
      "Epoch 38/100, Loss: 17.4344\n",
      "IoU = \n",
      "0.511364236923244\n",
      "mAP@50 = \n",
      "71.55469876332235\n",
      "Validation - BBox Loss: 18.6021, Label Loss: 0.0000, Total Loss: 18.6021\n",
      "Validation loss improved from 18.8051 to 18.6021. Saving model...\n",
      "Epoch 39/100, Loss: 17.5142\n",
      "IoU = \n",
      "0.5230783003118291\n",
      "mAP@50 = \n",
      "71.55469876332235\n",
      "Validation - BBox Loss: 18.3644, Label Loss: 0.0000, Total Loss: 18.3644\n",
      "Validation loss improved from 18.6021 to 18.3644. Saving model...\n",
      "Epoch 40/100, Loss: 17.5292\n",
      "IoU = \n",
      "0.4965465481427182\n",
      "mAP@50 = \n",
      "70.3179508834625\n",
      "Validation - BBox Loss: 19.0416, Label Loss: 0.0000, Total Loss: 19.0416\n",
      "Epoch 41/100, Loss: 17.4648\n",
      "IoU = \n",
      "0.5191490809295768\n",
      "mAP@50 = \n",
      "70.14127261491109\n",
      "Validation - BBox Loss: 18.4861, Label Loss: 0.0000, Total Loss: 18.4861\n",
      "Epoch 42/100, Loss: 17.3134\n",
      "IoU = \n",
      "0.5014176824204009\n",
      "mAP@50 = \n",
      "69.08120300360264\n",
      "Validation - BBox Loss: 18.9507, Label Loss: 0.0000, Total Loss: 18.9507\n",
      "Epoch 43/100, Loss: 17.3724\n",
      "IoU = \n",
      "0.5131017512291367\n",
      "mAP@50 = \n",
      "72.79144664318221\n",
      "Validation - BBox Loss: 18.6975, Label Loss: 0.0000, Total Loss: 18.6975\n",
      "Epoch 44/100, Loss: 17.3250\n",
      "IoU = \n",
      "0.5204806623128062\n",
      "mAP@50 = \n",
      "72.4380901060794\n",
      "Validation - BBox Loss: 18.7710, Label Loss: 0.0000, Total Loss: 18.7710\n",
      "Epoch 45/100, Loss: 17.4675\n",
      "IoU = \n",
      "0.49991547714983847\n",
      "mAP@50 = \n",
      "69.43455954070545\n",
      "Validation - BBox Loss: 18.9936, Label Loss: 0.0000, Total Loss: 18.9936\n",
      "Epoch 46/100, Loss: 17.3291\n",
      "IoU = \n",
      "0.5074356080653218\n",
      "mAP@50 = \n",
      "69.78791607780828\n",
      "Validation - BBox Loss: 18.8992, Label Loss: 0.0000, Total Loss: 18.8992\n",
      "Epoch 47/100, Loss: 17.1400\n",
      "IoU = \n",
      "0.5186354129788279\n",
      "mAP@50 = \n",
      "70.67130742056531\n",
      "Validation - BBox Loss: 18.4877, Label Loss: 0.0000, Total Loss: 18.4877\n",
      "Epoch 48/100, Loss: 17.2907\n",
      "IoU = \n",
      "0.508738269812638\n",
      "mAP@50 = \n",
      "70.67130742056531\n",
      "Validation - BBox Loss: 19.3011, Label Loss: 0.0000, Total Loss: 19.3011\n",
      "Epoch 49/100, Loss: 17.2414\n",
      "IoU = \n",
      "0.5277331628589463\n",
      "mAP@50 = \n",
      "72.4380901060794\n",
      "Validation - BBox Loss: 18.4890, Label Loss: 0.0000, Total Loss: 18.4890\n",
      "Epoch 50/100, Loss: 17.1690\n",
      "IoU = \n",
      "0.5028538331422336\n",
      "mAP@50 = \n",
      "70.3179508834625\n",
      "Validation - BBox Loss: 18.9738, Label Loss: 0.0000, Total Loss: 18.9738\n",
      "Epoch 51/100, Loss: 17.1770\n",
      "IoU = \n",
      "0.5115454785841314\n",
      "mAP@50 = \n",
      "73.14480318028502\n",
      "Validation - BBox Loss: 18.7156, Label Loss: 0.0000, Total Loss: 18.7156\n",
      "Epoch 52/100, Loss: 17.3415\n",
      "IoU = \n",
      "0.5073583536479431\n",
      "mAP@50 = \n",
      "72.4380901060794\n",
      "Validation - BBox Loss: 18.7451, Label Loss: 0.0000, Total Loss: 18.7451\n",
      "Epoch 53/100, Loss: 17.1634\n",
      "IoU = \n",
      "0.5263520389310514\n",
      "mAP@50 = \n",
      "71.20134222621954\n",
      "Validation - BBox Loss: 18.2848, Label Loss: 0.0000, Total Loss: 18.2848\n",
      "Validation loss improved from 18.3644 to 18.2848. Saving model...\n",
      "Epoch 54/100, Loss: 17.0500\n",
      "IoU = \n",
      "0.4758953033064495\n",
      "mAP@50 = \n",
      "67.49109858663996\n",
      "Validation - BBox Loss: 19.4853, Label Loss: 0.0000, Total Loss: 19.4853\n",
      "Epoch 55/100, Loss: 17.0911\n",
      "IoU = \n",
      "0.5203161862380178\n",
      "mAP@50 = \n",
      "71.55469876332235\n",
      "Validation - BBox Loss: 18.2785, Label Loss: 0.0000, Total Loss: 18.2785\n",
      "Validation loss improved from 18.2848 to 18.2785. Saving model...\n",
      "Epoch 56/100, Loss: 17.1688\n",
      "IoU = \n",
      "0.522445591052257\n",
      "mAP@50 = \n",
      "70.4946291520139\n",
      "Validation - BBox Loss: 18.1423, Label Loss: 0.0000, Total Loss: 18.1423\n",
      "Validation loss improved from 18.2785 to 18.1423. Saving model...\n",
      "Epoch 57/100, Loss: 17.1132\n",
      "IoU = \n",
      "0.5158955952987262\n",
      "mAP@50 = \n",
      "71.55469876332235\n",
      "Validation - BBox Loss: 18.8310, Label Loss: 0.0000, Total Loss: 18.8310\n",
      "Epoch 58/100, Loss: 17.2047\n",
      "IoU = \n",
      "0.5228316277321494\n",
      "mAP@50 = \n",
      "73.49815971738785\n",
      "Validation - BBox Loss: 18.1442, Label Loss: 0.0000, Total Loss: 18.1442\n",
      "Epoch 59/100, Loss: 17.0523\n",
      "IoU = \n",
      "0.5220933324055147\n",
      "mAP@50 = \n",
      "72.08473356897657\n",
      "Validation - BBox Loss: 18.3942, Label Loss: 0.0000, Total Loss: 18.3942\n",
      "Epoch 60/100, Loss: 16.9139\n",
      "IoU = \n",
      "0.5165952778069217\n",
      "mAP@50 = \n",
      "72.4380901060794\n",
      "Validation - BBox Loss: 18.3992, Label Loss: 0.0000, Total Loss: 18.3992\n",
      "Epoch 61/100, Loss: 16.9545\n",
      "IoU = \n",
      "0.5280217358459103\n",
      "mAP@50 = \n",
      "72.4380901060794\n",
      "Validation - BBox Loss: 18.3255, Label Loss: 0.0000, Total Loss: 18.3255\n",
      "Epoch 62/100, Loss: 17.2651\n",
      "IoU = \n",
      "0.48387942069933904\n",
      "mAP@50 = \n",
      "69.25788127215404\n",
      "Validation - BBox Loss: 19.5597, Label Loss: 0.0000, Total Loss: 19.5597\n",
      "Epoch 63/100, Loss: 17.2790\n",
      "IoU = \n",
      "0.5109947955037563\n",
      "mAP@50 = \n",
      "68.72784646649981\n",
      "Validation - BBox Loss: 18.4467, Label Loss: 0.0000, Total Loss: 18.4467\n",
      "Epoch 64/100, Loss: 16.9206\n",
      "IoU = \n",
      "0.5316250000589992\n",
      "mAP@50 = \n",
      "73.49815971738785\n",
      "Validation - BBox Loss: 18.2213, Label Loss: 0.0000, Total Loss: 18.2213\n",
      "Epoch 65/100, Loss: 16.9354\n",
      "IoU = \n",
      "0.5303895203059361\n",
      "mAP@50 = \n",
      "73.14480318028502\n",
      "Validation - BBox Loss: 18.1737, Label Loss: 0.0000, Total Loss: 18.1737\n",
      "Epoch 66/100, Loss: 16.8793\n",
      "IoU = \n",
      "0.5105794696474626\n",
      "mAP@50 = \n",
      "74.20487279159347\n",
      "Validation - BBox Loss: 18.9659, Label Loss: 0.0000, Total Loss: 18.9659\n",
      "Epoch 67/100, Loss: 16.7807\n",
      "IoU = \n",
      "0.5124407266723255\n",
      "mAP@50 = \n",
      "73.49815971738785\n",
      "Validation - BBox Loss: 18.6971, Label Loss: 0.0000, Total Loss: 18.6971\n",
      "Epoch 68/100, Loss: 16.7047\n",
      "IoU = \n",
      "0.5351930886322744\n",
      "mAP@50 = \n",
      "71.90805530042518\n",
      "Validation - BBox Loss: 17.8747, Label Loss: 0.0000, Total Loss: 17.8747\n",
      "Validation loss improved from 18.1423 to 17.8747. Saving model...\n",
      "Epoch 69/100, Loss: 16.6296\n",
      "IoU = \n",
      "0.5056866700489522\n",
      "mAP@50 = \n",
      "68.02113339229419\n",
      "Validation - BBox Loss: 18.7294, Label Loss: 0.0000, Total Loss: 18.7294\n",
      "Epoch 70/100, Loss: 16.6336\n",
      "IoU = \n",
      "0.5126275858513158\n",
      "mAP@50 = \n",
      "72.26141183752799\n",
      "Validation - BBox Loss: 18.5053, Label Loss: 0.0000, Total Loss: 18.5053\n",
      "Epoch 71/100, Loss: 16.7559\n",
      "IoU = \n",
      "0.5429851664542862\n",
      "mAP@50 = \n",
      "73.49815971738785\n",
      "Validation - BBox Loss: 17.7821, Label Loss: 0.0000, Total Loss: 17.7821\n",
      "Validation loss improved from 17.8747 to 17.7821. Saving model...\n",
      "Epoch 72/100, Loss: 16.7118\n",
      "IoU = \n",
      "0.5258846316933335\n",
      "mAP@50 = \n",
      "72.6147683746308\n",
      "Validation - BBox Loss: 17.8856, Label Loss: 0.0000, Total Loss: 17.8856\n",
      "Epoch 73/100, Loss: 16.9009\n",
      "IoU = \n",
      "0.5286000991382475\n",
      "mAP@50 = \n",
      "73.67483798593925\n",
      "Validation - BBox Loss: 18.4614, Label Loss: 0.0000, Total Loss: 18.4614\n",
      "Epoch 74/100, Loss: 16.5675\n",
      "IoU = \n",
      "0.5480891675965995\n",
      "mAP@50 = \n",
      "72.79144664318221\n",
      "Validation - BBox Loss: 17.6343, Label Loss: 0.0000, Total Loss: 17.6343\n",
      "Validation loss improved from 17.7821 to 17.6343. Saving model...\n",
      "Epoch 75/100, Loss: 16.4928\n",
      "IoU = \n",
      "0.5307990341413253\n",
      "mAP@50 = \n",
      "72.08473356897657\n",
      "Validation - BBox Loss: 18.1921, Label Loss: 0.0000, Total Loss: 18.1921\n",
      "Epoch 76/100, Loss: 16.3523\n",
      "IoU = \n",
      "0.5405941038736383\n",
      "mAP@50 = \n",
      "74.5582293286963\n",
      "Validation - BBox Loss: 18.0031, Label Loss: 0.0000, Total Loss: 18.0031\n",
      "Epoch 77/100, Loss: 16.3964\n",
      "IoU = \n",
      "0.5302928503645524\n",
      "mAP@50 = \n",
      "75.26494240290192\n",
      "Validation - BBox Loss: 18.2620, Label Loss: 0.0000, Total Loss: 18.2620\n",
      "Epoch 78/100, Loss: 16.4678\n",
      "IoU = \n",
      "0.5061368632801667\n",
      "mAP@50 = \n",
      "70.4946291520139\n",
      "Validation - BBox Loss: 18.8609, Label Loss: 0.0000, Total Loss: 18.8609\n",
      "Epoch 79/100, Loss: 16.3729\n",
      "IoU = \n",
      "0.5376258777802507\n",
      "mAP@50 = \n",
      "71.55469876332235\n",
      "Validation - BBox Loss: 17.5344, Label Loss: 0.0000, Total Loss: 17.5344\n",
      "Validation loss improved from 17.6343 to 17.5344. Saving model...\n",
      "Epoch 80/100, Loss: 16.2803\n",
      "IoU = \n",
      "0.49489046170235557\n",
      "mAP@50 = \n",
      "71.90805530042518\n",
      "Validation - BBox Loss: 18.7996, Label Loss: 0.0000, Total Loss: 18.7996\n",
      "Epoch 81/100, Loss: 16.4214\n",
      "IoU = \n",
      "0.5351247346368471\n",
      "mAP@50 = \n",
      "72.4380901060794\n",
      "Validation - BBox Loss: 17.6995, Label Loss: 0.0000, Total Loss: 17.6995\n",
      "Epoch 82/100, Loss: 16.2044\n",
      "IoU = \n",
      "0.5510183180790961\n",
      "mAP@50 = \n",
      "76.14833374565897\n",
      "Validation - BBox Loss: 17.4041, Label Loss: 0.0000, Total Loss: 17.4041\n",
      "Validation loss improved from 17.5344 to 17.4041. Saving model...\n",
      "Epoch 83/100, Loss: 16.2950\n",
      "IoU = \n",
      "0.5418762317332093\n",
      "mAP@50 = \n",
      "75.44162067145334\n",
      "Validation - BBox Loss: 17.9693, Label Loss: 0.0000, Total Loss: 17.9693\n",
      "Epoch 84/100, Loss: 16.2989\n",
      "IoU = \n",
      "0.5167018054081983\n",
      "mAP@50 = \n",
      "74.7349075972477\n",
      "Validation - BBox Loss: 18.4209, Label Loss: 0.0000, Total Loss: 18.4209\n",
      "Epoch 85/100, Loss: 16.3232\n",
      "IoU = \n",
      "0.5448004607968493\n",
      "mAP@50 = \n",
      "73.49815971738785\n",
      "Validation - BBox Loss: 17.5059, Label Loss: 0.0000, Total Loss: 17.5059\n",
      "Epoch 86/100, Loss: 16.2570\n",
      "IoU = \n",
      "0.5382888280554566\n",
      "mAP@50 = \n",
      "74.20487279159347\n",
      "Validation - BBox Loss: 17.8293, Label Loss: 0.0000, Total Loss: 17.8293\n",
      "Epoch 87/100, Loss: 16.1755\n",
      "IoU = \n",
      "0.5377467047767023\n",
      "mAP@50 = \n",
      "74.91158586579911\n",
      "Validation - BBox Loss: 18.0655, Label Loss: 0.0000, Total Loss: 18.0655\n",
      "Epoch 88/100, Loss: 16.2813\n",
      "IoU = \n",
      "0.5345843742941359\n",
      "mAP@50 = \n",
      "71.73137703187376\n",
      "Validation - BBox Loss: 17.6742, Label Loss: 0.0000, Total Loss: 17.6742\n",
      "Epoch 89/100, Loss: 16.3425\n",
      "IoU = \n",
      "0.5191065468422266\n",
      "mAP@50 = \n",
      "72.79144664318221\n",
      "Validation - BBox Loss: 18.6012, Label Loss: 0.0000, Total Loss: 18.6012\n",
      "Epoch 90/100, Loss: 16.1886\n",
      "IoU = \n",
      "0.544953096803202\n",
      "mAP@50 = \n",
      "72.6147683746308\n",
      "Validation - BBox Loss: 17.5355, Label Loss: 0.0000, Total Loss: 17.5355\n",
      "Epoch 91/100, Loss: 16.2093\n",
      "IoU = \n",
      "0.5474029830401902\n",
      "mAP@50 = \n",
      "76.14833374565897\n",
      "Validation - BBox Loss: 17.7315, Label Loss: 0.0000, Total Loss: 17.7315\n",
      "Epoch 92/100, Loss: 16.2594\n",
      "IoU = \n",
      "0.5523755809982462\n",
      "mAP@50 = \n",
      "75.61829894000475\n",
      "Validation - BBox Loss: 17.2798, Label Loss: 0.0000, Total Loss: 17.2798\n",
      "Validation loss improved from 17.4041 to 17.2798. Saving model...\n",
      "Epoch 93/100, Loss: 16.4106\n",
      "IoU = \n",
      "0.5396220675918638\n",
      "mAP@50 = \n",
      "73.67483798593925\n",
      "Validation - BBox Loss: 17.7185, Label Loss: 0.0000, Total Loss: 17.7185\n",
      "Epoch 94/100, Loss: 16.0885\n",
      "IoU = \n",
      "0.5343972217055472\n",
      "mAP@50 = \n",
      "75.26494240290192\n",
      "Validation - BBox Loss: 18.0990, Label Loss: 0.0000, Total Loss: 18.0990\n",
      "Epoch 95/100, Loss: 16.1138\n",
      "IoU = \n",
      "0.501589865674978\n",
      "mAP@50 = \n",
      "69.96459434635968\n",
      "Validation - BBox Loss: 18.7797, Label Loss: 0.0000, Total Loss: 18.7797\n",
      "Epoch 96/100, Loss: 16.0875\n",
      "IoU = \n",
      "0.5505714285721782\n",
      "mAP@50 = \n",
      "74.20487279159347\n",
      "Validation - BBox Loss: 17.3621, Label Loss: 0.0000, Total Loss: 17.3621\n",
      "Epoch 97/100, Loss: 16.1077\n",
      "IoU = \n",
      "0.5365174356659803\n",
      "mAP@50 = \n",
      "74.38155106014489\n",
      "Validation - BBox Loss: 17.9167, Label Loss: 0.0000, Total Loss: 17.9167\n",
      "Epoch 98/100, Loss: 16.2205\n",
      "IoU = \n",
      "0.5553797509870081\n",
      "mAP@50 = \n",
      "74.5582293286963\n",
      "Validation - BBox Loss: 17.3064, Label Loss: 0.0000, Total Loss: 17.3064\n",
      "Epoch 99/100, Loss: 16.0595\n",
      "IoU = \n",
      "0.552388960763799\n",
      "mAP@50 = \n",
      "73.85151625449066\n",
      "Validation - BBox Loss: 17.3323, Label Loss: 0.0000, Total Loss: 17.3323\n",
      "Epoch 100/100, Loss: 16.0319\n",
      "IoU = \n",
      "0.541533365434113\n",
      "mAP@50 = \n",
      "73.67483798593925\n",
      "Validation - BBox Loss: 17.8526, Label Loss: 0.0000, Total Loss: 17.8526\n",
      "Training complete. Best model saved as:\n",
      "mobilenetv2_1744589259.3402731.pth\n",
      "100%|██████████| 1/1 [33:00<00:00, 1981.00s/trial, best loss: 17.279836654663086]\n",
      "Epoch 1/100, Loss: 26.6426\n",
      "IoU = \n",
      "0.39895892021424784\n",
      "mAP@50 = \n",
      "53.35683710252714\n",
      "Validation - BBox Loss: 23.2873, Label Loss: 0.0000, Total Loss: 23.2873\n",
      "Validation loss improved from inf to 23.2873. Saving model...\n",
      "Epoch 2/100, Loss: 23.9949\n",
      "IoU = \n",
      "0.41169764706047374\n",
      "mAP@50 = \n",
      "52.47344575977006\n",
      "Validation - BBox Loss: 22.8417, Label Loss: 0.0000, Total Loss: 22.8417\n",
      "Validation loss improved from 23.2873 to 22.8417. Saving model...\n",
      "Epoch 3/100, Loss: 23.1141\n",
      "IoU = \n",
      "0.4014029837342624\n",
      "mAP@50 = \n",
      "51.23669787991016\n",
      "Validation - BBox Loss: 23.2867, Label Loss: 0.0000, Total Loss: 23.2867\n",
      "Epoch 4/100, Loss: 22.9346\n",
      "IoU = \n",
      "0.38028413167263647\n",
      "mAP@50 = \n",
      "43.816210600750736\n",
      "Validation - BBox Loss: 25.0988, Label Loss: 0.0000, Total Loss: 25.0988\n",
      "Epoch 5/100, Loss: 23.3211\n",
      "IoU = \n",
      "0.43473398490120285\n",
      "mAP@50 = \n",
      "56.36036766790119\n",
      "Validation - BBox Loss: 22.1006, Label Loss: 0.0000, Total Loss: 22.1006\n",
      "Validation loss improved from 22.8417 to 22.1006. Saving model...\n",
      "Epoch 6/100, Loss: 21.7069\n",
      "IoU = \n",
      "0.405537268205543\n",
      "mAP@50 = \n",
      "57.597115547761085\n",
      "Validation - BBox Loss: 22.2420, Label Loss: 0.0000, Total Loss: 22.2420\n",
      "Epoch 7/100, Loss: 20.9901\n",
      "IoU = \n",
      "0.4162130864602826\n",
      "mAP@50 = \n",
      "57.773793816312505\n",
      "Validation - BBox Loss: 22.0650, Label Loss: 0.0000, Total Loss: 22.0650\n",
      "Validation loss improved from 22.1006 to 22.0650. Saving model...\n",
      "Epoch 8/100, Loss: 20.6234\n",
      "IoU = \n",
      "0.4527867510719406\n",
      "mAP@50 = \n",
      "60.42396784458363\n",
      "Validation - BBox Loss: 20.5096, Label Loss: 0.0000, Total Loss: 20.5096\n",
      "Validation loss improved from 22.0650 to 20.5096. Saving model...\n",
      "Epoch 9/100, Loss: 19.9390\n",
      "IoU = \n",
      "0.4501319258981228\n",
      "mAP@50 = \n",
      "64.66424628981743\n",
      "Validation - BBox Loss: 21.3635, Label Loss: 0.0000, Total Loss: 21.3635\n",
      "Epoch 10/100, Loss: 19.7302\n",
      "IoU = \n",
      "0.465505999841237\n",
      "mAP@50 = \n",
      "64.1342114841632\n",
      "Validation - BBox Loss: 20.2140, Label Loss: 0.0000, Total Loss: 20.2140\n",
      "Validation loss improved from 20.5096 to 20.2140. Saving model...\n",
      "Epoch 11/100, Loss: 19.1591\n",
      "IoU = \n",
      "0.47291229449343813\n",
      "mAP@50 = \n",
      "64.84092455836884\n",
      "Validation - BBox Loss: 19.7114, Label Loss: 0.0000, Total Loss: 19.7114\n",
      "Validation loss improved from 20.2140 to 19.7114. Saving model...\n",
      "Epoch 12/100, Loss: 18.6605\n",
      "IoU = \n",
      "0.4272309386051283\n",
      "mAP@50 = \n",
      "60.247289576032216\n",
      "Validation - BBox Loss: 22.8980, Label Loss: 0.0000, Total Loss: 22.8980\n",
      "Epoch 13/100, Loss: 18.5283\n",
      "IoU = \n",
      "0.5023017161075448\n",
      "mAP@50 = \n",
      "69.08120300360264\n",
      "Validation - BBox Loss: 18.3114, Label Loss: 0.0000, Total Loss: 18.3114\n",
      "Validation loss improved from 19.7114 to 18.3114. Saving model...\n",
      "Epoch 14/100, Loss: 18.1777\n",
      "IoU = \n",
      "0.40165868298213947\n",
      "mAP@50 = \n",
      "51.23669787991016\n",
      "Validation - BBox Loss: 20.8043, Label Loss: 0.0000, Total Loss: 20.8043\n",
      "Epoch 15/100, Loss: 17.9989\n",
      "IoU = \n",
      "0.4616345564956948\n",
      "mAP@50 = \n",
      "65.19428109547165\n",
      "Validation - BBox Loss: 20.0113, Label Loss: 0.0000, Total Loss: 20.0113\n",
      "Epoch 16/100, Loss: 17.9923\n",
      "IoU = \n",
      "0.49763338293883513\n",
      "mAP@50 = \n",
      "68.02113339229419\n",
      "Validation - BBox Loss: 18.0692, Label Loss: 0.0000, Total Loss: 18.0692\n",
      "Validation loss improved from 18.3114 to 18.0692. Saving model...\n",
      "Epoch 17/100, Loss: 17.6316\n",
      "IoU = \n",
      "0.50816806825788\n",
      "mAP@50 = \n",
      "69.08120300360264\n",
      "Validation - BBox Loss: 18.0182, Label Loss: 0.0000, Total Loss: 18.0182\n",
      "Validation loss improved from 18.0692 to 18.0182. Saving model...\n",
      "Epoch 18/100, Loss: 17.7154\n",
      "IoU = \n",
      "0.49506863608252705\n",
      "mAP@50 = \n",
      "67.13774204953714\n",
      "Validation - BBox Loss: 17.8272, Label Loss: 0.0000, Total Loss: 17.8272\n",
      "Validation loss improved from 18.0182 to 17.8272. Saving model...\n",
      "Epoch 19/100, Loss: 17.5859\n",
      "IoU = \n",
      "0.4938871130306013\n",
      "mAP@50 = \n",
      "68.374489929397\n",
      "Validation - BBox Loss: 18.2248, Label Loss: 0.0000, Total Loss: 18.2248\n",
      "Epoch 20/100, Loss: 17.5284\n",
      "IoU = \n",
      "0.5062741307494832\n",
      "mAP@50 = \n",
      "69.78791607780828\n",
      "Validation - BBox Loss: 18.0589, Label Loss: 0.0000, Total Loss: 18.0589\n",
      "Epoch 21/100, Loss: 17.2996\n",
      "IoU = \n",
      "0.49370840274277983\n",
      "mAP@50 = \n",
      "68.90452473505123\n",
      "Validation - BBox Loss: 18.0182, Label Loss: 0.0000, Total Loss: 18.0182\n",
      "Epoch 22/100, Loss: 16.9800\n",
      "IoU = \n",
      "0.5144469221625709\n",
      "mAP@50 = \n",
      "67.13774204953714\n",
      "Validation - BBox Loss: 17.3101, Label Loss: 0.0000, Total Loss: 17.3101\n",
      "Validation loss improved from 17.8272 to 17.3101. Saving model...\n",
      "Epoch 23/100, Loss: 16.9660\n",
      "IoU = \n",
      "0.5060418613372056\n",
      "mAP@50 = \n",
      "69.25788127215404\n",
      "Validation - BBox Loss: 18.0076, Label Loss: 0.0000, Total Loss: 18.0076\n",
      "Epoch 24/100, Loss: 17.0527\n",
      "IoU = \n",
      "0.5194057664916647\n",
      "mAP@50 = \n",
      "69.61123780925686\n",
      "Validation - BBox Loss: 17.7190, Label Loss: 0.0000, Total Loss: 17.7190\n",
      "Epoch 25/100, Loss: 16.8261\n",
      "IoU = \n",
      "0.508230511552729\n",
      "mAP@50 = \n",
      "67.84445512374278\n",
      "Validation - BBox Loss: 17.5237, Label Loss: 0.0000, Total Loss: 17.5237\n",
      "Epoch 26/100, Loss: 16.7017\n",
      "IoU = \n",
      "0.506874483965408\n",
      "mAP@50 = \n",
      "67.13774204953714\n",
      "Validation - BBox Loss: 17.7397, Label Loss: 0.0000, Total Loss: 17.7397\n",
      "Epoch 27/100, Loss: 16.7553\n",
      "IoU = \n",
      "0.5000176079194826\n",
      "mAP@50 = \n",
      "66.60770724388291\n",
      "Validation - BBox Loss: 18.1174, Label Loss: 0.0000, Total Loss: 18.1174\n",
      "Epoch 28/100, Loss: 16.5951\n",
      "IoU = \n",
      "0.4963803068877037\n",
      "mAP@50 = \n",
      "68.02113339229419\n",
      "Validation - BBox Loss: 18.2641, Label Loss: 0.0000, Total Loss: 18.2641\n",
      "Epoch 29/100, Loss: 16.6174\n",
      "IoU = \n",
      "0.4818449026323746\n",
      "mAP@50 = \n",
      "62.89746360430335\n",
      "Validation - BBox Loss: 17.9697, Label Loss: 0.0000, Total Loss: 17.9697\n",
      "Epoch 30/100, Loss: 16.3697\n",
      "IoU = \n",
      "0.5125606614194768\n",
      "mAP@50 = \n",
      "68.19781166084559\n",
      "Validation - BBox Loss: 17.3981, Label Loss: 0.0000, Total Loss: 17.3981\n",
      "Epoch 31/100, Loss: 15.5900\n",
      "IoU = \n",
      "0.5361462750622481\n",
      "mAP@50 = \n",
      "69.43455954070545\n",
      "Validation - BBox Loss: 16.5552, Label Loss: 0.0000, Total Loss: 16.5552\n",
      "Validation loss improved from 17.3101 to 16.5552. Saving model...\n",
      "Epoch 32/100, Loss: 15.3161\n",
      "IoU = \n",
      "0.5452896100433968\n",
      "mAP@50 = \n",
      "70.67130742056531\n",
      "Validation - BBox Loss: 16.4501, Label Loss: 0.0000, Total Loss: 16.4501\n",
      "Validation loss improved from 16.5552 to 16.4501. Saving model...\n",
      "Epoch 33/100, Loss: 15.0511\n",
      "IoU = \n",
      "0.5421005551026173\n",
      "mAP@50 = \n",
      "69.43455954070545\n",
      "Validation - BBox Loss: 16.3397, Label Loss: 0.0000, Total Loss: 16.3397\n",
      "Validation loss improved from 16.4501 to 16.3397. Saving model...\n",
      "Epoch 34/100, Loss: 15.0037\n",
      "IoU = \n",
      "0.545259035370961\n",
      "mAP@50 = \n",
      "69.25788127215404\n",
      "Validation - BBox Loss: 16.3551, Label Loss: 0.0000, Total Loss: 16.3551\n",
      "Epoch 35/100, Loss: 14.9556\n",
      "IoU = \n",
      "0.5527302006213488\n",
      "mAP@50 = \n",
      "70.14127261491109\n",
      "Validation - BBox Loss: 16.2323, Label Loss: 0.0000, Total Loss: 16.2323\n",
      "Validation loss improved from 16.3397 to 16.2323. Saving model...\n",
      "Epoch 36/100, Loss: 14.8682\n",
      "IoU = \n",
      "0.5475444647505844\n",
      "mAP@50 = \n",
      "69.43455954070545\n",
      "Validation - BBox Loss: 16.3047, Label Loss: 0.0000, Total Loss: 16.3047\n",
      "Epoch 37/100, Loss: 14.8493\n",
      "IoU = \n",
      "0.5464335505286225\n",
      "mAP@50 = \n",
      "69.25788127215404\n",
      "Validation - BBox Loss: 16.3042, Label Loss: 0.0000, Total Loss: 16.3042\n",
      "Epoch 38/100, Loss: 14.7812\n",
      "IoU = \n",
      "0.5407277833643228\n",
      "mAP@50 = \n",
      "69.25788127215404\n",
      "Validation - BBox Loss: 16.4659, Label Loss: 0.0000, Total Loss: 16.4659\n",
      "Epoch 39/100, Loss: 14.7745\n",
      "IoU = \n",
      "0.5450832476245417\n",
      "mAP@50 = \n",
      "69.43455954070545\n",
      "Validation - BBox Loss: 16.2993, Label Loss: 0.0000, Total Loss: 16.2993\n",
      "Epoch 40/100, Loss: 14.6696\n",
      "IoU = \n",
      "0.5478977518215407\n",
      "mAP@50 = \n",
      "70.3179508834625\n",
      "Validation - BBox Loss: 16.2960, Label Loss: 0.0000, Total Loss: 16.2960\n",
      "Epoch 41/100, Loss: 14.5995\n",
      "IoU = \n",
      "0.5482500072188351\n",
      "mAP@50 = \n",
      "69.78791607780828\n",
      "Validation - BBox Loss: 16.2351, Label Loss: 0.0000, Total Loss: 16.2351\n",
      "Epoch 42/100, Loss: 14.5410\n",
      "IoU = \n",
      "0.5479400433285668\n",
      "mAP@50 = \n",
      "70.14127261491109\n",
      "Validation - BBox Loss: 16.2404, Label Loss: 0.0000, Total Loss: 16.2404\n",
      "Epoch 43/100, Loss: 14.4994\n",
      "IoU = \n",
      "0.5485133287186699\n",
      "mAP@50 = \n",
      "69.96459434635968\n",
      "Validation - BBox Loss: 16.2129, Label Loss: 0.0000, Total Loss: 16.2129\n",
      "Validation loss improved from 16.2323 to 16.2129. Saving model...\n",
      "Epoch 44/100, Loss: 14.4641\n",
      "IoU = \n",
      "0.5495217353256309\n",
      "mAP@50 = \n",
      "70.14127261491109\n",
      "Validation - BBox Loss: 16.2104, Label Loss: 0.0000, Total Loss: 16.2104\n",
      "Validation loss improved from 16.2129 to 16.2104. Saving model...\n",
      "Epoch 45/100, Loss: 14.4987\n",
      "IoU = \n",
      "0.5498087522594337\n",
      "mAP@50 = \n",
      "70.4946291520139\n",
      "Validation - BBox Loss: 16.2090, Label Loss: 0.0000, Total Loss: 16.2090\n",
      "Validation loss improved from 16.2104 to 16.2090. Saving model...\n",
      "Epoch 46/100, Loss: 14.5356\n",
      "IoU = \n",
      "0.5503663423319155\n",
      "mAP@50 = \n",
      "70.3179508834625\n",
      "Validation - BBox Loss: 16.2142, Label Loss: 0.0000, Total Loss: 16.2142\n",
      "Epoch 47/100, Loss: 14.4675\n",
      "IoU = \n",
      "0.5503085980694408\n",
      "mAP@50 = \n",
      "69.96459434635968\n",
      "Validation - BBox Loss: 16.1983, Label Loss: 0.0000, Total Loss: 16.1983\n",
      "Validation loss improved from 16.2090 to 16.1983. Saving model...\n",
      "Epoch 48/100, Loss: 14.4905\n",
      "IoU = \n",
      "0.5495002443413497\n",
      "mAP@50 = \n",
      "69.61123780925686\n",
      "Validation - BBox Loss: 16.2231, Label Loss: 0.0000, Total Loss: 16.2231\n",
      "Epoch 49/100, Loss: 14.4639\n",
      "IoU = \n",
      "0.5492545183477126\n",
      "mAP@50 = \n",
      "70.14127261491109\n",
      "Validation - BBox Loss: 16.1963, Label Loss: 0.0000, Total Loss: 16.1963\n",
      "Validation loss improved from 16.1983 to 16.1963. Saving model...\n",
      "Epoch 50/100, Loss: 14.4470\n",
      "IoU = \n",
      "0.5494790488789055\n",
      "mAP@50 = \n",
      "69.25788127215404\n",
      "Validation - BBox Loss: 16.1853, Label Loss: 0.0000, Total Loss: 16.1853\n",
      "Validation loss improved from 16.1963 to 16.1853. Saving model...\n",
      "Epoch 51/100, Loss: 14.4540\n",
      "IoU = \n",
      "0.549137464926871\n",
      "mAP@50 = \n",
      "69.96459434635968\n",
      "Validation - BBox Loss: 16.2166, Label Loss: 0.0000, Total Loss: 16.2166\n",
      "Epoch 52/100, Loss: 14.4360\n",
      "IoU = \n",
      "0.5497835705011742\n",
      "mAP@50 = \n",
      "69.96459434635968\n",
      "Validation - BBox Loss: 16.1856, Label Loss: 0.0000, Total Loss: 16.1856\n",
      "Epoch 53/100, Loss: 14.4572\n",
      "IoU = \n",
      "0.5496207108133301\n",
      "mAP@50 = \n",
      "69.96459434635968\n",
      "Validation - BBox Loss: 16.1964, Label Loss: 0.0000, Total Loss: 16.1964\n",
      "Epoch 54/100, Loss: 14.4664\n",
      "IoU = \n",
      "0.548111604448069\n",
      "mAP@50 = \n",
      "69.43455954070545\n",
      "Validation - BBox Loss: 16.2083, Label Loss: 0.0000, Total Loss: 16.2083\n",
      "Epoch 55/100, Loss: 14.4593\n",
      "IoU = \n",
      "0.5508814121733498\n",
      "mAP@50 = \n",
      "69.43455954070545\n",
      "Validation - BBox Loss: 16.1658, Label Loss: 0.0000, Total Loss: 16.1658\n",
      "Validation loss improved from 16.1853 to 16.1658. Saving model...\n",
      "Epoch 56/100, Loss: 14.4442\n",
      "IoU = \n",
      "0.5498310015561526\n",
      "mAP@50 = \n",
      "69.43455954070545\n",
      "Validation - BBox Loss: 16.2181, Label Loss: 0.0000, Total Loss: 16.2181\n",
      "Epoch 57/100, Loss: 14.4303\n",
      "IoU = \n",
      "0.5486925589336188\n",
      "mAP@50 = \n",
      "69.08120300360264\n",
      "Validation - BBox Loss: 16.2179, Label Loss: 0.0000, Total Loss: 16.2179\n",
      "Epoch 58/100, Loss: 14.3799\n",
      "IoU = \n",
      "0.5520638390650928\n",
      "mAP@50 = \n",
      "70.14127261491109\n",
      "Validation - BBox Loss: 16.1683, Label Loss: 0.0000, Total Loss: 16.1683\n",
      "Epoch 59/100, Loss: 14.3767\n",
      "IoU = \n",
      "0.5495131071782408\n",
      "mAP@50 = \n",
      "69.96459434635968\n",
      "Validation - BBox Loss: 16.1975, Label Loss: 0.0000, Total Loss: 16.1975\n",
      "Epoch 60/100, Loss: 14.4138\n",
      "IoU = \n",
      "0.5495547358902638\n",
      "mAP@50 = \n",
      "69.61123780925686\n",
      "Validation - BBox Loss: 16.2032, Label Loss: 0.0000, Total Loss: 16.2032\n",
      "Epoch 61/100, Loss: 14.3690\n",
      "IoU = \n",
      "0.5492576456706075\n",
      "mAP@50 = \n",
      "69.96459434635968\n",
      "Validation - BBox Loss: 16.2083, Label Loss: 0.0000, Total Loss: 16.2083\n",
      "Epoch 62/100, Loss: 14.3975\n",
      "IoU = \n",
      "0.5509672229977937\n",
      "mAP@50 = \n",
      "69.78791607780828\n",
      "Validation - BBox Loss: 16.2020, Label Loss: 0.0000, Total Loss: 16.2020\n",
      "Epoch 63/100, Loss: 14.3493\n",
      "IoU = \n",
      "0.550043665615771\n",
      "mAP@50 = \n",
      "69.25788127215404\n",
      "Validation - BBox Loss: 16.1925, Label Loss: 0.0000, Total Loss: 16.1925\n",
      "Epoch 64/100, Loss: 14.4092\n",
      "IoU = \n",
      "0.5482270164999785\n",
      "mAP@50 = \n",
      "69.61123780925686\n",
      "Validation - BBox Loss: 16.2095, Label Loss: 0.0000, Total Loss: 16.2095\n",
      "Epoch 65/100, Loss: 14.3612\n",
      "IoU = \n",
      "0.5503592925206281\n",
      "mAP@50 = \n",
      "69.61123780925686\n",
      "Validation - BBox Loss: 16.1905, Label Loss: 0.0000, Total Loss: 16.1905\n",
      "Epoch 66/100, Loss: 14.3927\n",
      "IoU = \n",
      "0.5474470964046326\n",
      "mAP@50 = \n",
      "69.25788127215404\n",
      "Validation - BBox Loss: 16.2216, Label Loss: 0.0000, Total Loss: 16.2216\n",
      "Epoch 67/100, Loss: 14.3245\n",
      "IoU = \n",
      "0.5496088094625116\n",
      "mAP@50 = \n",
      "69.96459434635968\n",
      "Validation - BBox Loss: 16.2155, Label Loss: 0.0000, Total Loss: 16.2155\n",
      "Epoch 68/100, Loss: 14.3218\n",
      "IoU = \n",
      "0.5480868603997986\n",
      "mAP@50 = \n",
      "69.78791607780828\n",
      "Validation - BBox Loss: 16.2397, Label Loss: 0.0000, Total Loss: 16.2397\n",
      "Epoch 69/100, Loss: 14.3475\n",
      "IoU = \n",
      "0.5495896146014866\n",
      "mAP@50 = \n",
      "69.25788127215404\n",
      "Validation - BBox Loss: 16.2034, Label Loss: 0.0000, Total Loss: 16.2034\n",
      "Epoch 70/100, Loss: 14.3747\n",
      "IoU = \n",
      "0.550711655791013\n",
      "mAP@50 = \n",
      "70.14127261491109\n",
      "Validation - BBox Loss: 16.1907, Label Loss: 0.0000, Total Loss: 16.1907\n",
      "Epoch 71/100, Loss: 14.3244\n",
      "IoU = \n",
      "0.5496684299953045\n",
      "mAP@50 = \n",
      "69.96459434635968\n",
      "Validation - BBox Loss: 16.2047, Label Loss: 0.0000, Total Loss: 16.2047\n",
      "Epoch 72/100, Loss: 14.3045\n",
      "IoU = \n",
      "0.5492428677047968\n",
      "mAP@50 = \n",
      "69.25788127215404\n",
      "Validation - BBox Loss: 16.2018, Label Loss: 0.0000, Total Loss: 16.2018\n",
      "Epoch 73/100, Loss: 14.3465\n",
      "IoU = \n",
      "0.5484298120817176\n",
      "mAP@50 = \n",
      "69.43455954070545\n",
      "Validation - BBox Loss: 16.2256, Label Loss: 0.0000, Total Loss: 16.2256\n",
      "Epoch 74/100, Loss: 14.2742\n",
      "IoU = \n",
      "0.5493758864661303\n",
      "mAP@50 = \n",
      "69.43455954070545\n",
      "Validation - BBox Loss: 16.2223, Label Loss: 0.0000, Total Loss: 16.2223\n",
      "Epoch 75/100, Loss: 14.3042\n",
      "IoU = \n",
      "0.549821956946215\n",
      "mAP@50 = \n",
      "69.61123780925686\n",
      "Validation - BBox Loss: 16.2063, Label Loss: 0.0000, Total Loss: 16.2063\n",
      "Epoch 76/100, Loss: 14.2826\n",
      "IoU = \n",
      "0.5500648929424874\n",
      "mAP@50 = \n",
      "68.90452473505123\n",
      "Validation - BBox Loss: 16.1906, Label Loss: 0.0000, Total Loss: 16.1906\n",
      "Epoch 77/100, Loss: 14.2811\n",
      "IoU = \n",
      "0.5493019680540298\n",
      "mAP@50 = \n",
      "69.08120300360264\n",
      "Validation - BBox Loss: 16.2215, Label Loss: 0.0000, Total Loss: 16.2215\n",
      "Epoch 78/100, Loss: 14.2917\n",
      "IoU = \n",
      "0.5486715719714274\n",
      "mAP@50 = \n",
      "69.61123780925686\n",
      "Validation - BBox Loss: 16.2313, Label Loss: 0.0000, Total Loss: 16.2313\n",
      "Epoch 79/100, Loss: 14.2286\n",
      "IoU = \n",
      "0.5491039950853911\n",
      "mAP@50 = \n",
      "69.08120300360264\n",
      "Validation - BBox Loss: 16.2282, Label Loss: 0.0000, Total Loss: 16.2282\n",
      "Epoch 80/100, Loss: 14.3096\n",
      "IoU = \n",
      "0.5488083112545562\n",
      "mAP@50 = \n",
      "68.90452473505123\n",
      "Validation - BBox Loss: 16.2414, Label Loss: 0.0000, Total Loss: 16.2414\n",
      "Epoch 81/100, Loss: 14.2893\n",
      "IoU = \n",
      "0.5492643146311236\n",
      "mAP@50 = \n",
      "69.08120300360264\n",
      "Validation - BBox Loss: 16.2365, Label Loss: 0.0000, Total Loss: 16.2365\n",
      "Epoch 82/100, Loss: 14.2921\n",
      "IoU = \n",
      "0.5479696716727811\n",
      "mAP@50 = \n",
      "68.90452473505123\n",
      "Validation - BBox Loss: 16.2550, Label Loss: 0.0000, Total Loss: 16.2550\n",
      "Epoch 83/100, Loss: 14.2725\n",
      "IoU = \n",
      "0.5487947044360871\n",
      "mAP@50 = \n",
      "69.08120300360264\n",
      "Validation - BBox Loss: 16.2522, Label Loss: 0.0000, Total Loss: 16.2522\n",
      "Epoch 84/100, Loss: 14.2792\n",
      "IoU = \n",
      "0.5487441955785869\n",
      "mAP@50 = \n",
      "68.374489929397\n",
      "Validation - BBox Loss: 16.2278, Label Loss: 0.0000, Total Loss: 16.2278\n",
      "Epoch 85/100, Loss: 14.2282\n",
      "IoU = \n",
      "0.5489596872156084\n",
      "mAP@50 = \n",
      "68.90452473505123\n",
      "Validation - BBox Loss: 16.2331, Label Loss: 0.0000, Total Loss: 16.2331\n",
      "Epoch 86/100, Loss: 14.2542\n",
      "IoU = \n",
      "0.550388320253721\n",
      "mAP@50 = \n",
      "69.08120300360264\n",
      "Validation - BBox Loss: 16.2148, Label Loss: 0.0000, Total Loss: 16.2148\n",
      "Epoch 87/100, Loss: 14.2740\n",
      "IoU = \n",
      "0.5489309231459423\n",
      "mAP@50 = \n",
      "69.08120300360264\n",
      "Validation - BBox Loss: 16.2168, Label Loss: 0.0000, Total Loss: 16.2168\n",
      "Epoch 88/100, Loss: 14.2763\n",
      "IoU = \n",
      "0.5486479108028489\n",
      "mAP@50 = \n",
      "69.25788127215404\n",
      "Validation - BBox Loss: 16.2293, Label Loss: 0.0000, Total Loss: 16.2293\n",
      "Epoch 89/100, Loss: 14.2112\n",
      "IoU = \n",
      "0.5480006163676151\n",
      "mAP@50 = \n",
      "68.55116819794841\n",
      "Validation - BBox Loss: 16.2633, Label Loss: 0.0000, Total Loss: 16.2633\n",
      "Epoch 90/100, Loss: 14.2562\n",
      "IoU = \n",
      "0.5483727715994838\n",
      "mAP@50 = \n",
      "68.374489929397\n",
      "Validation - BBox Loss: 16.2382, Label Loss: 0.0000, Total Loss: 16.2382\n",
      "Epoch 91/100, Loss: 14.2344\n",
      "IoU = \n",
      "0.5482480182544488\n",
      "mAP@50 = \n",
      "68.72784646649981\n",
      "Validation - BBox Loss: 16.2386, Label Loss: 0.0000, Total Loss: 16.2386\n",
      "Epoch 92/100, Loss: 14.2779\n",
      "IoU = \n",
      "0.5507762435187714\n",
      "mAP@50 = \n",
      "69.25788127215404\n",
      "Validation - BBox Loss: 16.2216, Label Loss: 0.0000, Total Loss: 16.2216\n",
      "Epoch 93/100, Loss: 14.1904\n",
      "IoU = \n",
      "0.549480375667825\n",
      "mAP@50 = \n",
      "68.55116819794841\n",
      "Validation - BBox Loss: 16.2214, Label Loss: 0.0000, Total Loss: 16.2214\n",
      "Epoch 94/100, Loss: 14.1998\n",
      "IoU = \n",
      "0.5513551707219911\n",
      "mAP@50 = \n",
      "69.25788127215404\n",
      "Validation - BBox Loss: 16.1945, Label Loss: 0.0000, Total Loss: 16.1945\n",
      "Epoch 95/100, Loss: 14.2029\n",
      "IoU = \n",
      "0.5486205579661978\n",
      "mAP@50 = \n",
      "68.90452473505123\n",
      "Validation - BBox Loss: 16.2371, Label Loss: 0.0000, Total Loss: 16.2371\n",
      "Epoch 96/100, Loss: 14.2360\n",
      "IoU = \n",
      "0.5507078636211405\n",
      "mAP@50 = \n",
      "69.43455954070545\n",
      "Validation - BBox Loss: 16.1880, Label Loss: 0.0000, Total Loss: 16.1880\n",
      "Epoch 97/100, Loss: 14.1715\n",
      "IoU = \n",
      "0.5509996976986834\n",
      "mAP@50 = \n",
      "69.61123780925686\n",
      "Validation - BBox Loss: 16.2041, Label Loss: 0.0000, Total Loss: 16.2041\n",
      "Epoch 98/100, Loss: 14.2214\n",
      "IoU = \n",
      "0.5461330713096236\n",
      "mAP@50 = \n",
      "68.19781166084559\n",
      "Validation - BBox Loss: 16.2482, Label Loss: 0.0000, Total Loss: 16.2482\n",
      "Epoch 99/100, Loss: 14.2625\n",
      "IoU = \n",
      "0.54912597001341\n",
      "mAP@50 = \n",
      "69.43455954070545\n",
      "Validation - BBox Loss: 16.2339, Label Loss: 0.0000, Total Loss: 16.2339\n",
      "Epoch 100/100, Loss: 14.2309\n",
      "IoU = \n",
      "0.5477210736673904\n",
      "mAP@50 = \n",
      "69.08120300360264\n",
      "Validation - BBox Loss: 16.2639, Label Loss: 0.0000, Total Loss: 16.2639\n",
      "Training complete. Best model saved as:\n",
      "yolo_1744591240.344742.pth\n",
      "100%|██████████| 1/1 [35:01<00:00, 2101.40s/trial, best loss: 16.165769577026367]\n"
     ]
    }
   ],
   "source": [
    "#batch_size = 16\n",
    "#target_size = (224, 224)\n",
    "#train_loader, val_loader = get_dataloaders(base_adress, annotations, batch_size, target_size)\n",
    "#train_model(mobilenetfacedetector, train_loader, val_loader, num_epochs=2)\n",
    "import time\n",
    "\n",
    "hyperopt_out = [['model id', 'score', 'arch', 'learning_rate', 'batch_size']]\n",
    "\n",
    "# ***************** mobilenet architecture\n",
    "def min_func(params):\n",
    "    model_id = time.time()\n",
    "    curr_model = MobileNetFaceDetector().to(device)\n",
    "    params = {'model_id': model_id, 'model': curr_model, 'arch': params['arch'],\n",
    "              'learning_rate': float(params['learning_rate']),\n",
    "              'batch_size': int(params['batch_size'])}\n",
    "              #'dropout': float(params['dropout'])}\n",
    "              #weight decay\n",
    "    target_size = (224, 224)\n",
    "    train_loader, val_loader = get_dataloaders(base_adress, annotations, params['batch_size'], target_size)\n",
    "    score = train_model(train_loader, val_loader, num_epochs=100, scheduler=False, **params)\n",
    "    hyperopt_out.append([model_id, score, params['arch'],\n",
    "                         params['learning_rate'], params['batch_size']])\n",
    "\n",
    "    return score\n",
    "\n",
    "mobilenetv2space={'arch': 'mobilenetv2',\n",
    "                  #'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(1e-3)),\n",
    "                  'learning_rate': hp.choice('learning_rate', [0.0009422826315669756]),\n",
    "                  #'batch_size': hp.choice('batch_size', [16, 32, 64])}\n",
    "                  'batch_size': hp.choice('batch_size', [32])}\n",
    "\n",
    "best_params1 = fmin(fn=min_func, space=mobilenetv2space, algo=tpe.suggest, max_evals=1)\n",
    "\n",
    "# ************* yolo architecture\n",
    "def min_func(params):\n",
    "    model_id = time.time()\n",
    "    curr_model = YOLOFaceDetector().to(device)\n",
    "    params = {'model_id': model_id, 'model': curr_model, 'arch': params['arch'],\n",
    "              'learning_rate': float(params['learning_rate']),\n",
    "              'batch_size': int(params['batch_size'])}\n",
    "    target_size = (224, 224)\n",
    "    train_loader, val_loader = get_dataloaders(base_adress, annotations, params['batch_size'], target_size)\n",
    "    score = train_model(train_loader, val_loader, num_epochs=100, scheduler=True, **params)\n",
    "    hyperopt_out.append([model_id, score, params['arch'],\n",
    "                         params['learning_rate'], params['batch_size']])\n",
    "\n",
    "    return score\n",
    "\n",
    "yolospace={'arch': 'yolo',\n",
    "           'learning_rate': hp.loguniform('learning_rate', np.log(1e-5), np.log(1e-2)),\n",
    "           'learning_rate': hp.choice('learning_rate', [0.0017586225237505772]),\n",
    "           #'batch_size': hp.choice('batch_size', [16, 32, 64])}\n",
    "           'batch_size': hp.choice('batch_size', [16])}\n",
    "\n",
    "\n",
    "best_params2 = fmin(fn=min_func, space=yolospace, algo=tpe.suggest, max_evals=1)\n",
    "\n",
    "with open('hyperopt_out.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(hyperopt_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e751144",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T01:15:42.094356Z",
     "iopub.status.busy": "2025-04-14T01:15:42.094029Z",
     "iopub.status.idle": "2025-04-14T01:15:42.100665Z",
     "shell.execute_reply": "2025-04-14T01:15:42.099858Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.179427,
     "end_time": "2025-04-14T01:15:42.101991",
     "exception": false,
     "start_time": "2025-04-14T01:15:41.922564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FDDBTestDataset(Dataset):\n",
    "    def __init__(self, img_dir, target_size=(224, 224)):\n",
    "        self.img_dir = img_dir\n",
    "        self.target_size = target_size\n",
    "        self.transform = transforms.Compose([\n",
    "                                            transforms.ToTensor(),\n",
    "                                            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                                            ])\n",
    "        self.image_files = []\n",
    "\n",
    "        for img in os.listdir(img_dir):\n",
    "            self.image_files.append(img)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_dir + '/' + self.image_files[idx]\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
    "        image_resized = cv2.resize(image, self.target_size)\n",
    "        image_resized = self.transform(image_resized)\n",
    "\n",
    "        return image_resized, self.image_files[idx]\n",
    "\n",
    "# DataLoader preparation\n",
    "def get_test_dataloader(img_dir, batch_size=1, target_size=(224, 224)):\n",
    "    dataset = FDDBTestDataset(img_dir, target_size)\n",
    "    test_loader = DataLoader(dataset, batch_size=batch_size)#, collate_fn=collate_fn)\n",
    "\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "950efb54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T01:15:42.446865Z",
     "iopub.status.busy": "2025-04-14T01:15:42.446562Z",
     "iopub.status.idle": "2025-04-14T01:15:42.451039Z",
     "shell.execute_reply": "2025-04-14T01:15:42.450377Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.179778,
     "end_time": "2025-04-14T01:15:42.452229",
     "exception": false,
     "start_time": "2025-04-14T01:15:42.272451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    predictions = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (image, image_name) in enumerate(test_loader):\n",
    "            image = image.to(device)\n",
    "\n",
    "            # get prediction\n",
    "            pbbox, plabel = model(image)\n",
    "            \n",
    "            # format prediction\n",
    "            preds = [{\"id\": image_name, \"boxes\": [pbbox], \"labels\": plabel}]\n",
    "            preds = normalize_boxes(preds)\n",
    "            predictions.append(preds)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56a59f92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T01:15:42.795447Z",
     "iopub.status.busy": "2025-04-14T01:15:42.795086Z",
     "iopub.status.idle": "2025-04-14T01:16:57.946109Z",
     "shell.execute_reply": "2025-04-14T01:16:57.945096Z"
    },
    "papermill": {
     "duration": 75.325166,
     "end_time": "2025-04-14T01:16:57.947768",
     "exception": false,
     "start_time": "2025-04-14T01:15:42.622602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferencing on model: mobilenetv2_17445892593402731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-76c115351f9d>:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  inf_model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferencing on model: yolo_1744591240344742\n"
     ]
    }
   ],
   "source": [
    "# evaluate - submission\n",
    "\n",
    "# test dataloader\n",
    "testset_file_path = '/kaggle/input/testset/testset'\n",
    "test_dataloader = get_test_dataloader(testset_file_path)\n",
    "\n",
    "# model inference\n",
    "for model_path in os.listdir('/kaggle/working'):\n",
    "    full_path = model_path.split('.')\n",
    "    arch = model_path.split('_')[0]\n",
    "    model_id = ''.join(full_path[0:len(full_path)-1])\n",
    "    if full_path[-1] == 'pth':\n",
    "        print('inferencing on model:', model_id)\n",
    "        if arch == 'mobilenetv2':\n",
    "            inf_model = MobileNetFaceDetector()\n",
    "        elif arch == 'yolo':\n",
    "            inf_model = YOLOFaceDetector()\n",
    "        else:\n",
    "            print('ERROR: model architecture not supported:', arch)\n",
    "        inf_model.load_state_dict(torch.load(model_path))\n",
    "        inf_model.to(device)\n",
    "        predictions = inference(inf_model, test_dataloader, device)\n",
    "        \n",
    "        # create submission\n",
    "        data = [['image_id', 'x1', 'y1', 'x2', 'y2']]\n",
    "        \n",
    "        for i in range(len(predictions)):\n",
    "            img_id = predictions[i][0]['id'][0]\n",
    "            image = cv2.imread(testset_file_path + '/' + img_id)\n",
    "            pbbox = predictions[i][0]['boxes'].cpu().tolist()[0][0]\n",
    "        \n",
    "            # scale predictions\n",
    "            h, w = (224, 224)\n",
    "            target_h, target_w, _ = image.shape\n",
    "            scale_x = target_w / w\n",
    "            scale_y = target_h / h\n",
    "            x_min = int(pbbox[0] * scale_x)\n",
    "            y_min = int(pbbox[1] * scale_y)\n",
    "            x_max = int(pbbox[2] * scale_x)\n",
    "            y_max = int(pbbox[3] * scale_y)\n",
    "            pbbox = [x_min, y_min, x_max, y_max]\n",
    "            formatted_img_id = \"\\'\" + img_id + \"\\'\"\n",
    "            data.append([formatted_img_id, pbbox[0], pbbox[1], pbbox[2], pbbox[3]])\n",
    "        with open(f'od_out_{model_id}.csv', 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45c81589",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T01:16:58.358346Z",
     "iopub.status.busy": "2025-04-14T01:16:58.358018Z",
     "iopub.status.idle": "2025-04-14T01:17:06.271039Z",
     "shell.execute_reply": "2025-04-14T01:17:06.269744Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 8.088525,
     "end_time": "2025-04-14T01:17:06.272884",
     "exception": false,
     "start_time": "2025-04-14T01:16:58.184359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (1.17.0)\r\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.26.4)\r\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->onnx) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->onnx) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->onnx) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->onnx) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->onnx) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->onnx) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.20->onnx) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.20->onnx) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.20->onnx) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.20->onnx) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.20->onnx) (2024.2.0)\r\n",
      "Collecting onnxscript\r\n",
      "  Downloading onnxscript-0.2.4-py3-none-any.whl.metadata (15 kB)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnxscript) (1.26.4)\r\n",
      "Requirement already satisfied: onnx>=1.16 in /usr/local/lib/python3.10/dist-packages (from onnxscript) (1.17.0)\r\n",
      "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.10/dist-packages (from onnxscript) (4.12.2)\r\n",
      "Requirement already satisfied: ml_dtypes in /usr/local/lib/python3.10/dist-packages (from onnxscript) (0.4.1)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxscript) (24.2)\r\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.16->onnxscript) (3.20.3)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->onnxscript) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->onnxscript) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->onnxscript) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->onnxscript) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->onnxscript) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->onnxscript) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->onnxscript) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->onnxscript) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->onnxscript) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->onnxscript) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->onnxscript) (2024.2.0)\r\n",
      "Downloading onnxscript-0.2.4-py3-none-any.whl (705 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m705.4/705.4 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: onnxscript\r\n",
      "Successfully installed onnxscript-0.2.4\r\n"
     ]
    }
   ],
   "source": [
    "!pip install onnx\n",
    "!pip install onnxscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f174f477",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T01:17:06.626117Z",
     "iopub.status.busy": "2025-04-14T01:17:06.625703Z",
     "iopub.status.idle": "2025-04-14T01:17:22.327202Z",
     "shell.execute_reply": "2025-04-14T01:17:22.326137Z"
    },
    "papermill": {
     "duration": 15.880489,
     "end_time": "2025-04-14T01:17:22.328647",
     "exception": false,
     "start_time": "2025-04-14T01:17:06.448158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deploying to onnx: mobilenetv2_17445892593402731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-cb2f0252f971>:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(PATH))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Model successfully exported to ONNX!\n",
      "deploying to onnx: yolo_1744591240344742\n",
      "...Model successfully exported to ONNX!\n"
     ]
    }
   ],
   "source": [
    "# Model class must be defined somewhere\n",
    "for PATH in os.listdir('/kaggle/working'):\n",
    "    full_path = PATH.split('.')\n",
    "    arch = PATH.split('_')[0]\n",
    "    model_id = ''.join(full_path[0:len(full_path)-1])\n",
    "    if full_path[-1] == 'pth':\n",
    "        print('deploying to onnx:', model_id)\n",
    "        if arch == 'mobilenetv2':\n",
    "            model = MobileNetFaceDetector()\n",
    "        elif arch == 'yolo':\n",
    "            model = YOLOFaceDetector()\n",
    "        else:\n",
    "            print('ERROR: model architecture not supported:', arch)\n",
    "        model.load_state_dict(torch.load(PATH))\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        dummy_input = torch.randn(1, 3, 224, 224).to(device)  # Adjust shape based on your model's input size\n",
    "        \n",
    "        # Export the model to ONNX\n",
    "        torch.onnx.export(\n",
    "            model,  # The loaded PyTorch model\n",
    "            dummy_input,  # Example input tensor\n",
    "            f\"{model_id}.onnx\",  # Output ONNX file name\n",
    "            export_params=True,  # Store trained parameters\n",
    "            opset_version=13,  # ONNX version (adjust as needed)\n",
    "            do_constant_folding=True,  # Optimize by folding constants\n",
    "            input_names=[\"input\"],  # Naming input tensor\n",
    "            output_names=[\"output\"],  # Naming output tensor\n",
    "            dynamic_axes=None \n",
    "        )\n",
    "        \n",
    "        print(\"...Model successfully exported to ONNX!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6836738,
     "sourceId": 10984842,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7089690,
     "sourceId": 11333711,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4211.904529,
   "end_time": "2025-04-14T01:17:25.714653",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-14T00:07:13.810124",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
